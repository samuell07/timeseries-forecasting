{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related urls, will remove once finished:\n",
    "- https://www.tensorflow.org/tutorials/structured_data/time_series#multi-step_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "import sys\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path.cwd().parent.parent\n",
    "\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "from shared.metrics import print_evaluation_metrics\n",
    "from shared.helpers import store_model\n",
    "from shared.lstm import create_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/parsed_dataset.csv\"\n",
    "date_column = \"Date\"\n",
    "target_column = \"Close\"\n",
    "df = pd.read_csv(file_path, parse_dates=True)\n",
    "\n",
    "df.set_index(date_column, inplace=True)\n",
    "df = df.dropna()\n",
    "dates = df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3396, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days you want to predict into the future\n",
    "# Number of past days you want to use to predict the future\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = create_data(\n",
    "    scaled_data,\n",
    "    n_future=1,\n",
    "    n_past=30,\n",
    "    train_test_split_percentage=0.9,\n",
    "    validation_split_percentage=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3029, 30, 2)\n",
      "(337, 30, 2)\n",
      "(3029, 1)\n",
      "(337, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 16)            1216      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 16)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3345 (13.07 KB)\n",
      "Trainable params: 3345 (13.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------------LSTM-----------------------\n",
    "regressor = Sequential()\n",
    "regressor.add(\n",
    "    LSTM(\n",
    "        units=16,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    )\n",
    ")\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=16, return_sequences=False))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "regressor.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 9s 88ms/step - loss: 0.2511 - root_mean_squared_error: 0.5011 - val_loss: 1.9605 - val_root_mean_squared_error: 1.4002\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 2s 52ms/step - loss: 0.0290 - root_mean_squared_error: 0.1704 - val_loss: 1.9212 - val_root_mean_squared_error: 1.3861\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 2s 44ms/step - loss: 0.0190 - root_mean_squared_error: 0.1378 - val_loss: 1.8982 - val_root_mean_squared_error: 1.3778\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 2s 55ms/step - loss: 0.0155 - root_mean_squared_error: 0.1246 - val_loss: 1.8681 - val_root_mean_squared_error: 1.3668\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 2s 52ms/step - loss: 0.0142 - root_mean_squared_error: 0.1190 - val_loss: 1.8401 - val_root_mean_squared_error: 1.3565\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167 - val_loss: 1.8051 - val_root_mean_squared_error: 1.3435\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 2s 53ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - val_loss: 1.7854 - val_root_mean_squared_error: 1.3362\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0121 - root_mean_squared_error: 0.1100 - val_loss: 1.7695 - val_root_mean_squared_error: 1.3302\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 2s 54ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 1.7581 - val_root_mean_squared_error: 1.3259\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0118 - root_mean_squared_error: 0.1087 - val_loss: 1.7527 - val_root_mean_squared_error: 1.3239\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0114 - root_mean_squared_error: 0.1070 - val_loss: 1.7512 - val_root_mean_squared_error: 1.3233\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 1s 44ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 1.7362 - val_root_mean_squared_error: 1.3177\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 2s 52ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 1.7331 - val_root_mean_squared_error: 1.3165\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 2s 48ms/step - loss: 0.0103 - root_mean_squared_error: 0.1017 - val_loss: 1.7400 - val_root_mean_squared_error: 1.3191\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0103 - root_mean_squared_error: 0.1013 - val_loss: 1.7369 - val_root_mean_squared_error: 1.3179\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 1.7334 - val_root_mean_squared_error: 1.3166\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 1.7392 - val_root_mean_squared_error: 1.3188\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 1s 44ms/step - loss: 0.0102 - root_mean_squared_error: 0.1008 - val_loss: 1.7398 - val_root_mean_squared_error: 1.3190\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "# mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "history = regressor.fit(\n",
    "    X_train, y_train, validation_split=0.3, epochs=200, batch_size=64, callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7682 - root_mean_squared_error: 0.8765\n",
      "test loss, test acc: [0.7682 0.8765]\n"
     ]
    }
   ],
   "source": [
    "results = regressor.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", np.round(results, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, x_train, y_train, x_test, y_test):\n",
    "    (\n",
    "        first_additional_layer,\n",
    "        second_additional_layer,\n",
    "        third_additional_layer,\n",
    "        n_neurons,\n",
    "        n_batch_size,\n",
    "        dropout,\n",
    "    ) = config\n",
    "    possible_combinations = list(\n",
    "        itertools.product(\n",
    "            first_additional_layer,\n",
    "            second_additional_layer,\n",
    "            third_additional_layer,\n",
    "            n_neurons,\n",
    "            n_batch_size,\n",
    "            dropout,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(possible_combinations)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hist = []\n",
    "\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f\"{i+1}th combination: \\n\")\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "        (\n",
    "            first_additional_layer,\n",
    "            second_additional_layer,\n",
    "            third_additional_layer,\n",
    "            n_neurons,\n",
    "            n_batch_size,\n",
    "            dropout,\n",
    "        ) = possible_combinations[i]\n",
    "\n",
    "        # instantiating the model in the strategy scope creates the model on the TPU\n",
    "        # with tpu_strategy.scope():\n",
    "        regressor = Sequential()\n",
    "        regressor.add(\n",
    "            LSTM(\n",
    "                units=n_neurons,\n",
    "                return_sequences=True,\n",
    "                input_shape=(x_train.shape[1], x_train.shape[2]),\n",
    "            )\n",
    "        )\n",
    "        regressor.add(Dropout(dropout))\n",
    "\n",
    "        if first_additional_layer:\n",
    "            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        if second_additional_layer:\n",
    "            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        if third_additional_layer:\n",
    "            regressor.add(GRU(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        regressor.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "        regressor.add(Dropout(dropout))\n",
    "        regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "        regressor.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "        \"\"\"''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        \"\"\" \"\"\n",
    "\n",
    "        file_path = \"best_model.h5\"\n",
    "\n",
    "        mc = ModelCheckpoint(\n",
    "            file_path, monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True\n",
    "        )\n",
    "\n",
    "        \"\"\"''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        \"\"\" \"\"\n",
    "\n",
    "        regressor.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            validation_split=0.3,\n",
    "            epochs=1000,\n",
    "            batch_size=n_batch_size,\n",
    "            callbacks=[es, mc],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # load the best model\n",
    "        # regressor = load_model('best_model.h5')\n",
    "\n",
    "        train_accuracy = regressor.evaluate(x_train, y_train, verbose=0)\n",
    "        test_accuracy = regressor.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "        hist.append(\n",
    "            list(\n",
    "                (\n",
    "                    first_additional_layer,\n",
    "                    second_additional_layer,\n",
    "                    third_additional_layer,\n",
    "                    n_neurons,\n",
    "                    n_batch_size,\n",
    "                    dropout,\n",
    "                    train_accuracy,\n",
    "                    test_accuracy,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}\"\n",
    "        )\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(True, True, True, 64, 7, 0.2), (True, True, True, 64, 28, 0.2), (True, True, True, 64, 365, 0.2), (True, True, True, 128, 7, 0.2), (True, True, True, 128, 28, 0.2), (True, True, True, 128, 365, 0.2), (True, True, True, 256, 7, 0.2), (True, True, True, 256, 28, 0.2), (True, True, True, 256, 365, 0.2), (True, True, False, 64, 7, 0.2), (True, True, False, 64, 28, 0.2), (True, True, False, 64, 365, 0.2), (True, True, False, 128, 7, 0.2), (True, True, False, 128, 28, 0.2), (True, True, False, 128, 365, 0.2), (True, True, False, 256, 7, 0.2), (True, True, False, 256, 28, 0.2), (True, True, False, 256, 365, 0.2), (True, False, True, 64, 7, 0.2), (True, False, True, 64, 28, 0.2), (True, False, True, 64, 365, 0.2), (True, False, True, 128, 7, 0.2), (True, False, True, 128, 28, 0.2), (True, False, True, 128, 365, 0.2), (True, False, True, 256, 7, 0.2), (True, False, True, 256, 28, 0.2), (True, False, True, 256, 365, 0.2), (True, False, False, 64, 7, 0.2), (True, False, False, 64, 28, 0.2), (True, False, False, 64, 365, 0.2), (True, False, False, 128, 7, 0.2), (True, False, False, 128, 28, 0.2), (True, False, False, 128, 365, 0.2), (True, False, False, 256, 7, 0.2), (True, False, False, 256, 28, 0.2), (True, False, False, 256, 365, 0.2), (False, True, True, 64, 7, 0.2), (False, True, True, 64, 28, 0.2), (False, True, True, 64, 365, 0.2), (False, True, True, 128, 7, 0.2), (False, True, True, 128, 28, 0.2), (False, True, True, 128, 365, 0.2), (False, True, True, 256, 7, 0.2), (False, True, True, 256, 28, 0.2), (False, True, True, 256, 365, 0.2), (False, True, False, 64, 7, 0.2), (False, True, False, 64, 28, 0.2), (False, True, False, 64, 365, 0.2), (False, True, False, 128, 7, 0.2), (False, True, False, 128, 28, 0.2), (False, True, False, 128, 365, 0.2), (False, True, False, 256, 7, 0.2), (False, True, False, 256, 28, 0.2), (False, True, False, 256, 365, 0.2), (False, False, True, 64, 7, 0.2), (False, False, True, 64, 28, 0.2), (False, False, True, 64, 365, 0.2), (False, False, True, 128, 7, 0.2), (False, False, True, 128, 28, 0.2), (False, False, True, 128, 365, 0.2), (False, False, True, 256, 7, 0.2), (False, False, True, 256, 28, 0.2), (False, False, True, 256, 365, 0.2), (False, False, False, 64, 7, 0.2), (False, False, False, 64, 28, 0.2), (False, False, False, 64, 365, 0.2), (False, False, False, 128, 7, 0.2), (False, False, False, 128, 28, 0.2), (False, False, False, 128, 365, 0.2), (False, False, False, 256, 7, 0.2), (False, False, False, 256, 28, 0.2), (False, False, False, 256, 365, 0.2)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.98610, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuell/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.98610 to 0.91106, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.91106\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.91106\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.91106\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.91106\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.91106\n",
      "Epoch 7: early stopping\n",
      "0-th combination = (True, True, True, 64, 7, 0.2) \n",
      " train accuracy: [0.5017463564872742, 0.708340585231781] and test accuracy: [0.8513628840446472, 0.9226932525634766]\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.16217, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.16217\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.16217\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.16217\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.16217\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.16217\n",
      "Epoch 6: early stopping\n",
      "1-th combination = (True, True, True, 64, 28, 0.2) \n",
      " train accuracy: [0.39930179715156555, 0.6319032907485962] and test accuracy: [0.5954403877258301, 0.7716478109359741]\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.06652, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.06652\n",
      "\n",
      "Epoch 3: val_loss improved from 1.06652 to 1.01882, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.01882\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.01882\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.01882\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.01882\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.01882\n",
      "Epoch 8: early stopping\n",
      "2-th combination = (True, True, True, 64, 365, 0.2) \n",
      " train accuracy: [0.3338635563850403, 0.5778092741966248] and test accuracy: [0.4588574171066284, 0.6773901581764221]\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.97047, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.97047 to 0.79221, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.79221\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.79221\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.79221\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.79221\n",
      "\n",
      "Epoch 7: val_loss improved from 0.79221 to 0.14129, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.14129\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.14129\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.14129\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.14129\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.14129\n",
      "Epoch 12: early stopping\n",
      "3-th combination = (True, True, True, 128, 7, 0.2) \n",
      " train accuracy: [0.1690075397491455, 0.41110527515411377] and test accuracy: [0.23993481695652008, 0.48983141779899597]\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.78936, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.78936\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.78936\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.78936\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.78936\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.78936\n",
      "Epoch 6: early stopping\n",
      "4-th combination = (True, True, True, 128, 28, 0.2) \n",
      " train accuracy: [0.33667290210723877, 0.5802351832389832] and test accuracy: [0.44421693682670593, 0.6664960384368896]\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41394, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.41394 to 1.09208, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09208 to 0.94495, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.94495\n",
      "\n",
      "Epoch 5: val_loss improved from 0.94495 to 0.82175, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.82175\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.82175\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.82175\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.82175\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.82175\n",
      "Epoch 10: early stopping\n",
      "5-th combination = (True, True, True, 128, 365, 0.2) \n",
      " train accuracy: [0.27347156405448914, 0.5229451060295105] and test accuracy: [0.3218393325805664, 0.5673088431358337]\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46879, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.46879\n",
      "\n",
      "Epoch 3: val_loss improved from 0.46879 to 0.44897, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.44897\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.44897\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.44897\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.44897\n",
      "\n",
      "Epoch 8: val_loss improved from 0.44897 to 0.41324, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.41324 to 0.22974, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.22974\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.22974\n",
      "\n",
      "Epoch 12: val_loss improved from 0.22974 to 0.21272, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.21272\n",
      "\n",
      "Epoch 14: val_loss improved from 0.21272 to 0.16769, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.16769\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.16769\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.16769\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.16769\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.16769\n",
      "Epoch 19: early stopping\n",
      "6-th combination = (True, True, True, 256, 7, 0.2) \n",
      " train accuracy: [0.6468409895896912, 0.80426424741745] and test accuracy: [0.9807345271110535, 0.9903204441070557]\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.25874, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.25874\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.25874\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.25874\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.25874\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.25874\n",
      "Epoch 6: early stopping\n",
      "7-th combination = (True, True, True, 256, 28, 0.2) \n",
      " train accuracy: [0.17674455046653748, 0.4204099774360657] and test accuracy: [0.24619035422801971, 0.49617573618888855]\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.88765, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.88765 to 0.62664, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.62664\n",
      "\n",
      "Epoch 4: val_loss improved from 0.62664 to 0.33409, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.33409\n",
      "\n",
      "Epoch 6: val_loss improved from 0.33409 to 0.32826, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.32826 to 0.32274, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.32274 to 0.27067, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.27067 to 0.26816, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.26816 to 0.22127, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.22127\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.22127\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.22127\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.22127\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.22127\n",
      "Epoch 15: early stopping\n",
      "8-th combination = (True, True, True, 256, 365, 0.2) \n",
      " train accuracy: [0.10856319963932037, 0.3294892907142639] and test accuracy: [0.11628519743680954, 0.34100615978240967]\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68778, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.68778\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.68778\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68778 to 0.67534, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.67534\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.67534\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.67534\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.67534\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.67534\n",
      "Epoch 9: early stopping\n",
      "9-th combination = (True, True, False, 64, 7, 0.2) \n",
      " train accuracy: [0.4566420614719391, 0.6757529377937317] and test accuracy: [0.7539973258972168, 0.868330180644989]\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.13039, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.13039\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.13039\n",
      "\n",
      "Epoch 4: val_loss improved from 1.13039 to 1.12201, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 1.12201 to 1.10217, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.10217\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.10217\n",
      "\n",
      "Epoch 8: val_loss improved from 1.10217 to 1.03458, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.03458\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.03458\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.03458\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.03458\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.03458\n",
      "Epoch 13: early stopping\n",
      "10-th combination = (True, True, False, 64, 28, 0.2) \n",
      " train accuracy: [0.31415078043937683, 0.5604915618896484] and test accuracy: [0.4184770882129669, 0.6468980312347412]\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.86810, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.86810\n",
      "\n",
      "Epoch 3: val_loss improved from 0.86810 to 0.80092, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.80092\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.80092\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.80092\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.80092\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.80092\n",
      "Epoch 8: early stopping\n",
      "11-th combination = (True, True, False, 64, 365, 0.2) \n",
      " train accuracy: [0.26406556367874146, 0.5138731002807617] and test accuracy: [0.3305114507675171, 0.574901282787323]\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.79827, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.79827\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.79827\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.79827\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.79827\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.79827\n",
      "Epoch 6: early stopping\n",
      "12-th combination = (True, True, False, 128, 7, 0.2) \n",
      " train accuracy: [0.4105426073074341, 0.6407359838485718] and test accuracy: [0.644173800945282, 0.8026043772697449]\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.70315, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.70315 to 0.64850, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.64850\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.64850\n",
      "\n",
      "Epoch 5: val_loss improved from 0.64850 to 0.51499, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51499\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51499\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51499\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51499\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51499\n",
      "Epoch 10: early stopping\n",
      "13-th combination = (True, True, False, 128, 28, 0.2) \n",
      " train accuracy: [0.24256844818592072, 0.49251237511634827] and test accuracy: [0.2934253513813019, 0.5416874885559082]\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.94086, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.94086 to 0.52892, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52892 to 0.47553, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.47553 to 0.46895, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.46895 to 0.33742, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.33742\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.33742\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.33742\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.33742\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.33742\n",
      "Epoch 10: early stopping\n",
      "14-th combination = (True, True, False, 128, 365, 0.2) \n",
      " train accuracy: [0.13953490555286407, 0.37354370951652527] and test accuracy: [0.13533847033977509, 0.3678837716579437]\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52221, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52221\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52221 to 0.22882, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.22882\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.22882\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.22882\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.22882\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.22882\n",
      "Epoch 8: early stopping\n",
      "15-th combination = (True, True, False, 256, 7, 0.2) \n",
      " train accuracy: [0.502824604511261, 0.7091012597084045] and test accuracy: [0.8482761979103088, 0.9210191369056702]\n",
      "17th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.35018, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.35018\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.35018\n",
      "\n",
      "Epoch 4: val_loss improved from 0.35018 to 0.34627, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.34627\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34627\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.34627\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34627\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.34627\n",
      "Epoch 9: early stopping\n",
      "16-th combination = (True, True, False, 256, 28, 0.2) \n",
      " train accuracy: [0.3019484281539917, 0.5494983196258545] and test accuracy: [0.3666481077671051, 0.6055147647857666]\n",
      "18th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.70324, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.70324 to 0.52743, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52743\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52743 to 0.20789, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.20789\n",
      "\n",
      "Epoch 6: val_loss improved from 0.20789 to 0.18775, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.18775 to 0.15157, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.15157\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.15157\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.15157\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.15157\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.15157\n",
      "Epoch 12: early stopping\n",
      "17-th combination = (True, True, False, 256, 365, 0.2) \n",
      " train accuracy: [0.07814415544271469, 0.2795427739620209] and test accuracy: [0.0768790990114212, 0.2772707939147949]\n",
      "19th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.84414, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.84414\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.84414\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.84414\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.84414\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.84414\n",
      "Epoch 6: early stopping\n",
      "18-th combination = (True, False, True, 64, 7, 0.2) \n",
      " train accuracy: [0.2886313796043396, 0.5372442603111267] and test accuracy: [0.29245927929878235, 0.5407950282096863]\n",
      "20th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.84777, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.84777 to 0.84434, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.84434\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.84434\n",
      "\n",
      "Epoch 5: val_loss improved from 0.84434 to 0.81824, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.81824\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.81824\n",
      "\n",
      "Epoch 8: val_loss improved from 0.81824 to 0.76795, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.76795 to 0.64340, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.64340\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.64340\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.64340\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.64340\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.64340\n",
      "Epoch 14: early stopping\n",
      "19-th combination = (True, False, True, 64, 28, 0.2) \n",
      " train accuracy: [0.23029907047748566, 0.47989484667778015] and test accuracy: [0.3054612874984741, 0.5526854991912842]\n",
      "21th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.78842, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.78842\n",
      "\n",
      "Epoch 3: val_loss improved from 0.78842 to 0.70756, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.70756\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.70756\n",
      "\n",
      "Epoch 6: val_loss improved from 0.70756 to 0.69923, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.69923\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.69923\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.69923\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.69923\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.69923\n",
      "Epoch 11: early stopping\n",
      "20-th combination = (True, False, True, 64, 365, 0.2) \n",
      " train accuracy: [0.2268647700548172, 0.47630321979522705] and test accuracy: [0.2662619352340698, 0.5160056948661804]\n",
      "22th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.18941, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.18941\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.18941\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.18941\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.18941\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.18941\n",
      "Epoch 6: early stopping\n",
      "21-th combination = (True, False, True, 128, 7, 0.2) \n",
      " train accuracy: [0.26473191380500793, 0.514521062374115] and test accuracy: [0.3628781735897064, 0.6023936867713928]\n",
      "23th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.39003, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.39003\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.39003\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.39003\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.39003\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.39003\n",
      "Epoch 6: early stopping\n",
      "22-th combination = (True, False, True, 128, 28, 0.2) \n",
      " train accuracy: [0.1748967319726944, 0.4182065725326538] and test accuracy: [0.20595283806324005, 0.45382025837898254]\n",
      "24th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75984, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.75984 to 0.32952, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.32952\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.32952\n",
      "\n",
      "Epoch 5: val_loss improved from 0.32952 to 0.30019, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.30019\n",
      "\n",
      "Epoch 7: val_loss improved from 0.30019 to 0.26166, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.26166\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.26166\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.26166\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.26166\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.26166\n",
      "Epoch 12: early stopping\n",
      "23-th combination = (True, False, True, 128, 365, 0.2) \n",
      " train accuracy: [0.11311253905296326, 0.3363220691680908] and test accuracy: [0.11840569972991943, 0.34410127997398376]\n",
      "25th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.23481, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.23481\n",
      "\n",
      "Epoch 3: val_loss improved from 0.23481 to 0.20965, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.20965\n",
      "\n",
      "Epoch 5: val_loss improved from 0.20965 to 0.07353, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.07353\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.07353\n",
      "\n",
      "Epoch 8: val_loss improved from 0.07353 to 0.02223, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.02223\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.02223\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.02223\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.02223\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.02223\n",
      "Epoch 13: early stopping\n",
      "24-th combination = (True, False, True, 256, 7, 0.2) \n",
      " train accuracy: [0.1576492190361023, 0.3970506489276886] and test accuracy: [0.15466900169849396, 0.3932797908782959]\n",
      "26th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.10774, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.10774\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.10774\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.10774\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.10774\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.10774\n",
      "Epoch 6: early stopping\n",
      "25-th combination = (True, False, True, 256, 28, 0.2) \n",
      " train accuracy: [0.12371540814638138, 0.3517320156097412] and test accuracy: [0.1438433676958084, 0.3792668879032135]\n",
      "27th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.99088, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.99088 to 0.25864, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.25864 to 0.21238, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.21238\n",
      "\n",
      "Epoch 5: val_loss improved from 0.21238 to 0.14772, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.14772\n",
      "\n",
      "Epoch 7: val_loss improved from 0.14772 to 0.09420, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.09420\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.09420\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.09420\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.09420\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.09420\n",
      "Epoch 12: early stopping\n",
      "26-th combination = (True, False, True, 256, 365, 0.2) \n",
      " train accuracy: [0.06088436022400856, 0.24674756824970245] and test accuracy: [0.046313829720020294, 0.21520648896694183]\n",
      "28th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.71257, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.71257\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.71257\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.71257\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.71257\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.71257\n",
      "Epoch 6: early stopping\n",
      "27-th combination = (True, False, False, 64, 7, 0.2) \n",
      " train accuracy: [0.27565792202949524, 0.525031328201294] and test accuracy: [0.3970295190811157, 0.630102813243866]\n",
      "29th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.97494, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.97494\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.97494\n",
      "\n",
      "Epoch 4: val_loss improved from 0.97494 to 0.95630, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.95630\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.95630\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.95630\n",
      "\n",
      "Epoch 8: val_loss improved from 0.95630 to 0.90182, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.90182 to 0.86834, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.86834\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.86834\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.86834\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.86834\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.86834\n",
      "Epoch 14: early stopping\n",
      "28-th combination = (True, False, False, 64, 28, 0.2) \n",
      " train accuracy: [0.2981332540512085, 0.5460157990455627] and test accuracy: [0.47860631346702576, 0.6918137669563293]\n",
      "30th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.95404, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.95404\n",
      "\n",
      "Epoch 3: val_loss improved from 0.95404 to 0.79568, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.79568\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.79568\n",
      "\n",
      "Epoch 6: val_loss improved from 0.79568 to 0.77772, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.77772\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.77772\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.77772\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.77772\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.77772\n",
      "Epoch 11: early stopping\n",
      "29-th combination = (True, False, False, 64, 365, 0.2) \n",
      " train accuracy: [0.25360795855522156, 0.5035950541496277] and test accuracy: [0.2929675579071045, 0.5412647724151611]\n",
      "31th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.24561, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.24561\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.24561\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.24561\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.24561\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.24561\n",
      "Epoch 6: early stopping\n",
      "30-th combination = (True, False, False, 128, 7, 0.2) \n",
      " train accuracy: [0.40937381982803345, 0.6398232579231262] and test accuracy: [0.6123394966125488, 0.7825212478637695]\n",
      "32th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.29202, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.29202\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.29202\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.29202\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.29202\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.29202\n",
      "Epoch 6: early stopping\n",
      "31-th combination = (True, False, False, 128, 28, 0.2) \n",
      " train accuracy: [0.14081425964832306, 0.37525224685668945] and test accuracy: [0.17834320664405823, 0.42230701446533203]\n",
      "33th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.97524, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.97524 to 0.65223, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65223 to 0.47595, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.47595\n",
      "\n",
      "Epoch 5: val_loss improved from 0.47595 to 0.42293, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.42293\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.42293\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.42293\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.42293\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.42293\n",
      "Epoch 10: early stopping\n",
      "32-th combination = (True, False, False, 128, 365, 0.2) \n",
      " train accuracy: [0.14938227832317352, 0.3865000307559967] and test accuracy: [0.15828365087509155, 0.39784878492355347]\n",
      "34th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.13985, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.13985\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.13985\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.13985\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.13985\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.13985\n",
      "Epoch 6: early stopping\n",
      "33-th combination = (True, False, False, 256, 7, 0.2) \n",
      " train accuracy: [0.24545106291770935, 0.4954301714897156] and test accuracy: [0.317316472530365, 0.5633084774017334]\n",
      "35th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.08749, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.08749\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.08749\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.08749\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.08749\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.08749\n",
      "Epoch 6: early stopping\n",
      "34-th combination = (True, False, False, 256, 28, 0.2) \n",
      " train accuracy: [0.09245754033327103, 0.30406832695007324] and test accuracy: [0.1048625186085701, 0.32382482290267944]\n",
      "36th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.25701, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.25701 to 0.19167, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.19167\n",
      "\n",
      "Epoch 4: val_loss improved from 0.19167 to 0.12210, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.12210\n",
      "\n",
      "Epoch 6: val_loss improved from 0.12210 to 0.10483, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.10483 to 0.08595, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.08595\n",
      "\n",
      "Epoch 9: val_loss improved from 0.08595 to 0.07136, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.07136\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.07136\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.07136\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.07136\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.07136\n",
      "Epoch 14: early stopping\n",
      "35-th combination = (True, False, False, 256, 365, 0.2) \n",
      " train accuracy: [0.033113993704319, 0.18197250366210938] and test accuracy: [0.02119331806898117, 0.1455792486667633]\n",
      "37th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.79378, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.79378 to 0.63506, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.63506\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.63506\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.63506\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.63506\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.63506\n",
      "Epoch 7: early stopping\n",
      "36-th combination = (False, True, True, 64, 7, 0.2) \n",
      " train accuracy: [0.41295677423477173, 0.6426171064376831] and test accuracy: [0.659052848815918, 0.8118206858634949]\n",
      "38th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.18715, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.18715 to 1.17211, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.17211\n",
      "\n",
      "Epoch 4: val_loss improved from 1.17211 to 1.14061, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.14061\n",
      "\n",
      "Epoch 6: val_loss improved from 1.14061 to 1.11299, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.11299\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.11299\n",
      "\n",
      "Epoch 9: val_loss improved from 1.11299 to 0.99055, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.99055\n",
      "\n",
      "Epoch 11: val_loss improved from 0.99055 to 0.93719, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.93719\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.93719\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.93719\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.93719\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.93719\n",
      "Epoch 16: early stopping\n",
      "37-th combination = (False, True, True, 64, 28, 0.2) \n",
      " train accuracy: [0.32612845301628113, 0.5710765719413757] and test accuracy: [0.45865607261657715, 0.6772415041923523]\n",
      "39th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.93730, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.93730\n",
      "\n",
      "Epoch 3: val_loss improved from 0.93730 to 0.89801, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.89801\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.89801\n",
      "\n",
      "Epoch 6: val_loss improved from 0.89801 to 0.85856, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.85856\n",
      "\n",
      "Epoch 8: val_loss improved from 0.85856 to 0.85635, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.85635\n",
      "\n",
      "Epoch 10: val_loss improved from 0.85635 to 0.84927, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.84927\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.84927\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.84927\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.84927\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.84927\n",
      "Epoch 15: early stopping\n",
      "38-th combination = (False, True, True, 64, 365, 0.2) \n",
      " train accuracy: [0.27109211683273315, 0.5206650495529175] and test accuracy: [0.35721567273139954, 0.5976752042770386]\n",
      "40th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52397, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52397 to 0.50245, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.50245 to 0.49751, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49751\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49751\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49751\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49751\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49751\n",
      "Epoch 8: early stopping\n",
      "39-th combination = (False, True, True, 128, 7, 0.2) \n",
      " train accuracy: [0.3737275004386902, 0.6113325357437134] and test accuracy: [0.5877880454063416, 0.7666733860969543]\n",
      "41th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.31055, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.31055\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.31055\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.31055\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.31055\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.31055\n",
      "Epoch 6: early stopping\n",
      "40-th combination = (False, True, True, 128, 28, 0.2) \n",
      " train accuracy: [0.14036627113819122, 0.3746548593044281] and test accuracy: [0.17058993875980377, 0.4130253493785858]\n",
      "42th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.92792, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.92792 to 0.45142, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.45142\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45142 to 0.44459, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.44459 to 0.34517, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34517\n",
      "\n",
      "Epoch 7: val_loss improved from 0.34517 to 0.33419, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.33419\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.33419\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.33419\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.33419\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.33419\n",
      "Epoch 12: early stopping\n",
      "41-th combination = (False, True, True, 128, 365, 0.2) \n",
      " train accuracy: [0.13949374854564667, 0.3734886050224304] and test accuracy: [0.12108214944601059, 0.34796860814094543]\n",
      "43th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.05706, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.05706\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.05706\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.05706\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.05706\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05706\n",
      "Epoch 6: early stopping\n",
      "42-th combination = (False, True, True, 256, 7, 0.2) \n",
      " train accuracy: [0.21627087891101837, 0.4650493264198303] and test accuracy: [0.2699333727359772, 0.5195510983467102]\n",
      "44th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.09166, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.09166\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.09166\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.09166\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.09166\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.09166\n",
      "Epoch 6: early stopping\n",
      "43-th combination = (False, True, True, 256, 28, 0.2) \n",
      " train accuracy: [0.10619741678237915, 0.32587945461273193] and test accuracy: [0.13577678799629211, 0.36847901344299316]\n",
      "45th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.19777, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.19777 to 0.26555, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.26555\n",
      "\n",
      "Epoch 4: val_loss improved from 0.26555 to 0.19149, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.19149\n",
      "\n",
      "Epoch 6: val_loss improved from 0.19149 to 0.12646, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.12646\n",
      "\n",
      "Epoch 8: val_loss improved from 0.12646 to 0.11333, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.11333 to 0.07540, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.07540\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.07540\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.07540\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.07540\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.07540\n",
      "Epoch 14: early stopping\n",
      "44-th combination = (False, True, True, 256, 365, 0.2) \n",
      " train accuracy: [0.05637423321604729, 0.2374325841665268] and test accuracy: [0.04798191785812378, 0.21904775500297546]\n",
      "46th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.70196, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.70196 to 0.60103, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60103 to 0.51274, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51274\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51274\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51274\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51274\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51274\n",
      "Epoch 8: early stopping\n",
      "45-th combination = (False, True, False, 64, 7, 0.2) \n",
      " train accuracy: [0.48930731415748596, 0.6995050311088562] and test accuracy: [0.7227279543876648, 0.8501340746879578]\n",
      "47th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55512, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.55512\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.55512\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.55512\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55512\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.55512\n",
      "Epoch 6: early stopping\n",
      "46-th combination = (False, True, False, 64, 28, 0.2) \n",
      " train accuracy: [0.18745407462120056, 0.4329596757888794] and test accuracy: [0.2342284619808197, 0.4839715361595154]\n",
      "48th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.83416, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.83416\n",
      "\n",
      "Epoch 3: val_loss improved from 0.83416 to 0.74879, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.74879 to 0.68315, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.68315\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68315 to 0.67469, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.67469\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.67469\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.67469\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.67469\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.67469\n",
      "Epoch 11: early stopping\n",
      "47-th combination = (False, True, False, 64, 365, 0.2) \n",
      " train accuracy: [0.20948906242847443, 0.4576997458934784] and test accuracy: [0.22601823508739471, 0.4754137396812439]\n",
      "49th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.31487, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.31487 to 0.14958, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.14958 to 0.08552, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.08552\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.08552\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.08552\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.08552\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.08552\n",
      "Epoch 8: early stopping\n",
      "48-th combination = (False, True, False, 128, 7, 0.2) \n",
      " train accuracy: [0.20087815821170807, 0.44819432497024536] and test accuracy: [0.3035396635532379, 0.5509443283081055]\n",
      "50th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.24335, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.24335\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.24335\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.24335\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.24335\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.24335\n",
      "Epoch 6: early stopping\n",
      "49-th combination = (False, True, False, 128, 28, 0.2) \n",
      " train accuracy: [0.15502287447452545, 0.39372944831848145] and test accuracy: [0.19405940175056458, 0.4405217468738556]\n",
      "51th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.74196, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.74196 to 0.31648, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.31648\n",
      "\n",
      "Epoch 4: val_loss improved from 0.31648 to 0.25913, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.25913\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.25913\n",
      "\n",
      "Epoch 7: val_loss improved from 0.25913 to 0.25804, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.25804\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.25804\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.25804\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.25804\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.25804\n",
      "Epoch 12: early stopping\n",
      "50-th combination = (False, True, False, 128, 365, 0.2) \n",
      " train accuracy: [0.09836693853139877, 0.31363505125045776] and test accuracy: [0.08733237534761429, 0.29552051424980164]\n",
      "52th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.07517, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.07517\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.07517\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.07517\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.07517\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.07517\n",
      "Epoch 6: early stopping\n",
      "51-th combination = (False, True, False, 256, 7, 0.2) \n",
      " train accuracy: [0.3456503450870514, 0.5879203677177429] and test accuracy: [0.524048388004303, 0.7239118814468384]\n",
      "53th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.09366, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.09366\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.09366\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.09366\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.09366\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.09366\n",
      "Epoch 6: early stopping\n",
      "52-th combination = (False, True, False, 256, 28, 0.2) \n",
      " train accuracy: [0.08989614993333817, 0.29982686042785645] and test accuracy: [0.11393402516841888, 0.3375411331653595]\n",
      "54th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.22292, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.22292 to 0.17405, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.17405\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17405 to 0.17253, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.17253 to 0.13908, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.13908 to 0.12389, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.12389 to 0.09794, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.09794 to 0.08500, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.08500 to 0.07443, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.07443 to 0.06933, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.06933 to 0.06826, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.06826 to 0.06548, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.06548\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.06548\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06548\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.06548\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.06548\n",
      "Epoch 17: early stopping\n",
      "53-th combination = (False, True, False, 256, 365, 0.2) \n",
      " train accuracy: [0.03401005268096924, 0.18441814184188843] and test accuracy: [0.02544267848134041, 0.159507617354393]\n",
      "55th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.21283, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.21283 to 0.19589, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.19589 to 0.12748, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.12748\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.12748\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.12748\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.12748\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.12748\n",
      "Epoch 8: early stopping\n",
      "54-th combination = (False, False, True, 64, 7, 0.2) \n",
      " train accuracy: [0.26164957880973816, 0.5115169286727905] and test accuracy: [0.40338969230651855, 0.6351296901702881]\n",
      "56th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.36187, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.36187\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.36187\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.36187\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.36187\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.36187\n",
      "Epoch 6: early stopping\n",
      "55-th combination = (False, False, True, 64, 28, 0.2) \n",
      " train accuracy: [0.14443093538284302, 0.38004070520401] and test accuracy: [0.172869011759758, 0.4157751798629761]\n",
      "57th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56921, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.56921\n",
      "\n",
      "Epoch 3: val_loss improved from 0.56921 to 0.53526, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53526 to 0.35362, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.35362\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.35362\n",
      "\n",
      "Epoch 7: val_loss improved from 0.35362 to 0.32102, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.32102\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.32102\n",
      "\n",
      "Epoch 10: val_loss improved from 0.32102 to 0.31254, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.31254\n",
      "\n",
      "Epoch 12: val_loss improved from 0.31254 to 0.29490, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.29490\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.29490\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.29490\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.29490\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.29490\n",
      "Epoch 17: early stopping\n",
      "56-th combination = (False, False, True, 64, 365, 0.2) \n",
      " train accuracy: [0.09217105805873871, 0.3035968542098999] and test accuracy: [0.08741123229265213, 0.29565390944480896]\n",
      "58th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.08018, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.08018\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.08018\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.08018\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.08018\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.08018\n",
      "Epoch 6: early stopping\n",
      "57-th combination = (False, False, True, 128, 7, 0.2) \n",
      " train accuracy: [0.1906217783689499, 0.43660253286361694] and test accuracy: [0.2394973635673523, 0.4893846809864044]\n",
      "59th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.10181, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.10181\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.10181\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.10181\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.10181\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.10181\n",
      "Epoch 6: early stopping\n",
      "58-th combination = (False, False, True, 128, 28, 0.2) \n",
      " train accuracy: [0.06988160312175751, 0.2643512785434723] and test accuracy: [0.06754418462514877, 0.25989264249801636]\n",
      "60th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53734, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.53734 to 0.19195, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.19195\n",
      "\n",
      "Epoch 4: val_loss improved from 0.19195 to 0.15861, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.15861\n",
      "\n",
      "Epoch 6: val_loss improved from 0.15861 to 0.14136, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.14136 to 0.12589, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.12589 to 0.11540, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.11540 to 0.10886, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.10886 to 0.09062, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.09062\n",
      "\n",
      "Epoch 12: val_loss improved from 0.09062 to 0.08554, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.08554 to 0.08471, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.08471\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.08471\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.08471\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.08471\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.08471\n",
      "Epoch 18: early stopping\n",
      "59-th combination = (False, False, True, 128, 365, 0.2) \n",
      " train accuracy: [0.04087983816862106, 0.20218762755393982] and test accuracy: [0.03583782538771629, 0.18930880725383759]\n",
      "61th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.03706, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.03706 to 0.02395, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.02395\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.02395\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.02395\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.02395\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.02395\n",
      "Epoch 7: early stopping\n",
      "60-th combination = (False, False, True, 256, 7, 0.2) \n",
      " train accuracy: [0.17306502163410187, 0.41601085662841797] and test accuracy: [0.282850444316864, 0.5318368673324585]\n",
      "62th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.03902, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.03902\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.03902\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.03902\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.03902\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.03902\n",
      "Epoch 6: early stopping\n",
      "61-th combination = (False, False, True, 256, 28, 0.2) \n",
      " train accuracy: [0.05057164654135704, 0.22488141059875488] and test accuracy: [0.0582900233566761, 0.2414332628250122]\n",
      "63th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.06773, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.06773 to 0.13658, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.13658\n",
      "\n",
      "Epoch 4: val_loss improved from 0.13658 to 0.09961, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.09961 to 0.09421, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.09421 to 0.07988, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.07988 to 0.06100, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.06100 to 0.04794, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.04794\n",
      "\n",
      "Epoch 10: val_loss improved from 0.04794 to 0.04434, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.04434\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.04434\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.04434\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.04434\n",
      "\n",
      "Epoch 15: val_loss improved from 0.04434 to 0.03675, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.03675 to 0.03516, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.03516 to 0.03438, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.03438\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.03438\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.03438\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.03438\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.03438\n",
      "Epoch 22: early stopping\n",
      "62-th combination = (False, False, True, 256, 365, 0.2) \n",
      " train accuracy: [0.014666862785816193, 0.1211068257689476] and test accuracy: [0.010346831753849983, 0.10171937942504883]\n",
      "64th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54935, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54935 to 0.53305, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53305 to 0.38022, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.38022 to 0.37245, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.37245 to 0.33526, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.33526\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.33526\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.33526\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.33526\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.33526\n",
      "Epoch 10: early stopping\n",
      "63-th combination = (False, False, False, 64, 7, 0.2) \n",
      " train accuracy: [0.14824886620044708, 0.38503098487854004] and test accuracy: [0.23339368402957916, 0.4831083416938782]\n",
      "65th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55937, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.55937\n",
      "Epoch 6: early stopping\n",
      "64-th combination = (False, False, False, 64, 28, 0.2) \n",
      " train accuracy: [0.1767307072877884, 0.42039352655410767] and test accuracy: [0.2036973237991333, 0.4513283967971802]\n",
      "66th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66904, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.66904\n",
      "\n",
      "Epoch 3: val_loss improved from 0.66904 to 0.63034, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.63034 to 0.48453, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.48453\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.48453\n",
      "\n",
      "Epoch 7: val_loss improved from 0.48453 to 0.45844, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.45844\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.45844\n",
      "\n",
      "Epoch 10: val_loss improved from 0.45844 to 0.44187, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.44187\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.44187\n",
      "\n",
      "Epoch 13: val_loss improved from 0.44187 to 0.44105, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.44105 to 0.43763, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.43763 to 0.43715, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.43715 to 0.43665, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.43665 to 0.42711, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.42711\n",
      "\n",
      "Epoch 19: val_loss improved from 0.42711 to 0.42365, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.42365\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.42365\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.42365\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.42365\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.42365\n",
      "Epoch 24: early stopping\n",
      "65-th combination = (False, False, False, 64, 365, 0.2) \n",
      " train accuracy: [0.13334962725639343, 0.3651706874370575] and test accuracy: [0.14656512439250946, 0.38283824920654297]\n",
      "67th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.10136, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.10136 to 0.03857, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.03857\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.03857\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.03857\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.03857\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.03857\n",
      "Epoch 7: early stopping\n",
      "66-th combination = (False, False, False, 128, 7, 0.2) \n",
      " train accuracy: [0.09879235923290253, 0.31431251764297485] and test accuracy: [0.11160265654325485, 0.3340698480606079]\n",
      "68th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.18127, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.18127\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.18127\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.18127\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.18127\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.18127\n",
      "Epoch 6: early stopping\n",
      "67-th combination = (False, False, False, 128, 28, 0.2) \n",
      " train accuracy: [0.08090408146381378, 0.28443643450737] and test accuracy: [0.0814143493771553, 0.28533199429512024]\n",
      "69th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.40539, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.40539 to 0.39929, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.39929 to 0.17052, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.17052\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.17052\n",
      "\n",
      "Epoch 6: val_loss improved from 0.17052 to 0.13245, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.13245\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.13245\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.13245\n",
      "\n",
      "Epoch 10: val_loss improved from 0.13245 to 0.13040, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.13040 to 0.12570, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.12570\n",
      "Epoch 16: early stopping\n",
      "68-th combination = (False, False, False, 128, 365, 0.2) \n",
      " train accuracy: [0.04319595918059349, 0.20783637464046478] and test accuracy: [0.03593405708670616, 0.1895628124475479]\n",
      "70th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.03491, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.03491 to 0.02839, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.02839\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.02839\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.02839\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.02839\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.02839\n",
      "Epoch 7: early stopping\n",
      "69-th combination = (False, False, False, 256, 7, 0.2) \n",
      " train accuracy: [0.21223171055316925, 0.4606861174106598] and test accuracy: [0.29929065704345703, 0.5470746159553528]\n",
      "71th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.03473, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.03473\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.03473\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.03473\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.03473\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.03473\n",
      "Epoch 6: early stopping\n",
      "70-th combination = (False, False, False, 256, 28, 0.2) \n",
      " train accuracy: [0.028091616928577423, 0.16760553419589996] and test accuracy: [0.02491089515388012, 0.15783186256885529]\n",
      "72th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54591, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54591 to 0.09937, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.09937\n",
      "\n",
      "Epoch 4: val_loss improved from 0.09937 to 0.08549, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.08549 to 0.07655, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.07655 to 0.05977, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.05977 to 0.04700, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.04700 to 0.03999, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.03999 to 0.03555, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.03555 to 0.03279, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.03279 to 0.03175, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.03175 to 0.03165, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.03165\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.03165\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.03165\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.03165\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.03165\n",
      "Epoch 17: early stopping\n",
      "71-th combination = (False, False, False, 256, 365, 0.2) \n",
      " train accuracy: [0.012978555634617805, 0.11392346024513245] and test accuracy: [0.00913596898317337, 0.0955822616815567]\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    [True, False],\n",
    "    [True, False],\n",
    "    [True, False],\n",
    "    [64, 128, 256],\n",
    "    [7, 28,365],\n",
    "    [0.2],\n",
    "]\n",
    "\n",
    "# list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n",
    "\n",
    "hist = LSTM_HyperParameter_Tuning(\n",
    "    config, X_train, y_train, X_test, y_test\n",
    ")  # change x_train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.012978555634617805, 0.11392346024513245]</td>\n",
       "      <td>[0.00913596898317337, 0.0955822616815567]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.014666862785816193, 0.1211068257689476]</td>\n",
       "      <td>[0.010346831753849983, 0.10171937942504883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.033113993704319, 0.18197250366210938]</td>\n",
       "      <td>[0.02119331806898117, 0.1455792486667633]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.028091616928577423, 0.16760553419589996]</td>\n",
       "      <td>[0.02491089515388012, 0.15783186256885529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.03401005268096924, 0.18441814184188843]</td>\n",
       "      <td>[0.02544267848134041, 0.159507617354393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.48930731415748596, 0.6995050311088562]</td>\n",
       "      <td>[0.7227279543876648, 0.8501340746879578]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.4566420614719391, 0.6757529377937317]</td>\n",
       "      <td>[0.7539973258972168, 0.868330180644989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.502824604511261, 0.7091012597084045]</td>\n",
       "      <td>[0.8482761979103088, 0.9210191369056702]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.5017463564872742, 0.708340585231781]</td>\n",
       "      <td>[0.8513628840446472, 0.9226932525634766]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.6468409895896912, 0.80426424741745]</td>\n",
       "      <td>[0.9807345271110535, 0.9903204441070557]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2    3    4    5  \\\n",
       "71  False  False  False  256  365  0.2   \n",
       "62  False  False   True  256  365  0.2   \n",
       "35   True  False  False  256  365  0.2   \n",
       "70  False  False  False  256   28  0.2   \n",
       "53  False   True  False  256  365  0.2   \n",
       "..    ...    ...    ...  ...  ...  ...   \n",
       "45  False   True  False   64    7  0.2   \n",
       "9    True   True  False   64    7  0.2   \n",
       "15   True   True  False  256    7  0.2   \n",
       "0    True   True   True   64    7  0.2   \n",
       "6    True   True   True  256    7  0.2   \n",
       "\n",
       "                                              6  \\\n",
       "71  [0.012978555634617805, 0.11392346024513245]   \n",
       "62   [0.014666862785816193, 0.1211068257689476]   \n",
       "35     [0.033113993704319, 0.18197250366210938]   \n",
       "70  [0.028091616928577423, 0.16760553419589996]   \n",
       "53   [0.03401005268096924, 0.18441814184188843]   \n",
       "..                                          ...   \n",
       "45    [0.48930731415748596, 0.6995050311088562]   \n",
       "9      [0.4566420614719391, 0.6757529377937317]   \n",
       "15      [0.502824604511261, 0.7091012597084045]   \n",
       "0       [0.5017463564872742, 0.708340585231781]   \n",
       "6        [0.6468409895896912, 0.80426424741745]   \n",
       "\n",
       "                                              7  \n",
       "71    [0.00913596898317337, 0.0955822616815567]  \n",
       "62  [0.010346831753849983, 0.10171937942504883]  \n",
       "35    [0.02119331806898117, 0.1455792486667633]  \n",
       "70   [0.02491089515388012, 0.15783186256885529]  \n",
       "53     [0.02544267848134041, 0.159507617354393]  \n",
       "..                                          ...  \n",
       "45     [0.7227279543876648, 0.8501340746879578]  \n",
       "9       [0.7539973258972168, 0.868330180644989]  \n",
       "15     [0.8482761979103088, 0.9210191369056702]  \n",
       "0      [0.8513628840446472, 0.9226932525634766]  \n",
       "6      [0.9807345271110535, 0.9903204441070557]  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(hist)\n",
    "hist = hist.sort_values(by=[7], ascending=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination: \n",
      " first_additional_layer = False\n",
      " second_additional_layer = False\n",
      " third_additional_layer = False\n",
      " n_neurons = 256\n",
      " n_batch_size = 365\n",
      " dropout = 0.2\n",
      "**************************\n",
      "Results Before Tunning:\n",
      " Test Set RMSE: 0.8765\n",
      "\n",
      "Results After Tunning:\n",
      " Test Set RMSE: 0.0956\n",
      "\n",
      "89.0% Improvement\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}\"\n",
    ")\n",
    "print(\"**************************\")\n",
    "print(f\"Results Before Tunning:\\n Test Set RMSE: {np.round(results, 4)[1]}\\n\")\n",
    "print(f\"Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)[1]}\\n\")\n",
    "print(\n",
    "    f\"{np.round((results[1] - hist.iloc[0, -1][1])*100/np.round(results, 4)[1])}% Improvement\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    first_additional_layer,\n",
    "    second_additional_layer,\n",
    "    third_additional_layer,\n",
    "    n_neurons,\n",
    "    n_batch_size,\n",
    "    dropout,\n",
    ") = list(hist.iloc[0, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61707, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuell/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.61707 to 0.11909, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.11909 to 0.11402, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.11402 to 0.10899, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.10899 to 0.07427, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.07427 to 0.06631, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.06631 to 0.05341, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.05341 to 0.04540, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.04540 to 0.04236, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.04236 to 0.03547, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.03547 to 0.03292, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.03292 to 0.03127, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.03127 to 0.03092, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.03092\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.03092\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.03092\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.03092\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.03092\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7567d665e8c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(\n",
    "    LSTM(\n",
    "        units=n_neurons,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    )\n",
    ")\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "if first_additional_layer:\n",
    "    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "if second_additional_layer:\n",
    "    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "if third_additional_layer:\n",
    "    regressor.add(GRU(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "regressor.add(Dropout(dropout))\n",
    "regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "regressor.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\")\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "\n",
    "file_path = \"best_model.h5\"\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    file_path, monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True\n",
    ")\n",
    "\n",
    "regressor.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=200,\n",
    "    batch_size=n_batch_size,\n",
    "    callbacks=[es, mc],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 66ms/step - loss: 0.0087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008658326230943203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1333.33x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df[[target_column]])\n",
    "y_pred = regressor.predict(X_test)\n",
    "unscaled_y_pred = scaler.inverse_transform([y_pred.flatten()])[0]\n",
    "unscaled_y_test = scaler.inverse_transform([y_test.flatten()])[0]\n",
    "unscaled_y_train = scaler.inverse_transform([y_train.flatten()])[0]\n",
    "\n",
    "data_length = len(unscaled_y_test)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1280 / 96, 720 / 96))\n",
    "ax.plot(dates[-data_length:], unscaled_y_test, label=\"actual\")\n",
    "ax.plot(dates[-data_length:], unscaled_y_pred, label=\"prediction\")\n",
    "ax.set_title(\"Prediction LSTM\")\n",
    "ax.set_ylabel(\"Closed\")\n",
    "ax.set_xlabel(date_column)\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "MSE: 2317645.61\n",
      "RMSE: 1522.38\n",
      "MAE: 1084.63\n",
      "MAPE: 3.46\n",
      "SMAPE: 3.52\n",
      "MASE: 2.98\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_metrics(unscaled_y_pred, unscaled_y_test, unscaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(regressor, \"lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related urls, will remove once finished:\n",
    "- https://www.tensorflow.org/tutorials/structured_data/time_series#multi-step_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 13:45:07.847372: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-25 13:45:08.007920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-25 13:45:08.007996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-25 13:45:08.029470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-25 13:45:08.073105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 13:45:09.327370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/WHO-COVID-19-global-data.csv\"\n",
    "date_column = \"Date_reported\"\n",
    "target_column = \"New_deaths\"\n",
    "df = pd.read_csv(file_path, parse_dates=True)\n",
    "df = df[[date_column, target_column, \"New_cases\", \"Cumulative_cases\"]]\n",
    "df = df.groupby(date_column).sum().reset_index()\n",
    "df = df.dropna()\n",
    "date_time = pd.to_datetime(df.pop(date_column), format=\"%Y-%m-%d\")\n",
    "df.set_index(date_time, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure (it does not work when you have only one feature)\n",
    "def create_data(\n",
    "    df, n_future, n_past, train_test_split_percentage, validation_split_percentage\n",
    "):\n",
    "    n_feature = df.shape[1]\n",
    "    x_data, y_data = [], []\n",
    "\n",
    "    for i in range(n_past, len(df) - n_future + 1):\n",
    "        x_data.append(df[i - n_past : i, 0:n_feature])\n",
    "        y_data.append(df[i + n_future - 1 : i + n_future, 0])\n",
    "\n",
    "    split_training_test_starting_point = int(\n",
    "        round(train_test_split_percentage * len(x_data))\n",
    "    )\n",
    "    split_train_validation_starting_point = int(\n",
    "        round(split_training_test_starting_point * (1 - validation_split_percentage))\n",
    "    )\n",
    "\n",
    "    x_train = x_data[:split_train_validation_starting_point]\n",
    "    y_train = y_data[:split_train_validation_starting_point]\n",
    "\n",
    "    # if you want to choose the validation set by yourself, uncomment the below code.\n",
    "    x_val = x_data[\n",
    "        split_train_validation_starting_point:split_training_test_starting_point\n",
    "    ]\n",
    "    y_val = x_data[\n",
    "        split_train_validation_starting_point:split_training_test_starting_point\n",
    "    ]\n",
    "\n",
    "    x_test = x_data[split_training_test_starting_point:]\n",
    "    y_test = y_data[split_training_test_starting_point:]\n",
    "\n",
    "    return (\n",
    "        np.array(x_train),\n",
    "        np.array(x_test),\n",
    "        np.array(x_val),\n",
    "        np.array(y_train),\n",
    "        np.array(y_test),\n",
    "        np.array(y_val),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days you want to predict into the future\n",
    "# Number of past days you want to use to predict the future\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = create_data(\n",
    "    scaled_data,\n",
    "    n_future=1,\n",
    "    n_past=25,\n",
    "    train_test_split_percentage=0.8,\n",
    "    validation_split_percentage=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1116, 25, 3)\n",
      "(279, 25, 3)\n",
      "(1116, 1)\n",
      "(279, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 25, 16)            1280      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 16)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3409 (13.32 KB)\n",
      "Trainable params: 3409 (13.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------------LSTM-----------------------\n",
    "regressor = Sequential()\n",
    "regressor.add(\n",
    "    LSTM(\n",
    "        units=16,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    )\n",
    ")\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=16, return_sequences=False))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "regressor.compile(\n",
    "    optimizer=\"adam\", loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "13/13 [==============================] - 5s 85ms/step - loss: 0.8061 - root_mean_squared_error: 0.8978 - val_loss: 0.7940 - val_root_mean_squared_error: 0.8910\n",
      "Epoch 2/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.4826 - root_mean_squared_error: 0.6947 - val_loss: 0.7181 - val_root_mean_squared_error: 0.8474\n",
      "Epoch 3/40\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4105 - root_mean_squared_error: 0.6407 - val_loss: 0.7461 - val_root_mean_squared_error: 0.8638\n",
      "Epoch 4/40\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4277 - root_mean_squared_error: 0.6540 - val_loss: 0.7252 - val_root_mean_squared_error: 0.8516\n",
      "Epoch 5/40\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4103 - root_mean_squared_error: 0.6405 - val_loss: 0.7081 - val_root_mean_squared_error: 0.8415\n",
      "Epoch 6/40\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4289 - root_mean_squared_error: 0.6549 - val_loss: 0.7093 - val_root_mean_squared_error: 0.8422\n",
      "Epoch 7/40\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3870 - root_mean_squared_error: 0.6221 - val_loss: 0.6673 - val_root_mean_squared_error: 0.8169\n",
      "Epoch 8/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3978 - root_mean_squared_error: 0.6307 - val_loss: 0.6335 - val_root_mean_squared_error: 0.7959\n",
      "Epoch 9/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3935 - root_mean_squared_error: 0.6273 - val_loss: 0.6149 - val_root_mean_squared_error: 0.7841\n",
      "Epoch 10/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3777 - root_mean_squared_error: 0.6146 - val_loss: 0.6107 - val_root_mean_squared_error: 0.7814\n",
      "Epoch 11/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3886 - root_mean_squared_error: 0.6233 - val_loss: 0.6082 - val_root_mean_squared_error: 0.7799\n",
      "Epoch 12/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3886 - root_mean_squared_error: 0.6233 - val_loss: 0.5893 - val_root_mean_squared_error: 0.7677\n",
      "Epoch 13/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3887 - root_mean_squared_error: 0.6234 - val_loss: 0.5862 - val_root_mean_squared_error: 0.7657\n",
      "Epoch 14/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3752 - root_mean_squared_error: 0.6126 - val_loss: 0.5967 - val_root_mean_squared_error: 0.7724\n",
      "Epoch 15/40\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3642 - root_mean_squared_error: 0.6035 - val_loss: 0.5966 - val_root_mean_squared_error: 0.7724\n",
      "Epoch 16/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3716 - root_mean_squared_error: 0.6096 - val_loss: 0.5740 - val_root_mean_squared_error: 0.7576\n",
      "Epoch 17/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3677 - root_mean_squared_error: 0.6064 - val_loss: 0.5777 - val_root_mean_squared_error: 0.7601\n",
      "Epoch 18/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3838 - root_mean_squared_error: 0.6195 - val_loss: 0.5756 - val_root_mean_squared_error: 0.7587\n",
      "Epoch 19/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3742 - root_mean_squared_error: 0.6117 - val_loss: 0.5799 - val_root_mean_squared_error: 0.7615\n",
      "Epoch 20/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3625 - root_mean_squared_error: 0.6021 - val_loss: 0.5797 - val_root_mean_squared_error: 0.7614\n",
      "Epoch 21/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3928 - root_mean_squared_error: 0.6267 - val_loss: 0.5729 - val_root_mean_squared_error: 0.7569\n",
      "Epoch 22/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3722 - root_mean_squared_error: 0.6101 - val_loss: 0.5667 - val_root_mean_squared_error: 0.7528\n",
      "Epoch 23/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3839 - root_mean_squared_error: 0.6196 - val_loss: 0.5691 - val_root_mean_squared_error: 0.7544\n",
      "Epoch 24/40\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.3759 - root_mean_squared_error: 0.6131 - val_loss: 0.5666 - val_root_mean_squared_error: 0.7528\n",
      "Epoch 25/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3653 - root_mean_squared_error: 0.6044 - val_loss: 0.5661 - val_root_mean_squared_error: 0.7524\n",
      "Epoch 26/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3634 - root_mean_squared_error: 0.6028 - val_loss: 0.5554 - val_root_mean_squared_error: 0.7453\n",
      "Epoch 27/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3569 - root_mean_squared_error: 0.5974 - val_loss: 0.5565 - val_root_mean_squared_error: 0.7460\n",
      "Epoch 28/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3635 - root_mean_squared_error: 0.6029 - val_loss: 0.5591 - val_root_mean_squared_error: 0.7477\n",
      "Epoch 29/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3645 - root_mean_squared_error: 0.6038 - val_loss: 0.5696 - val_root_mean_squared_error: 0.7547\n",
      "Epoch 30/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3645 - root_mean_squared_error: 0.6037 - val_loss: 0.5427 - val_root_mean_squared_error: 0.7367\n",
      "Epoch 31/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3595 - root_mean_squared_error: 0.5995 - val_loss: 0.5450 - val_root_mean_squared_error: 0.7382\n",
      "Epoch 32/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3502 - root_mean_squared_error: 0.5917 - val_loss: 0.5425 - val_root_mean_squared_error: 0.7365\n",
      "Epoch 33/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3672 - root_mean_squared_error: 0.6060 - val_loss: 0.5435 - val_root_mean_squared_error: 0.7372\n",
      "Epoch 34/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3524 - root_mean_squared_error: 0.5936 - val_loss: 0.5486 - val_root_mean_squared_error: 0.7407\n",
      "Epoch 35/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3540 - root_mean_squared_error: 0.5950 - val_loss: 0.5349 - val_root_mean_squared_error: 0.7314\n",
      "Epoch 36/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3453 - root_mean_squared_error: 0.5876 - val_loss: 0.5409 - val_root_mean_squared_error: 0.7354\n",
      "Epoch 37/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3535 - root_mean_squared_error: 0.5946 - val_loss: 0.5367 - val_root_mean_squared_error: 0.7326\n",
      "Epoch 38/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3606 - root_mean_squared_error: 0.6005 - val_loss: 0.5297 - val_root_mean_squared_error: 0.7278\n",
      "Epoch 39/40\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3505 - root_mean_squared_error: 0.5920 - val_loss: 0.5448 - val_root_mean_squared_error: 0.7381\n",
      "Epoch 40/40\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3638 - root_mean_squared_error: 0.6032 - val_loss: 0.5403 - val_root_mean_squared_error: 0.7351\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "# mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "history = regressor.fit(\n",
    "    X_train, y_train, validation_split=0.3, epochs=40, batch_size=64, callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'root_mean_squared_error', 'val_loss', 'val_root_mean_squared_error'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "fig.add_subplot(121)\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history.epoch, history.history[\"root_mean_squared_error\"], label=\"rmse\")\n",
    "plt.plot(\n",
    "    history.epoch, history.history[\"val_root_mean_squared_error\"], label=\"val_rmse\"\n",
    ")\n",
    "\n",
    "plt.title(\"RMSE\", fontsize=18)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"RMSE\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Adding Subplot 1 (For Loss)\n",
    "fig.add_subplot(122)\n",
    "\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "plt.title(\"Loss\", fontsize=18)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1545 - root_mean_squared_error: 0.3931\n",
      "test loss, test acc: [0.1545 0.3931]\n"
     ]
    }
   ],
   "source": [
    "results = regressor.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", np.round(results, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, x_train, y_train, x_test, y_test):\n",
    "    (\n",
    "        first_additional_layer,\n",
    "        second_additional_layer,\n",
    "        third_additional_layer,\n",
    "        n_neurons,\n",
    "        n_batch_size,\n",
    "        dropout,\n",
    "    ) = config\n",
    "    possible_combinations = list(\n",
    "        itertools.product(\n",
    "            first_additional_layer,\n",
    "            second_additional_layer,\n",
    "            third_additional_layer,\n",
    "            n_neurons,\n",
    "            n_batch_size,\n",
    "            dropout,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(possible_combinations)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hist = []\n",
    "\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f\"{i+1}th combination: \\n\")\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "        (\n",
    "            first_additional_layer,\n",
    "            second_additional_layer,\n",
    "            third_additional_layer,\n",
    "            n_neurons,\n",
    "            n_batch_size,\n",
    "            dropout,\n",
    "        ) = possible_combinations[i]\n",
    "\n",
    "        # instantiating the model in the strategy scope creates the model on the TPU\n",
    "        # with tpu_strategy.scope():\n",
    "        regressor = Sequential()\n",
    "        regressor.add(\n",
    "            LSTM(\n",
    "                units=n_neurons,\n",
    "                return_sequences=True,\n",
    "                input_shape=(x_train.shape[1], x_train.shape[2]),\n",
    "            )\n",
    "        )\n",
    "        regressor.add(Dropout(dropout))\n",
    "\n",
    "        if first_additional_layer:\n",
    "            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        if second_additional_layer:\n",
    "            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        if third_additional_layer:\n",
    "            regressor.add(GRU(units=n_neurons, return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "\n",
    "        regressor.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "        regressor.add(Dropout(dropout))\n",
    "        regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "        regressor.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "        \"\"\"''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        \"\"\" \"\"\n",
    "\n",
    "        file_path = \"best_model.h5\"\n",
    "\n",
    "        mc = ModelCheckpoint(\n",
    "            file_path, monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True\n",
    "        )\n",
    "\n",
    "        \"\"\"''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        \"\"\" \"\"\n",
    "\n",
    "        regressor.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            validation_split=0.3,\n",
    "            epochs=100,\n",
    "            batch_size=n_batch_size,\n",
    "            callbacks=[es, mc],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # load the best model\n",
    "        # regressor = load_model('best_model.h5')\n",
    "\n",
    "        train_accuracy = regressor.evaluate(x_train, y_train, verbose=0)\n",
    "        test_accuracy = regressor.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "        hist.append(\n",
    "            list(\n",
    "                (\n",
    "                    first_additional_layer,\n",
    "                    second_additional_layer,\n",
    "                    third_additional_layer,\n",
    "                    n_neurons,\n",
    "                    n_batch_size,\n",
    "                    dropout,\n",
    "                    train_accuracy,\n",
    "                    test_accuracy,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}\"\n",
    "        )\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(True, True, True, 16, 7, 0.2), (True, True, True, 16, 28, 0.2), (True, True, True, 16, 21, 0.2), (True, True, True, 16, 84, 0.2), (True, True, True, 16, 365, 0.2), (True, True, True, 32, 7, 0.2), (True, True, True, 32, 28, 0.2), (True, True, True, 32, 21, 0.2), (True, True, True, 32, 84, 0.2), (True, True, True, 32, 365, 0.2), (True, True, True, 64, 7, 0.2), (True, True, True, 64, 28, 0.2), (True, True, True, 64, 21, 0.2), (True, True, True, 64, 84, 0.2), (True, True, True, 64, 365, 0.2), (True, True, True, 128, 7, 0.2), (True, True, True, 128, 28, 0.2), (True, True, True, 128, 21, 0.2), (True, True, True, 128, 84, 0.2), (True, True, True, 128, 365, 0.2), (True, True, True, 256, 7, 0.2), (True, True, True, 256, 28, 0.2), (True, True, True, 256, 21, 0.2), (True, True, True, 256, 84, 0.2), (True, True, True, 256, 365, 0.2), (True, True, False, 16, 7, 0.2), (True, True, False, 16, 28, 0.2), (True, True, False, 16, 21, 0.2), (True, True, False, 16, 84, 0.2), (True, True, False, 16, 365, 0.2), (True, True, False, 32, 7, 0.2), (True, True, False, 32, 28, 0.2), (True, True, False, 32, 21, 0.2), (True, True, False, 32, 84, 0.2), (True, True, False, 32, 365, 0.2), (True, True, False, 64, 7, 0.2), (True, True, False, 64, 28, 0.2), (True, True, False, 64, 21, 0.2), (True, True, False, 64, 84, 0.2), (True, True, False, 64, 365, 0.2), (True, True, False, 128, 7, 0.2), (True, True, False, 128, 28, 0.2), (True, True, False, 128, 21, 0.2), (True, True, False, 128, 84, 0.2), (True, True, False, 128, 365, 0.2), (True, True, False, 256, 7, 0.2), (True, True, False, 256, 28, 0.2), (True, True, False, 256, 21, 0.2), (True, True, False, 256, 84, 0.2), (True, True, False, 256, 365, 0.2), (True, False, True, 16, 7, 0.2), (True, False, True, 16, 28, 0.2), (True, False, True, 16, 21, 0.2), (True, False, True, 16, 84, 0.2), (True, False, True, 16, 365, 0.2), (True, False, True, 32, 7, 0.2), (True, False, True, 32, 28, 0.2), (True, False, True, 32, 21, 0.2), (True, False, True, 32, 84, 0.2), (True, False, True, 32, 365, 0.2), (True, False, True, 64, 7, 0.2), (True, False, True, 64, 28, 0.2), (True, False, True, 64, 21, 0.2), (True, False, True, 64, 84, 0.2), (True, False, True, 64, 365, 0.2), (True, False, True, 128, 7, 0.2), (True, False, True, 128, 28, 0.2), (True, False, True, 128, 21, 0.2), (True, False, True, 128, 84, 0.2), (True, False, True, 128, 365, 0.2), (True, False, True, 256, 7, 0.2), (True, False, True, 256, 28, 0.2), (True, False, True, 256, 21, 0.2), (True, False, True, 256, 84, 0.2), (True, False, True, 256, 365, 0.2), (True, False, False, 16, 7, 0.2), (True, False, False, 16, 28, 0.2), (True, False, False, 16, 21, 0.2), (True, False, False, 16, 84, 0.2), (True, False, False, 16, 365, 0.2), (True, False, False, 32, 7, 0.2), (True, False, False, 32, 28, 0.2), (True, False, False, 32, 21, 0.2), (True, False, False, 32, 84, 0.2), (True, False, False, 32, 365, 0.2), (True, False, False, 64, 7, 0.2), (True, False, False, 64, 28, 0.2), (True, False, False, 64, 21, 0.2), (True, False, False, 64, 84, 0.2), (True, False, False, 64, 365, 0.2), (True, False, False, 128, 7, 0.2), (True, False, False, 128, 28, 0.2), (True, False, False, 128, 21, 0.2), (True, False, False, 128, 84, 0.2), (True, False, False, 128, 365, 0.2), (True, False, False, 256, 7, 0.2), (True, False, False, 256, 28, 0.2), (True, False, False, 256, 21, 0.2), (True, False, False, 256, 84, 0.2), (True, False, False, 256, 365, 0.2), (False, True, True, 16, 7, 0.2), (False, True, True, 16, 28, 0.2), (False, True, True, 16, 21, 0.2), (False, True, True, 16, 84, 0.2), (False, True, True, 16, 365, 0.2), (False, True, True, 32, 7, 0.2), (False, True, True, 32, 28, 0.2), (False, True, True, 32, 21, 0.2), (False, True, True, 32, 84, 0.2), (False, True, True, 32, 365, 0.2), (False, True, True, 64, 7, 0.2), (False, True, True, 64, 28, 0.2), (False, True, True, 64, 21, 0.2), (False, True, True, 64, 84, 0.2), (False, True, True, 64, 365, 0.2), (False, True, True, 128, 7, 0.2), (False, True, True, 128, 28, 0.2), (False, True, True, 128, 21, 0.2), (False, True, True, 128, 84, 0.2), (False, True, True, 128, 365, 0.2), (False, True, True, 256, 7, 0.2), (False, True, True, 256, 28, 0.2), (False, True, True, 256, 21, 0.2), (False, True, True, 256, 84, 0.2), (False, True, True, 256, 365, 0.2), (False, True, False, 16, 7, 0.2), (False, True, False, 16, 28, 0.2), (False, True, False, 16, 21, 0.2), (False, True, False, 16, 84, 0.2), (False, True, False, 16, 365, 0.2), (False, True, False, 32, 7, 0.2), (False, True, False, 32, 28, 0.2), (False, True, False, 32, 21, 0.2), (False, True, False, 32, 84, 0.2), (False, True, False, 32, 365, 0.2), (False, True, False, 64, 7, 0.2), (False, True, False, 64, 28, 0.2), (False, True, False, 64, 21, 0.2), (False, True, False, 64, 84, 0.2), (False, True, False, 64, 365, 0.2), (False, True, False, 128, 7, 0.2), (False, True, False, 128, 28, 0.2), (False, True, False, 128, 21, 0.2), (False, True, False, 128, 84, 0.2), (False, True, False, 128, 365, 0.2), (False, True, False, 256, 7, 0.2), (False, True, False, 256, 28, 0.2), (False, True, False, 256, 21, 0.2), (False, True, False, 256, 84, 0.2), (False, True, False, 256, 365, 0.2), (False, False, True, 16, 7, 0.2), (False, False, True, 16, 28, 0.2), (False, False, True, 16, 21, 0.2), (False, False, True, 16, 84, 0.2), (False, False, True, 16, 365, 0.2), (False, False, True, 32, 7, 0.2), (False, False, True, 32, 28, 0.2), (False, False, True, 32, 21, 0.2), (False, False, True, 32, 84, 0.2), (False, False, True, 32, 365, 0.2), (False, False, True, 64, 7, 0.2), (False, False, True, 64, 28, 0.2), (False, False, True, 64, 21, 0.2), (False, False, True, 64, 84, 0.2), (False, False, True, 64, 365, 0.2), (False, False, True, 128, 7, 0.2), (False, False, True, 128, 28, 0.2), (False, False, True, 128, 21, 0.2), (False, False, True, 128, 84, 0.2), (False, False, True, 128, 365, 0.2), (False, False, True, 256, 7, 0.2), (False, False, True, 256, 28, 0.2), (False, False, True, 256, 21, 0.2), (False, False, True, 256, 84, 0.2), (False, False, True, 256, 365, 0.2), (False, False, False, 16, 7, 0.2), (False, False, False, 16, 28, 0.2), (False, False, False, 16, 21, 0.2), (False, False, False, 16, 84, 0.2), (False, False, False, 16, 365, 0.2), (False, False, False, 32, 7, 0.2), (False, False, False, 32, 28, 0.2), (False, False, False, 32, 21, 0.2), (False, False, False, 32, 84, 0.2), (False, False, False, 32, 365, 0.2), (False, False, False, 64, 7, 0.2), (False, False, False, 64, 28, 0.2), (False, False, False, 64, 21, 0.2), (False, False, False, 64, 84, 0.2), (False, False, False, 64, 365, 0.2), (False, False, False, 128, 7, 0.2), (False, False, False, 128, 28, 0.2), (False, False, False, 128, 21, 0.2), (False, False, False, 128, 84, 0.2), (False, False, False, 128, 365, 0.2), (False, False, False, 256, 7, 0.2), (False, False, False, 256, 28, 0.2), (False, False, False, 256, 21, 0.2), (False, False, False, 256, 84, 0.2), (False, False, False, 256, 365, 0.2)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67577, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67577 to 0.51822, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51822\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51822\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51822 to 0.50382, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.50382 to 0.48537, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.48537\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.48537\n",
      "\n",
      "Epoch 9: val_loss improved from 0.48537 to 0.48396, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.48396\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.48396\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.48396\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.48396\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.48396\n",
      "Epoch 14: early stopping\n",
      "0-th combination = (True, True, True, 16, 7, 0.2) \n",
      " train accuracy: [0.3997824192047119, 0.6322835087776184] and test accuracy: [0.4210500717163086, 0.6488837003707886]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.77354, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.77354 to 0.65443, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65443 to 0.58472, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58472 to 0.52495, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.52495 to 0.51271, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51271 to 0.50957, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50957 to 0.50918, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50918 to 0.49857, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49857\n",
      "\n",
      "Epoch 10: val_loss improved from 0.49857 to 0.49346, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49346\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49346\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49346\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49346\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49346\n",
      "Epoch 15: early stopping\n",
      "1-th combination = (True, True, True, 16, 28, 0.2) \n",
      " train accuracy: [0.37926730513572693, 0.6158468127250671] and test accuracy: [0.17732378840446472, 0.4210983216762543]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.95045, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.95045 to 0.87537, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.87537 to 0.67037, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67037 to 0.65300, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.65300 to 0.64813, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.64813\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.64813\n",
      "\n",
      "Epoch 8: val_loss improved from 0.64813 to 0.62428, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.62428\n",
      "\n",
      "Epoch 10: val_loss improved from 0.62428 to 0.58311, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.58311\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.58311\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.58311\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.58311\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.58311\n",
      "Epoch 15: early stopping\n",
      "2-th combination = (True, True, True, 16, 21, 0.2) \n",
      " train accuracy: [0.4353698492050171, 0.6598256230354309] and test accuracy: [0.48482662439346313, 0.696294903755188]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85922, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.85922\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.85922\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.85922\n",
      "\n",
      "Epoch 5: val_loss improved from 0.85922 to 0.77535, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.77535 to 0.70219, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.70219 to 0.65015, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.65015 to 0.60950, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.60950 to 0.60180, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.60180 to 0.59530, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.59530 to 0.59296, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.59296 to 0.58147, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.58147 to 0.57035, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.57035\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.57035\n",
      "\n",
      "Epoch 16: val_loss improved from 0.57035 to 0.55880, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.55880 to 0.55659, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.55659\n",
      "\n",
      "Epoch 19: val_loss improved from 0.55659 to 0.55355, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.55355 to 0.54761, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.54761 to 0.52150, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 26: val_loss improved from 0.52150 to 0.52122, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.52122 to 0.51686, saving model to best_model.h5\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.51686\n",
      "\n",
      "Epoch 29: val_loss improved from 0.51686 to 0.50718, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.50718 to 0.50443, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.50443\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.50443\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.50443\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.50443\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.50443\n",
      "Epoch 35: early stopping\n",
      "3-th combination = (True, True, True, 16, 84, 0.2) \n",
      " train accuracy: [0.38919174671173096, 0.6238523721694946] and test accuracy: [0.20691566169261932, 0.4548798203468323]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.81064, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.81064\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.81064\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.81064\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.81064\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.81064\n",
      "Epoch 6: early stopping\n",
      "4-th combination = (True, True, True, 16, 365, 0.2) \n",
      " train accuracy: [0.68843674659729, 0.8297209143638611] and test accuracy: [0.5821943879127502, 0.7630166411399841]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61738, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61738 to 0.54594, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54594\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.54594\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.54594\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.54594\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.54594\n",
      "Epoch 7: early stopping\n",
      "5-th combination = (True, True, True, 32, 7, 0.2) \n",
      " train accuracy: [0.4030466377735138, 0.634859561920166] and test accuracy: [0.14964541792869568, 0.3868403136730194]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66618, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66618 to 0.60149, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60149 to 0.57271, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57271\n",
      "\n",
      "Epoch 5: val_loss improved from 0.57271 to 0.52838, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52838 to 0.51969, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51969\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51969\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51969\n",
      "\n",
      "Epoch 10: val_loss improved from 0.51969 to 0.51436, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.51436 to 0.50605, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50605\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50605\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50605\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.50605\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.50605\n",
      "Epoch 16: early stopping\n",
      "6-th combination = (True, True, True, 32, 28, 0.2) \n",
      " train accuracy: [0.37830501794815063, 0.6150650382041931] and test accuracy: [0.1734943985939026, 0.41652658581733704]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66069, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66069 to 0.52827, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52827\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52827\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52827\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52827 to 0.52670, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52670\n",
      "\n",
      "Epoch 8: val_loss improved from 0.52670 to 0.49932, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49932\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49932\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49932\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49932\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49932\n",
      "Epoch 13: early stopping\n",
      "7-th combination = (True, True, True, 32, 21, 0.2) \n",
      " train accuracy: [0.3900529444217682, 0.6245421767234802] and test accuracy: [0.2900712490081787, 0.5385826230049133]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.79143, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.79143\n",
      "\n",
      "Epoch 3: val_loss improved from 0.79143 to 0.75097, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.75097 to 0.68666, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68666 to 0.66126, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.66126 to 0.64642, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.64642 to 0.61542, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.61542 to 0.59871, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.59871 to 0.59390, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.59390 to 0.57122, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.57122\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.57122\n",
      "\n",
      "Epoch 13: val_loss improved from 0.57122 to 0.53484, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.53484\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.53484\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.53484\n",
      "\n",
      "Epoch 17: val_loss improved from 0.53484 to 0.52367, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.52367\n",
      "\n",
      "Epoch 19: val_loss improved from 0.52367 to 0.52202, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.52202\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.52202\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.52202\n",
      "\n",
      "Epoch 23: val_loss improved from 0.52202 to 0.51201, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.51201 to 0.49944, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.49944\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.49944\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.49944\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.49944\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.49944\n",
      "Epoch 29: early stopping\n",
      "8-th combination = (True, True, True, 32, 84, 0.2) \n",
      " train accuracy: [0.38069865107536316, 0.6170077919960022] and test accuracy: [0.20817111432552338, 0.45625773072242737]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.80178, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.80178\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.80178\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.80178\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.80178\n",
      "\n",
      "Epoch 6: val_loss improved from 0.80178 to 0.76794, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.76794 to 0.74338, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.74338 to 0.72788, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.72788 to 0.71478, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.71478 to 0.70513, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.70513 to 0.69490, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.69490 to 0.67767, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.67767 to 0.66043, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.66043 to 0.64178, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.64178 to 0.62193, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.62193 to 0.59902, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.59902 to 0.57600, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.57600 to 0.56719, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.56719 to 0.56656, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.56656\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.56656\n",
      "\n",
      "Epoch 22: val_loss improved from 0.56656 to 0.56387, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.56387 to 0.55294, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.55294 to 0.54723, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.54723 to 0.54212, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.54212 to 0.53620, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.53620\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.53620\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.53620\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.53620\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.53620\n",
      "Epoch 31: early stopping\n",
      "9-th combination = (True, True, True, 32, 365, 0.2) \n",
      " train accuracy: [0.4084102511405945, 0.6390698552131653] and test accuracy: [0.118141308426857, 0.34371688961982727]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62991, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62991 to 0.53665, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53665 to 0.50364, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50364\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50364\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50364\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50364\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50364\n",
      "Epoch 8: early stopping\n",
      "10-th combination = (True, True, True, 64, 7, 0.2) \n",
      " train accuracy: [0.4128258228302002, 0.642515242099762] and test accuracy: [0.06458540260791779, 0.2541365921497345]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66504, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66504 to 0.57504, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57504 to 0.51388, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51388\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51388\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51388\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51388 to 0.51182, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51182 to 0.50248, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50248\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50248\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50248\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50248\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50248\n",
      "Epoch 13: early stopping\n",
      "11-th combination = (True, True, True, 64, 28, 0.2) \n",
      " train accuracy: [0.38023641705513, 0.6166331171989441] and test accuracy: [0.04600635543465614, 0.21449092030525208]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63476, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63476 to 0.61761, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.61761 to 0.53850, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.53850\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53850 to 0.49559, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.49559 to 0.49199, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49199\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49199\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49199\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49199\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49199\n",
      "Epoch 11: early stopping\n",
      "12-th combination = (True, True, True, 64, 21, 0.2) \n",
      " train accuracy: [0.3908140957355499, 0.6251512765884399] and test accuracy: [0.02082052454352379, 0.1442931890487671]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.84685, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.84685 to 0.69945, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.69945 to 0.66293, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.66293 to 0.63101, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.63101\n",
      "\n",
      "Epoch 6: val_loss improved from 0.63101 to 0.59344, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.59344 to 0.55894, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.55894\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.55894\n",
      "\n",
      "Epoch 10: val_loss improved from 0.55894 to 0.52167, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52167\n",
      "\n",
      "Epoch 12: val_loss improved from 0.52167 to 0.51452, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51452\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51452\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51452\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51452\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51452\n",
      "Epoch 17: early stopping\n",
      "13-th combination = (True, True, True, 64, 84, 0.2) \n",
      " train accuracy: [0.40100759267807007, 0.6332516074180603] and test accuracy: [0.07485318928956985, 0.27359309792518616]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75590, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.75590\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.75590\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.75590\n",
      "\n",
      "Epoch 5: val_loss improved from 0.75590 to 0.69822, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.69822 to 0.64706, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.64706 to 0.63729, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.63729\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.63729\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.63729\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.63729\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.63729\n",
      "Epoch 12: early stopping\n",
      "14-th combination = (True, True, True, 64, 365, 0.2) \n",
      " train accuracy: [0.4549870491027832, 0.6745272874832153] and test accuracy: [0.3111698031425476, 0.5578259825706482]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54711, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54711 to 0.49583, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49583\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49583\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49583\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49583\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49583\n",
      "Epoch 7: early stopping\n",
      "15-th combination = (True, True, True, 128, 7, 0.2) \n",
      " train accuracy: [0.3756370544433594, 0.6128923892974854] and test accuracy: [0.07624155282974243, 0.2761187255382538]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "17th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75879, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.75879 to 0.60444, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60444 to 0.52761, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52761 to 0.52726, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.52726 to 0.49554, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49554\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49554\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49554\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49554\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49554\n",
      "Epoch 10: early stopping\n",
      "16-th combination = (True, True, True, 128, 28, 0.2) \n",
      " train accuracy: [0.39088791608810425, 0.6252102851867676] and test accuracy: [0.034625738859176636, 0.18607991933822632]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "18th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53524, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.53524\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53524\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.53524\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53524 to 0.50593, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50593\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50593\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50593\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50593\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50593\n",
      "Epoch 10: early stopping\n",
      "17-th combination = (True, True, True, 128, 21, 0.2) \n",
      " train accuracy: [0.390054851770401, 0.6245437264442444] and test accuracy: [0.027395913377404213, 0.16551710665225983]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "19th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66838, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66838 to 0.61152, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.61152 to 0.56311, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56311 to 0.53964, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53964 to 0.51639, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51639\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51639 to 0.50580, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50580\n",
      "\n",
      "Epoch 9: val_loss improved from 0.50580 to 0.50214, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50214\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50214\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50214\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50214\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50214\n",
      "Epoch 14: early stopping\n",
      "18-th combination = (True, True, True, 128, 84, 0.2) \n",
      " train accuracy: [0.3836938440799713, 0.6194302439689636] and test accuracy: [0.021743478253483772, 0.14745670557022095]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "20th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.74354, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.74354 to 0.68739, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68739 to 0.57998, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57998 to 0.52129, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52129\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52129\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52129\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52129\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52129\n",
      "Epoch 9: early stopping\n",
      "19-th combination = (True, True, True, 128, 365, 0.2) \n",
      " train accuracy: [0.4635505676269531, 0.6808454990386963] and test accuracy: [0.17803120613098145, 0.4219374358654022]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "21th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52251, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52251\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52251 to 0.51676, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51676\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51676\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51676\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51676\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51676\n",
      "Epoch 8: early stopping\n",
      "20-th combination = (True, True, True, 256, 7, 0.2) \n",
      " train accuracy: [0.3580778241157532, 0.5983960628509521] and test accuracy: [0.03471364080905914, 0.18631596863269806]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "22th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.71649, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.71649 to 0.64420, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.64420 to 0.63449, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.63449 to 0.54520, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.54520 to 0.50810, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50810\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50810\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50810\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50810\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50810\n",
      "Epoch 10: early stopping\n",
      "21-th combination = (True, True, True, 256, 28, 0.2) \n",
      " train accuracy: [0.4087299108505249, 0.639319896697998] and test accuracy: [0.05465910583734512, 0.23379287123680115]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "23th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56811, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56811 to 0.50026, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50026\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50026\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50026\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50026\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50026\n",
      "Epoch 7: early stopping\n",
      "22-th combination = (True, True, True, 256, 21, 0.2) \n",
      " train accuracy: [0.4017133414745331, 0.6338086128234863] and test accuracy: [0.02462698146700859, 0.1569298654794693]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "24th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67843, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.67843\n",
      "\n",
      "Epoch 3: val_loss improved from 0.67843 to 0.63663, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.63663 to 0.54312, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.54312\n",
      "\n",
      "Epoch 6: val_loss improved from 0.54312 to 0.53363, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.53363\n",
      "\n",
      "Epoch 8: val_loss improved from 0.53363 to 0.52466, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52466\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52466 to 0.52341, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52341\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.52341\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.52341\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.52341\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.52341\n",
      "Epoch 15: early stopping\n",
      "23-th combination = (True, True, True, 256, 84, 0.2) \n",
      " train accuracy: [0.38831666111946106, 0.6231505870819092] and test accuracy: [0.031019112095236778, 0.17612244188785553]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "25th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68865, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.68865\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.68865\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.68865\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68865 to 0.61538, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.61538\n",
      "\n",
      "Epoch 7: val_loss improved from 0.61538 to 0.61131, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.61131\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.61131\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.61131\n",
      "\n",
      "Epoch 11: val_loss improved from 0.61131 to 0.59242, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.59242 to 0.56048, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.56048\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.56048\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.56048\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.56048\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.56048\n",
      "Epoch 17: early stopping\n",
      "24-th combination = (True, True, True, 256, 365, 0.2) \n",
      " train accuracy: [0.41735324263572693, 0.6460288166999817] and test accuracy: [0.0938580110669136, 0.3063625395298004]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "26th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60074, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60074 to 0.53227, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53227\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53227 to 0.52458, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52458\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52458\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52458 to 0.52164, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52164\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52164\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.52164\n",
      "\n",
      "Epoch 11: val_loss improved from 0.52164 to 0.51291, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51291\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51291\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51291\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51291\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51291\n",
      "Epoch 16: early stopping\n",
      "25-th combination = (True, True, False, 16, 7, 0.2) \n",
      " train accuracy: [0.4041917622089386, 0.6357607841491699] and test accuracy: [0.13381485641002655, 0.36580711603164673]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "27th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.05584, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.05584\n",
      "\n",
      "Epoch 3: val_loss improved from 1.05584 to 1.01539, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 1.01539 to 0.84845, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.84845 to 0.78237, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.78237\n",
      "\n",
      "Epoch 7: val_loss improved from 0.78237 to 0.76730, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.76730 to 0.75822, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.75822 to 0.69707, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.69707\n",
      "\n",
      "Epoch 11: val_loss improved from 0.69707 to 0.67112, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.67112\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.67112\n",
      "\n",
      "Epoch 14: val_loss improved from 0.67112 to 0.67019, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.67019\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.67019\n",
      "\n",
      "Epoch 17: val_loss improved from 0.67019 to 0.65894, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.65894 to 0.64570, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.64570\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.64570\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.64570\n",
      "\n",
      "Epoch 22: val_loss improved from 0.64570 to 0.63397, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.63397\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63397 to 0.62968, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.62968 to 0.61265, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.61265 to 0.61132, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.61132\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.61132\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.61132\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.61132\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.61132\n",
      "Epoch 31: early stopping\n",
      "26-th combination = (True, True, False, 16, 28, 0.2) \n",
      " train accuracy: [0.4189336597919464, 0.6472508311271667] and test accuracy: [0.45983368158340454, 0.6781103610992432]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "28th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.84895, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.84895 to 0.63792, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63792 to 0.56428, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56428 to 0.53590, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53590 to 0.53207, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.53207 to 0.52184, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52184 to 0.50361, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50361 to 0.49685, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.49685 to 0.49572, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49572\n",
      "\n",
      "Epoch 11: val_loss improved from 0.49572 to 0.49414, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49414\n",
      "\n",
      "Epoch 13: val_loss improved from 0.49414 to 0.48881, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.48881\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.48881\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.48881\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.48881\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.48881\n",
      "Epoch 18: early stopping\n",
      "27-th combination = (True, True, False, 16, 21, 0.2) \n",
      " train accuracy: [0.3772266209125519, 0.6141877770423889] and test accuracy: [0.02431654930114746, 0.15593764185905457]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "29th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73409, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.73409\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.73409\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.73409\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.73409\n",
      "\n",
      "Epoch 6: val_loss improved from 0.73409 to 0.72362, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.72362 to 0.66919, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66919 to 0.63571, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.63571 to 0.60872, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.60872\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.60872\n",
      "\n",
      "Epoch 12: val_loss improved from 0.60872 to 0.58484, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.58484\n",
      "\n",
      "Epoch 14: val_loss improved from 0.58484 to 0.56683, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.56683\n",
      "\n",
      "Epoch 16: val_loss improved from 0.56683 to 0.56587, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.56587 to 0.56222, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.56222 to 0.54607, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.54607 to 0.53712, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.53712\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.53712\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.53712\n",
      "\n",
      "Epoch 23: val_loss improved from 0.53712 to 0.52772, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.52772\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.52772\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.52772\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.52772\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.52772\n",
      "Epoch 28: early stopping\n",
      "28-th combination = (True, True, False, 16, 84, 0.2) \n",
      " train accuracy: [0.39705905318260193, 0.6301262378692627] and test accuracy: [0.2853710353374481, 0.5342013239860535]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "30th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.72077, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.72077 to 0.71238, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.71238 to 0.70616, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.70616 to 0.70387, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.70387\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.70387\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.70387\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.70387\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.70387\n",
      "Epoch 9: early stopping\n",
      "29-th combination = (True, True, False, 16, 365, 0.2) \n",
      " train accuracy: [0.5311747193336487, 0.728817343711853] and test accuracy: [0.2774698734283447, 0.5267540812492371]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "31th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60039, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60039 to 0.53521, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53521 to 0.51680, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51680 to 0.51468, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51468\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51468\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51468\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51468\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51468\n",
      "Epoch 9: early stopping\n",
      "30-th combination = (True, True, False, 32, 7, 0.2) \n",
      " train accuracy: [0.470657616853714, 0.6860449314117432] and test accuracy: [0.2982262969017029, 0.5461009740829468]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "32th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73269, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73269 to 0.59196, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.59196 to 0.55835, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55835 to 0.54757, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.54757 to 0.51981, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51981\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51981\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51981\n",
      "\n",
      "Epoch 9: val_loss improved from 0.51981 to 0.51573, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51573\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51573\n",
      "\n",
      "Epoch 12: val_loss improved from 0.51573 to 0.50916, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50916\n",
      "\n",
      "Epoch 14: val_loss improved from 0.50916 to 0.50756, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.50756 to 0.49660, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49660\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49660\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49660\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49660\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49660\n",
      "Epoch 20: early stopping\n",
      "31-th combination = (True, True, False, 32, 28, 0.2) \n",
      " train accuracy: [0.38091742992401123, 0.6171850562095642] and test accuracy: [0.08709460496902466, 0.29511794447898865]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "33th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56003, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56003 to 0.52364, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52364 to 0.50932, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50932\n",
      "\n",
      "Epoch 5: val_loss improved from 0.50932 to 0.50424, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.50424 to 0.49737, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.49737 to 0.49052, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49052\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49052\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49052\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49052\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49052\n",
      "Epoch 12: early stopping\n",
      "32-th combination = (True, True, False, 32, 21, 0.2) \n",
      " train accuracy: [0.37748345732688904, 0.6143968105316162] and test accuracy: [0.19621698558330536, 0.4429638683795929]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "34th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.76310, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.76310\n",
      "\n",
      "Epoch 3: val_loss improved from 0.76310 to 0.70330, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.70330 to 0.69524, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.69524 to 0.68990, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68990 to 0.66077, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.66077 to 0.64049, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.64049 to 0.60908, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.60908\n",
      "\n",
      "Epoch 10: val_loss improved from 0.60908 to 0.59977, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.59977 to 0.57948, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.57948 to 0.55779, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.55779 to 0.53106, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.53106\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.53106\n",
      "\n",
      "Epoch 16: val_loss improved from 0.53106 to 0.51589, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.51589 to 0.51493, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.51493\n",
      "\n",
      "Epoch 19: val_loss improved from 0.51493 to 0.50455, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50455\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.50455\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.50455\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.50455\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.50455\n",
      "Epoch 24: early stopping\n",
      "33-th combination = (True, True, False, 32, 84, 0.2) \n",
      " train accuracy: [0.379046767950058, 0.6156677603721619] and test accuracy: [0.13349832594394684, 0.36537423729896545]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "35th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.80540, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.80540 to 0.75780, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.75780 to 0.72939, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.72939\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.72939\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.72939\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.72939\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.72939\n",
      "Epoch 8: early stopping\n",
      "34-th combination = (True, True, False, 32, 365, 0.2) \n",
      " train accuracy: [0.5116536617279053, 0.7152997255325317] and test accuracy: [0.4121173620223999, 0.6419636607170105]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "36th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54591, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54591 to 0.49996, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49996\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49996\n",
      "\n",
      "Epoch 5: val_loss improved from 0.49996 to 0.49222, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49222\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49222\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49222\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49222\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49222\n",
      "Epoch 10: early stopping\n",
      "35-th combination = (True, True, False, 64, 7, 0.2) \n",
      " train accuracy: [0.37721672654151917, 0.6141797304153442] and test accuracy: [0.1388894021511078, 0.3726786971092224]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "37th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61012, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61012 to 0.57080, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57080 to 0.56122, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56122 to 0.49065, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49065\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49065\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49065\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49065\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49065\n",
      "Epoch 9: early stopping\n",
      "36-th combination = (True, True, False, 64, 28, 0.2) \n",
      " train accuracy: [0.42078790068626404, 0.648681640625] and test accuracy: [0.023890899494290352, 0.15456680953502655]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "38th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62943, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62943 to 0.61428, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.61428 to 0.51791, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51791 to 0.50301, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50301\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50301\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50301\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50301\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50301\n",
      "Epoch 9: early stopping\n",
      "37-th combination = (True, True, False, 64, 21, 0.2) \n",
      " train accuracy: [0.41495034098625183, 0.6441664099693298] and test accuracy: [0.03592055290937424, 0.18952718377113342]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "39th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68754, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68754 to 0.62882, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62882 to 0.57863, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57863\n",
      "\n",
      "Epoch 5: val_loss improved from 0.57863 to 0.57014, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.57014 to 0.56804, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.56804 to 0.53738, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.53738 to 0.53727, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53727 to 0.52248, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.52248\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52248\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.52248\n",
      "\n",
      "Epoch 13: val_loss improved from 0.52248 to 0.51087, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51087\n",
      "\n",
      "Epoch 15: val_loss improved from 0.51087 to 0.51020, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.51020 to 0.50928, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.50928\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50928\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.50928\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50928\n",
      "\n",
      "Epoch 21: val_loss improved from 0.50928 to 0.50718, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.50718\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.50718\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.50718\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.50718\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.50718\n",
      "Epoch 26: early stopping\n",
      "38-th combination = (True, True, False, 64, 84, 0.2) \n",
      " train accuracy: [0.3799159526824951, 0.6163732409477234] and test accuracy: [0.06910036504268646, 0.2628694772720337]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "40th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.71245, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.71245 to 0.63666, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.63666\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.63666\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.63666\n",
      "\n",
      "Epoch 6: val_loss improved from 0.63666 to 0.60337, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.60337 to 0.57640, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.57640 to 0.57558, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.57558 to 0.56957, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.56957 to 0.55303, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.55303 to 0.54176, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.54176 to 0.54093, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.54093 to 0.53657, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.53657 to 0.51799, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.51799 to 0.51592, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51592\n",
      "\n",
      "Epoch 17: val_loss improved from 0.51592 to 0.50681, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50681\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.50681\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50681\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.50681\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.50681\n",
      "Epoch 22: early stopping\n",
      "39-th combination = (True, True, False, 64, 365, 0.2) \n",
      " train accuracy: [0.39878544211387634, 0.6314945816993713] and test accuracy: [0.13369257748126984, 0.36563995480537415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "41th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49694, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.49694\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49694\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49694\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49694\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49694\n",
      "Epoch 6: early stopping\n",
      "40-th combination = (True, True, False, 128, 7, 0.2) \n",
      " train accuracy: [0.4149085581302643, 0.644133985042572] and test accuracy: [0.1898152232170105, 0.4356778860092163]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "42th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69706, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69706 to 0.49192, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49192\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49192\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49192\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49192\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49192\n",
      "Epoch 7: early stopping\n",
      "41-th combination = (True, True, False, 128, 28, 0.2) \n",
      " train accuracy: [0.39180344343185425, 0.625942051410675] and test accuracy: [0.03447498381137848, 0.18567439913749695]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "43th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54509, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54509 to 0.49695, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49695\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49695\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49695\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49695\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49695\n",
      "Epoch 7: early stopping\n",
      "42-th combination = (True, True, False, 128, 21, 0.2) \n",
      " train accuracy: [0.41208913922309875, 0.6419416666030884] and test accuracy: [0.05405234917998314, 0.2324916124343872]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "44th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67382, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67382 to 0.58648, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.58648\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58648 to 0.52982, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52982\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52982 to 0.52775, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52775 to 0.50770, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50770\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50770\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50770\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50770\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50770\n",
      "Epoch 12: early stopping\n",
      "43-th combination = (True, True, False, 128, 84, 0.2) \n",
      " train accuracy: [0.3796720802783966, 0.6161753535270691] and test accuracy: [0.028414878994226456, 0.16856713593006134]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "45th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54892, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.54892\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54892\n",
      "\n",
      "Epoch 4: val_loss improved from 0.54892 to 0.53896, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.53896\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.53896\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.53896\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.53896\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.53896\n",
      "Epoch 9: early stopping\n",
      "44-th combination = (True, True, False, 128, 365, 0.2) \n",
      " train accuracy: [0.4324871003627777, 0.6576375365257263] and test accuracy: [0.14888456463813782, 0.38585561513900757]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "46th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62792, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62792 to 0.55656, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55656 to 0.52051, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52051\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52051\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52051\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52051\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52051\n",
      "Epoch 8: early stopping\n",
      "45-th combination = (True, True, False, 256, 7, 0.2) \n",
      " train accuracy: [0.34128430485725403, 0.5841954350471497] and test accuracy: [0.015950078144669533, 0.1262936145067215]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "47th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55446, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.55446\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.55446\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55446 to 0.50812, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50812\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50812\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50812\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50812\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50812\n",
      "Epoch 9: early stopping\n",
      "46-th combination = (True, True, False, 256, 28, 0.2) \n",
      " train accuracy: [0.44374406337738037, 0.666141152381897] and test accuracy: [0.1473332792520523, 0.3838401734828949]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "48th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67927, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67927 to 0.61210, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.61210\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.61210\n",
      "\n",
      "Epoch 5: val_loss improved from 0.61210 to 0.55235, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.55235 to 0.53841, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.53841\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.53841\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.53841\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.53841\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.53841\n",
      "Epoch 11: early stopping\n",
      "47-th combination = (True, True, False, 256, 21, 0.2) \n",
      " train accuracy: [0.32915443181991577, 0.5737197995185852] and test accuracy: [0.03256160393357277, 0.18044833838939667]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "49th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51356, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.51356\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51356\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51356\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51356\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51356 to 0.50282, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50282\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50282\n",
      "\n",
      "Epoch 9: val_loss improved from 0.50282 to 0.49873, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49873\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49873\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49873\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49873\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49873\n",
      "Epoch 14: early stopping\n",
      "48-th combination = (True, True, False, 256, 84, 0.2) \n",
      " train accuracy: [0.40344324707984924, 0.6351718306541443] and test accuracy: [0.11371559649705887, 0.33721742033958435]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "50th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63158, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63158 to 0.59420, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.59420 to 0.57908, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57908\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57908\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.57908\n",
      "\n",
      "Epoch 8: val_loss improved from 0.57908 to 0.52125, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52125\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.52125\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52125\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.52125\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.52125\n",
      "Epoch 13: early stopping\n",
      "49-th combination = (True, True, False, 256, 365, 0.2) \n",
      " train accuracy: [0.4147069752216339, 0.6439774632453918] and test accuracy: [0.03357172757387161, 0.18322588503360748]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "51th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63701, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63701 to 0.53708, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53708\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.53708\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53708 to 0.53236, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.53236\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.53236\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.53236\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.53236\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.53236\n",
      "Epoch 10: early stopping\n",
      "50-th combination = (True, False, True, 16, 7, 0.2) \n",
      " train accuracy: [0.4015813171863556, 0.633704423904419] and test accuracy: [0.22523416578769684, 0.47458842396736145]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "52th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.14945, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.14945 to 0.85672, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.85672 to 0.73680, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.73680 to 0.66661, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.66661 to 0.60815, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.60815 to 0.55019, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.55019 to 0.54738, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.54738\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.54738\n",
      "\n",
      "Epoch 10: val_loss improved from 0.54738 to 0.54049, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.54049\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.54049\n",
      "\n",
      "Epoch 13: val_loss improved from 0.54049 to 0.53753, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.53753\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.53753\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.53753\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.53753\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.53753\n",
      "Epoch 18: early stopping\n",
      "51-th combination = (True, False, True, 16, 28, 0.2) \n",
      " train accuracy: [0.3906119465827942, 0.6249895691871643] and test accuracy: [0.11973675340414047, 0.34602999687194824]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "53th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.71503, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.71503 to 0.58801, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58801 to 0.54331, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.54331 to 0.52210, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.52210 to 0.51547, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51547 to 0.50500, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50500\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50500 to 0.50363, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.50363 to 0.50122, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50122 to 0.50000, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50000 to 0.49770, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.49770 to 0.49364, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49364\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49364\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49364\n",
      "\n",
      "Epoch 16: val_loss improved from 0.49364 to 0.49117, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49117\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49117\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49117\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49117\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49117\n",
      "Epoch 21: early stopping\n",
      "52-th combination = (True, False, True, 16, 21, 0.2) \n",
      " train accuracy: [0.3807538151741028, 0.6170524954795837] and test accuracy: [0.05073188245296478, 0.2252373844385147]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "54th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.76322, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.76322\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.76322\n",
      "\n",
      "Epoch 4: val_loss improved from 0.76322 to 0.72433, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.72433 to 0.69030, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.69030 to 0.65215, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.65215 to 0.61486, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.61486 to 0.59162, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.59162 to 0.57997, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.57997 to 0.57025, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.57025 to 0.55677, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.55677 to 0.54128, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.54128\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.54128\n",
      "\n",
      "Epoch 15: val_loss improved from 0.54128 to 0.53027, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.53027 to 0.52794, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.52794\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.52794\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.52794\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.52794\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.52794\n",
      "Epoch 21: early stopping\n",
      "53-th combination = (True, False, True, 16, 84, 0.2) \n",
      " train accuracy: [0.39581868052482605, 0.6291412115097046] and test accuracy: [0.2204018533229828, 0.46946975588798523]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "55th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.80961, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.80961\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.80961\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.80961\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.80961\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.80961\n",
      "Epoch 6: early stopping\n",
      "54-th combination = (True, False, True, 16, 365, 0.2) \n",
      " train accuracy: [0.6022999286651611, 0.7760798335075378] and test accuracy: [0.521080732345581, 0.7218592166900635]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "56th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54218, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54218 to 0.53326, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53326 to 0.48572, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.48572\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.48572\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.48572\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.48572\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.48572\n",
      "Epoch 8: early stopping\n",
      "55-th combination = (True, False, True, 32, 7, 0.2) \n",
      " train accuracy: [0.396689772605896, 0.6298331022262573] and test accuracy: [0.15765908360481262, 0.39706307649612427]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "57th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57699, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57699 to 0.51603, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51603 to 0.50223, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.50223 to 0.49420, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49420\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49420\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49420\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49420\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49420\n",
      "Epoch 9: early stopping\n",
      "56-th combination = (True, False, True, 32, 28, 0.2) \n",
      " train accuracy: [0.38467058539390564, 0.6202181577682495] and test accuracy: [0.020459774881601334, 0.14303767681121826]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "58th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63001, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63001 to 0.55711, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55711 to 0.54466, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.54466 to 0.52287, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52287\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52287 to 0.52105, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52105 to 0.51965, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51965\n",
      "\n",
      "Epoch 9: val_loss improved from 0.51965 to 0.51279, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51279\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51279\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51279\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51279\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51279\n",
      "Epoch 14: early stopping\n",
      "57-th combination = (True, False, True, 32, 21, 0.2) \n",
      " train accuracy: [0.39831414818763733, 0.6311213374137878] and test accuracy: [0.05254708230495453, 0.22923150658607483]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "59th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63443, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.63443\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.63443\n",
      "\n",
      "Epoch 4: val_loss improved from 0.63443 to 0.62368, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.62368 to 0.59801, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.59801 to 0.56336, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.56336 to 0.54698, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54698 to 0.53409, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53409 to 0.52433, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52433 to 0.51070, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51070\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51070\n",
      "\n",
      "Epoch 13: val_loss improved from 0.51070 to 0.50932, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.50932 to 0.50390, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.50390\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.50390\n",
      "\n",
      "Epoch 17: val_loss improved from 0.50390 to 0.49934, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49934\n",
      "\n",
      "Epoch 19: val_loss improved from 0.49934 to 0.49804, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.49804 to 0.49504, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49504\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.49504\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.49504\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.49504\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.49504\n",
      "Epoch 25: early stopping\n",
      "58-th combination = (True, False, True, 32, 84, 0.2) \n",
      " train accuracy: [0.3863973617553711, 0.6216086745262146] and test accuracy: [0.0886019915342331, 0.29766085743904114]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "60th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75977, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.75977\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.75977\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.75977\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.75977\n",
      "\n",
      "Epoch 6: val_loss improved from 0.75977 to 0.75853, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.75853 to 0.70508, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.70508 to 0.67196, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67196 to 0.64580, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.64580 to 0.62877, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.62877 to 0.62084, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.62084 to 0.61595, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.61595 to 0.61142, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.61142 to 0.60769, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.60769 to 0.60111, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.60111 to 0.59210, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.59210 to 0.57464, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.57464 to 0.55619, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.55619 to 0.54350, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.54350 to 0.54210, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.54210 to 0.54001, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.54001 to 0.52995, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.52995 to 0.52049, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.52049 to 0.51797, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.51797\n",
      "Epoch 29: early stopping\n",
      "59-th combination = (True, False, True, 32, 365, 0.2) \n",
      " train accuracy: [0.39289233088493347, 0.6268112659454346] and test accuracy: [0.10074904561042786, 0.3174099028110504]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "61th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51726, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.51726\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51726\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51726\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51726 to 0.48811, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.48811\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.48811\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.48811\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.48811\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.48811\n",
      "Epoch 10: early stopping\n",
      "60-th combination = (True, False, True, 64, 7, 0.2) \n",
      " train accuracy: [0.3329243063926697, 0.5769959092140198] and test accuracy: [0.033395323902368546, 0.1827438771724701]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "62th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.59721, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.59721\n",
      "\n",
      "Epoch 3: val_loss improved from 0.59721 to 0.53569, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53569 to 0.51174, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51174\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51174\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51174 to 0.50918, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50918\n",
      "\n",
      "Epoch 9: val_loss improved from 0.50918 to 0.50078, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50078\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50078\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50078\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50078\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50078\n",
      "Epoch 14: early stopping\n",
      "61-th combination = (True, False, True, 64, 28, 0.2) \n",
      " train accuracy: [0.38379913568496704, 0.6195152401924133] and test accuracy: [0.025237714871764183, 0.158863827586174]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "63th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60173, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60173 to 0.54269, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54269 to 0.51649, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51649 to 0.49369, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49369\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49369\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49369\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49369\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49369\n",
      "Epoch 9: early stopping\n",
      "62-th combination = (True, False, True, 64, 21, 0.2) \n",
      " train accuracy: [0.3823874890804291, 0.6183748841285706] and test accuracy: [0.058768823742866516, 0.24242281913757324]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "64th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85610, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.85610 to 0.56917, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.56917\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.56917\n",
      "\n",
      "Epoch 5: val_loss improved from 0.56917 to 0.56582, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.56582 to 0.53232, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.53232 to 0.51355, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51355\n",
      "\n",
      "Epoch 9: val_loss improved from 0.51355 to 0.50256, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50256\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50256 to 0.49933, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49933\n",
      "\n",
      "Epoch 13: val_loss improved from 0.49933 to 0.49811, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49811\n",
      "\n",
      "Epoch 15: val_loss improved from 0.49811 to 0.49675, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49675\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49675\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49675\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49675\n",
      "\n",
      "Epoch 20: val_loss improved from 0.49675 to 0.49624, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49624\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.49624\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.49624\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.49624\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.49624\n",
      "Epoch 25: early stopping\n",
      "63-th combination = (True, False, True, 64, 84, 0.2) \n",
      " train accuracy: [0.3802907466888428, 0.6166771650314331] and test accuracy: [0.02349473163485527, 0.15327991545200348]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "65th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69059, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69059 to 0.61907, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.61907\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.61907\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.61907\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.61907\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.61907\n",
      "Epoch 7: early stopping\n",
      "64-th combination = (True, False, True, 64, 365, 0.2) \n",
      " train accuracy: [0.45820048451423645, 0.67690509557724] and test accuracy: [0.13014011085033417, 0.36074936389923096]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "66th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50640, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.50640\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50640\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50640\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50640\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50640\n",
      "Epoch 6: early stopping\n",
      "65-th combination = (True, False, True, 128, 7, 0.2) \n",
      " train accuracy: [0.37076395750045776, 0.6089038848876953] and test accuracy: [0.025173397734761238, 0.15866126120090485]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "67th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56393, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56393 to 0.50106, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.50106 to 0.50037, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50037\n",
      "\n",
      "Epoch 5: val_loss improved from 0.50037 to 0.49280, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49280\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49280\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49280\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49280\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49280\n",
      "Epoch 10: early stopping\n",
      "66-th combination = (True, False, True, 128, 28, 0.2) \n",
      " train accuracy: [0.3941173553466797, 0.6277876496315002] and test accuracy: [0.036925770342350006, 0.19216080009937286]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "68th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54250, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54250 to 0.53718, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53718 to 0.50444, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50444\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50444\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50444\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50444\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50444\n",
      "Epoch 8: early stopping\n",
      "67-th combination = (True, False, True, 128, 21, 0.2) \n",
      " train accuracy: [0.39492741227149963, 0.6284325122833252] and test accuracy: [0.16098126769065857, 0.40122470259666443]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "69th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60132, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60132 to 0.53177, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53177 to 0.50795, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50795\n",
      "\n",
      "Epoch 5: val_loss improved from 0.50795 to 0.49324, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49324\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49324\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49324\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49324\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49324\n",
      "Epoch 10: early stopping\n",
      "68-th combination = (True, False, True, 128, 84, 0.2) \n",
      " train accuracy: [0.38435444235801697, 0.6199632883071899] and test accuracy: [0.020282382145524025, 0.14241622388362885]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "70th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66240, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.66240\n",
      "\n",
      "Epoch 3: val_loss improved from 0.66240 to 0.57935, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57935 to 0.51751, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51751\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51751\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51751\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51751\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51751\n",
      "Epoch 9: early stopping\n",
      "69-th combination = (True, False, True, 128, 365, 0.2) \n",
      " train accuracy: [0.40485528111457825, 0.6362823843955994] and test accuracy: [0.058467667549848557, 0.24180088937282562]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "71th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63343, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63343 to 0.57776, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57776 to 0.56659, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.56659\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.56659\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.56659\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.56659\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.56659\n",
      "Epoch 8: early stopping\n",
      "70-th combination = (True, False, True, 256, 7, 0.2) \n",
      " train accuracy: [0.28848177194595337, 0.5371049642562866] and test accuracy: [0.0384618416428566, 0.19611690938472748]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "72th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56146, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56146 to 0.52811, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52811\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52811 to 0.51733, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51733 to 0.51486, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51486\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51486\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51486\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51486\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51486\n",
      "Epoch 10: early stopping\n",
      "71-th combination = (True, False, True, 256, 28, 0.2) \n",
      " train accuracy: [0.3749101758003235, 0.6122990846633911] and test accuracy: [0.02817552722990513, 0.16785567998886108]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "73th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.65206, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.65206 to 0.58791, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.58791\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58791 to 0.53718, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53718 to 0.52947, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52947\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52947\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52947\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52947\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.52947\n",
      "Epoch 10: early stopping\n",
      "72-th combination = (True, False, True, 256, 21, 0.2) \n",
      " train accuracy: [0.3540623188018799, 0.5950313806533813] and test accuracy: [0.05829843133687973, 0.24145068228244781]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "74th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63943, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63943 to 0.56474, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.56474\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56474 to 0.53205, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.53205\n",
      "\n",
      "Epoch 6: val_loss improved from 0.53205 to 0.52949, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52949\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52949\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52949\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52949 to 0.52027, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52027\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.52027\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.52027\n",
      "\n",
      "Epoch 14: val_loss improved from 0.52027 to 0.51949, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51949\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51949\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51949\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.51949\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.51949\n",
      "Epoch 19: early stopping\n",
      "73-th combination = (True, False, True, 256, 84, 0.2) \n",
      " train accuracy: [0.5287531614303589, 0.7271541357040405] and test accuracy: [0.5338331460952759, 0.730638861656189]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "75th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63525, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.63525\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63525 to 0.56056, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56056 to 0.51213, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51213\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51213\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51213\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51213\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51213\n",
      "Epoch 9: early stopping\n",
      "74-th combination = (True, False, True, 256, 365, 0.2) \n",
      " train accuracy: [0.4012535810470581, 0.6334457993507385] and test accuracy: [0.06274489313364029, 0.2504892945289612]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "76th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55462, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55462 to 0.51003, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51003 to 0.50758, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.50758 to 0.49420, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.49420 to 0.48200, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.48200\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.48200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.48200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.48200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.48200\n",
      "Epoch 10: early stopping\n",
      "75-th combination = (True, False, False, 16, 7, 0.2) \n",
      " train accuracy: [0.3744133710861206, 0.6118932962417603] and test accuracy: [0.04737995192408562, 0.21766936779022217]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "77th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66289, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66289 to 0.62508, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62508 to 0.58651, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58651 to 0.55422, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.55422 to 0.54633, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.54633 to 0.53967, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.53967 to 0.52256, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.52256 to 0.50892, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50892\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50892 to 0.50553, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50553\n",
      "\n",
      "Epoch 12: val_loss improved from 0.50553 to 0.50258, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.50258 to 0.49828, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49828\n",
      "\n",
      "Epoch 15: val_loss improved from 0.49828 to 0.49587, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49587\n",
      "\n",
      "Epoch 17: val_loss improved from 0.49587 to 0.49432, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49432\n",
      "\n",
      "Epoch 19: val_loss improved from 0.49432 to 0.49285, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49285\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49285\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.49285\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.49285\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.49285\n",
      "Epoch 24: early stopping\n",
      "76-th combination = (True, False, False, 16, 28, 0.2) \n",
      " train accuracy: [0.37698671221733093, 0.61399245262146] and test accuracy: [0.2037356048822403, 0.45137080550193787]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "78th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.64865, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.64865 to 0.58781, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58781 to 0.53045, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.53045\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53045 to 0.51612, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51612 to 0.50644, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50644\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50644 to 0.50644, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50644\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50644 to 0.50425, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50425 to 0.50407, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50407\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50407\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50407\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.50407\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.50407\n",
      "Epoch 16: early stopping\n",
      "77-th combination = (True, False, False, 16, 21, 0.2) \n",
      " train accuracy: [0.3904198408126831, 0.6248358488082886] and test accuracy: [0.031826362013816833, 0.1783994436264038]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "79th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68415, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68415 to 0.67410, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.67410\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.67410\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67410 to 0.67248, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67248 to 0.65766, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.65766 to 0.64222, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.64222\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.64222\n",
      "\n",
      "Epoch 10: val_loss improved from 0.64222 to 0.62865, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.62865 to 0.62135, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.62135\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.62135\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.62135\n",
      "\n",
      "Epoch 15: val_loss improved from 0.62135 to 0.61550, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.61550 to 0.61164, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.61164 to 0.60683, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.60683 to 0.60604, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.60604 to 0.60129, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.60129 to 0.59459, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.59459 to 0.59346, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.59346\n",
      "\n",
      "Epoch 23: val_loss improved from 0.59346 to 0.59023, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.59023 to 0.58617, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.58617 to 0.58038, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.58038\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.58038\n",
      "\n",
      "Epoch 28: val_loss improved from 0.58038 to 0.57857, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.57857\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.57857\n",
      "\n",
      "Epoch 31: val_loss improved from 0.57857 to 0.57089, saving model to best_model.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.57089 to 0.56734, saving model to best_model.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.56734 to 0.56233, saving model to best_model.h5\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.56233\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.56233\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.56233\n",
      "\n",
      "Epoch 37: val_loss improved from 0.56233 to 0.55992, saving model to best_model.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.55992 to 0.54879, saving model to best_model.h5\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.54879\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.54879\n",
      "78-th combination = (True, False, False, 16, 84, 0.2) \n",
      " train accuracy: [0.39419373869895935, 0.6278485059738159] and test accuracy: [0.2726295590400696, 0.5221394300460815]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "80th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.78348, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.78348 to 0.78245, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.78245\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.78245\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.78245\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.78245\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.78245\n",
      "Epoch 7: early stopping\n",
      "79-th combination = (True, False, False, 16, 365, 0.2) \n",
      " train accuracy: [0.6558093428611755, 0.8098205327987671] and test accuracy: [0.7348453402519226, 0.8572311997413635]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "81th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54675, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54675 to 0.50312, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50312\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50312\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50312\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50312\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50312 to 0.49449, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49449\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49449\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49449\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49449\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49449\n",
      "Epoch 12: early stopping\n",
      "80-th combination = (True, False, False, 32, 7, 0.2) \n",
      " train accuracy: [0.34260624647140503, 0.5853257775306702] and test accuracy: [0.0743134543299675, 0.27260494232177734]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "82th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73925, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73925 to 0.62403, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62403 to 0.57327, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57327 to 0.53344, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.53344\n",
      "\n",
      "Epoch 6: val_loss improved from 0.53344 to 0.51974, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51974\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51974 to 0.51638, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.51638 to 0.50457, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50457\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50457 to 0.50316, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50316\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50316\n",
      "\n",
      "Epoch 14: val_loss improved from 0.50316 to 0.50164, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.50164\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.50164\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.50164\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50164\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.50164\n",
      "Epoch 19: early stopping\n",
      "81-th combination = (True, False, False, 32, 28, 0.2) \n",
      " train accuracy: [0.38123637437820435, 0.6174434423446655] and test accuracy: [0.06039157882332802, 0.24574698507785797]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "83th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57660, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57660 to 0.55198, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55198 to 0.53238, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53238 to 0.53039, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53039 to 0.50242, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50242\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50242 to 0.50196, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50196 to 0.49551, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.49551 to 0.49504, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.49504 to 0.48823, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.48823\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.48823\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.48823\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.48823\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.48823\n",
      "Epoch 15: early stopping\n",
      "82-th combination = (True, False, False, 32, 21, 0.2) \n",
      " train accuracy: [0.38118621706962585, 0.6174027919769287] and test accuracy: [0.020833240821957588, 0.1443372517824173]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "84th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.65087, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.65087\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65087 to 0.57757, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57757 to 0.56637, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.56637\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.56637\n",
      "\n",
      "Epoch 7: val_loss improved from 0.56637 to 0.53983, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.53983\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53983 to 0.53569, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.53569 to 0.53168, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.53168 to 0.53013, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.53013 to 0.52700, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.52700 to 0.51797, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51797\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.51797\n",
      "Epoch 18: early stopping\n",
      "83-th combination = (True, False, False, 32, 84, 0.2) \n",
      " train accuracy: [0.40780705213546753, 0.6385977268218994] and test accuracy: [0.4380895495414734, 0.6618833541870117]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "85th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.77586, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.77586 to 0.71844, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.71844 to 0.67936, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67936 to 0.67034, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.67034\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.67034\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.67034\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.67034\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.67034\n",
      "Epoch 9: early stopping\n",
      "84-th combination = (True, False, False, 32, 365, 0.2) \n",
      " train accuracy: [0.46783414483070374, 0.6839840412139893] and test accuracy: [0.4046751856803894, 0.6361408829689026]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "86th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51977, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51977 to 0.50572, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50572\n",
      "\n",
      "Epoch 4: val_loss improved from 0.50572 to 0.49959, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49959\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49959\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49959\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49959\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49959\n",
      "Epoch 9: early stopping\n",
      "85-th combination = (True, False, False, 64, 7, 0.2) \n",
      " train accuracy: [0.441298246383667, 0.6643028259277344] and test accuracy: [0.18951401114463806, 0.4353320598602295]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "87th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56611, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56611 to 0.56380, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.56380 to 0.56352, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56352 to 0.51341, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51341\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51341 to 0.50723, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50723\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50723\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50723\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50723\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50723\n",
      "Epoch 11: early stopping\n",
      "86-th combination = (True, False, False, 64, 28, 0.2) \n",
      " train accuracy: [0.3806343674659729, 0.6169556975364685] and test accuracy: [0.020853549242019653, 0.14440758526325226]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "88th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54995, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54995 to 0.51850, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51850 to 0.49544, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49544\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49544\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49544\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49544\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49544\n",
      "Epoch 8: early stopping\n",
      "87-th combination = (True, False, False, 64, 21, 0.2) \n",
      " train accuracy: [0.381816029548645, 0.6179126501083374] and test accuracy: [0.03149251267313957, 0.17746129631996155]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "89th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69255, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69255 to 0.56790, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.56790\n",
      "\n",
      "Epoch 4: val_loss improved from 0.56790 to 0.54775, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.54775\n",
      "\n",
      "Epoch 6: val_loss improved from 0.54775 to 0.53409, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.53409 to 0.53377, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.53377 to 0.51753, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51753\n",
      "\n",
      "Epoch 10: val_loss improved from 0.51753 to 0.50421, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 14: val_loss improved from 0.50421 to 0.50187, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.50187 to 0.49840, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49840\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49840\n",
      "\n",
      "Epoch 18: val_loss improved from 0.49840 to 0.49833, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49833\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49833\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49833\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.49833\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.49833\n",
      "Epoch 23: early stopping\n",
      "88-th combination = (True, False, False, 64, 84, 0.2) \n",
      " train accuracy: [0.37649014592170715, 0.6135879158973694] and test accuracy: [0.03026619181036949, 0.17397181689739227]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "90th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52192, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52192 to 0.52015, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52015\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52015\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52015\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52015\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52015\n",
      "Epoch 7: early stopping\n",
      "89-th combination = (True, False, False, 64, 365, 0.2) \n",
      " train accuracy: [0.42446383833885193, 0.6515088677406311] and test accuracy: [0.0895218700170517, 0.2992020547389984]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "91th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60450, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60450 to 0.52251, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52251\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52251\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52251\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52251\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52251\n",
      "Epoch 7: early stopping\n",
      "90-th combination = (True, False, False, 128, 7, 0.2) \n",
      " train accuracy: [0.3546864092350006, 0.5955555438995361] and test accuracy: [0.025478580966591835, 0.15962012112140656]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "92th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55115, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55115 to 0.52611, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52611 to 0.52295, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52295 to 0.50113, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50113\n",
      "Epoch 9: early stopping\n",
      "91-th combination = (True, False, False, 128, 28, 0.2) \n",
      " train accuracy: [0.3811924457550049, 0.6174078583717346] and test accuracy: [0.037501756101846695, 0.19365370273590088]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "93th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50741, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.50741\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50741\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50741\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50741\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50741\n",
      "Epoch 6: early stopping\n",
      "92-th combination = (True, False, False, 128, 21, 0.2) \n",
      " train accuracy: [0.3964485824108124, 0.6296416521072388] and test accuracy: [0.05914424732327461, 0.24319590628147125]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "94th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.59884, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.59884 to 0.53408, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53408\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53408 to 0.53155, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53155 to 0.51711, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51711 to 0.51183, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51183 to 0.51054, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51054\n",
      "\n",
      "Epoch 9: val_loss improved from 0.51054 to 0.50469, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50469\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50469\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50469\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50469\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50469\n",
      "Epoch 14: early stopping\n",
      "93-th combination = (True, False, False, 128, 84, 0.2) \n",
      " train accuracy: [0.3828529119491577, 0.6187511086463928] and test accuracy: [0.02274036779999733, 0.15079909563064575]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "95th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60734, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.60734\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60734 to 0.59181, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.59181 to 0.52481, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.52481 to 0.50303, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50303\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50303\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50303\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50303\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50303\n",
      "Epoch 10: early stopping\n",
      "94-th combination = (True, False, False, 128, 365, 0.2) \n",
      " train accuracy: [0.40138670802116394, 0.6335508823394775] and test accuracy: [0.065376877784729, 0.25568902492523193]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "96th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52886, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52886 to 0.52512, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52512\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52512\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52512\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52512\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52512\n",
      "Epoch 7: early stopping\n",
      "95-th combination = (True, False, False, 256, 7, 0.2) \n",
      " train accuracy: [0.39324086904525757, 0.6270892024040222] and test accuracy: [0.28215500712394714, 0.5311826467514038]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "97th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50858, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.50858\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50858\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50858\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50858\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50858\n",
      "Epoch 6: early stopping\n",
      "96-th combination = (True, False, False, 256, 28, 0.2) \n",
      " train accuracy: [0.4109806418418884, 0.6410776972770691] and test accuracy: [0.049014609307050705, 0.2213924378156662]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "98th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58704, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.58704 to 0.52590, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52590 to 0.52181, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52181\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52181\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52181\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52181\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52181\n",
      "Epoch 8: early stopping\n",
      "97-th combination = (True, False, False, 256, 21, 0.2) \n",
      " train accuracy: [0.4427419602870941, 0.6653885841369629] and test accuracy: [0.21568842232227325, 0.46442267298698425]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "99th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51904, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.51904\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51904 to 0.51120, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51120 to 0.50451, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50451\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50451\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50451\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50451\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50451\n",
      "Epoch 9: early stopping\n",
      "98-th combination = (True, False, False, 256, 84, 0.2) \n",
      " train accuracy: [0.38740256428718567, 0.6224167346954346] and test accuracy: [0.04086606949567795, 0.20215357840061188]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "100th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58477, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.58477\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58477 to 0.51792, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51792 to 0.51121, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51121\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51121\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51121\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51121 to 0.50395, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.50395 to 0.50105, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50105\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50105\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50105\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50105\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50105\n",
      "Epoch 14: early stopping\n",
      "99-th combination = (True, False, False, 256, 365, 0.2) \n",
      " train accuracy: [0.39228782057762146, 0.6263288259506226] and test accuracy: [0.04313865303993225, 0.20769846439361572]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "101th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.79601, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.79601 to 0.69385, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.69385 to 0.60852, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.60852 to 0.59375, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.59375 to 0.57341, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57341\n",
      "\n",
      "Epoch 7: val_loss improved from 0.57341 to 0.55365, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.55365\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.55365\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.55365\n",
      "\n",
      "Epoch 11: val_loss improved from 0.55365 to 0.54973, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.54973\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.54973\n",
      "\n",
      "Epoch 14: val_loss improved from 0.54973 to 0.53715, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.53715\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.53715\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.53715\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.53715\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.53715\n",
      "Epoch 19: early stopping\n",
      "100-th combination = (False, True, True, 16, 7, 0.2) \n",
      " train accuracy: [0.40120476484298706, 0.6334072947502136] and test accuracy: [0.39169415831565857, 0.6258547306060791]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "102th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75135, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.75135 to 0.70009, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.70009 to 0.61696, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.61696 to 0.55196, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.55196 to 0.53314, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.53314 to 0.51899, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51899 to 0.51597, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51597 to 0.50728, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50728\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50728\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50728 to 0.50246, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.50246 to 0.49555, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49555\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49555\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49555\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49555\n",
      "\n",
      "Epoch 17: val_loss improved from 0.49555 to 0.49545, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49545\n",
      "\n",
      "Epoch 19: val_loss improved from 0.49545 to 0.48738, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.48738 to 0.48063, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.48063\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.48063\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.48063\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.48063\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.48063\n",
      "Epoch 25: early stopping\n",
      "101-th combination = (False, True, True, 16, 28, 0.2) \n",
      " train accuracy: [0.37639370560646057, 0.6135093569755554] and test accuracy: [0.08890870958566666, 0.2981756329536438]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "103th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.82105, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.82105 to 0.75907, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.75907 to 0.64691, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.64691 to 0.62845, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.62845 to 0.59944, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.59944 to 0.58096, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.58096\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.58096\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.58096\n",
      "\n",
      "Epoch 10: val_loss improved from 0.58096 to 0.57454, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.57454 to 0.54978, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.54978\n",
      "\n",
      "Epoch 13: val_loss improved from 0.54978 to 0.54923, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.54923\n",
      "\n",
      "Epoch 15: val_loss improved from 0.54923 to 0.53796, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.53796\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.53796\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.53796\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.53796\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.53796\n",
      "Epoch 20: early stopping\n",
      "102-th combination = (False, True, True, 16, 21, 0.2) \n",
      " train accuracy: [0.3893672823905945, 0.6239930391311646] and test accuracy: [0.4622533619403839, 0.6798921823501587]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "104th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73896, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.73896\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.73896\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.73896\n",
      "\n",
      "Epoch 5: val_loss improved from 0.73896 to 0.68175, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68175 to 0.64620, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.64620 to 0.60981, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.60981 to 0.58001, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.58001 to 0.57015, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.57015 to 0.56949, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.56949 to 0.55262, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.55262 to 0.55029, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.55029\n",
      "\n",
      "Epoch 14: val_loss improved from 0.55029 to 0.54138, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.54138 to 0.52271, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.52271 to 0.51956, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51956\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.51956\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.51956\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.51956\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.51956\n",
      "Epoch 21: early stopping\n",
      "103-th combination = (False, True, True, 16, 84, 0.2) \n",
      " train accuracy: [0.3892071843147278, 0.6238647103309631] and test accuracy: [0.19749853014945984, 0.4444080591201782]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "105th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.84644, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.84644\n",
      "Epoch 6: early stopping\n",
      "104-th combination = (False, True, True, 16, 365, 0.2) \n",
      " train accuracy: [0.6881216168403625, 0.8295309543609619] and test accuracy: [0.9535651803016663, 0.9765066504478455]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "106th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67797, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67797 to 0.57597, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57597 to 0.49773, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49773\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49773\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49773\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49773\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49773\n",
      "Epoch 8: early stopping\n",
      "105-th combination = (False, True, True, 32, 7, 0.2) \n",
      " train accuracy: [0.40069088339805603, 0.6330015063285828] and test accuracy: [0.07463326305150986, 0.2731908857822418]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "107th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67086, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67086 to 0.58241, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58241 to 0.53197, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53197 to 0.51935, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51935\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51935 to 0.49776, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49776\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49776\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49776\n",
      "\n",
      "Epoch 10: val_loss improved from 0.49776 to 0.49584, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49584\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49584\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49584\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49584\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49584\n",
      "Epoch 15: early stopping\n",
      "106-th combination = (False, True, True, 32, 28, 0.2) \n",
      " train accuracy: [0.38175517320632935, 0.6178634166717529] and test accuracy: [0.02908865548670292, 0.17055396735668182]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "108th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.65554, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.65554 to 0.56207, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.56207 to 0.51591, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51591\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51591\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51591\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51591\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51591\n",
      "Epoch 8: early stopping\n",
      "107-th combination = (False, True, True, 32, 21, 0.2) \n",
      " train accuracy: [0.39452335238456726, 0.628110945224762] and test accuracy: [0.06113184243440628, 0.2472485452890396]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "109th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66864, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.66864\n",
      "\n",
      "Epoch 3: val_loss improved from 0.66864 to 0.65396, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.65396 to 0.60787, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.60787 to 0.57562, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.57562 to 0.57438, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.57438 to 0.53768, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.53768\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53768 to 0.52901, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52901 to 0.51691, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.51691 to 0.51093, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51093\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51093\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51093\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51093\n",
      "\n",
      "Epoch 16: val_loss improved from 0.51093 to 0.50598, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.50598 to 0.50130, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50130\n",
      "\n",
      "Epoch 19: val_loss improved from 0.50130 to 0.49218, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49218\n",
      "\n",
      "Epoch 21: val_loss improved from 0.49218 to 0.48889, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.48889\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.48889\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.48889\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.48889\n",
      "\n",
      "Epoch 26: val_loss improved from 0.48889 to 0.48794, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.48794\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.48794\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.48794\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.48794\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.48794\n",
      "Epoch 31: early stopping\n",
      "108-th combination = (False, True, True, 32, 84, 0.2) \n",
      " train accuracy: [0.3740142285823822, 0.6115670204162598] and test accuracy: [0.15558665990829468, 0.3944447636604309]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "110th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.83928, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.83928 to 0.82956, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.82956\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.82956\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.82956\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.82956\n",
      "\n",
      "Epoch 7: val_loss improved from 0.82956 to 0.80064, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.80064 to 0.76137, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.76137 to 0.72930, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.72930 to 0.70278, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.70278 to 0.68463, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.68463 to 0.67835, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.67835\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.67835\n",
      "\n",
      "Epoch 15: val_loss improved from 0.67835 to 0.67486, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.67486 to 0.65662, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.65662 to 0.63600, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.63600 to 0.62733, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62733 to 0.62483, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.62483 to 0.62215, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.62215 to 0.61531, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.61531 to 0.60061, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.60061 to 0.58664, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.58664 to 0.57379, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.57379 to 0.55978, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.55978 to 0.55312, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.55312\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.55312\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.55312\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.55312\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.55312\n",
      "Epoch 31: early stopping\n",
      "109-th combination = (False, True, True, 32, 365, 0.2) \n",
      " train accuracy: [0.42161160707473755, 0.6493162512779236] and test accuracy: [0.22887645661830902, 0.4784103333950043]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "111th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53761, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.53761\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53761 to 0.49987, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49987\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49987\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49987\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49987\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49987\n",
      "Epoch 8: early stopping\n",
      "110-th combination = (False, True, True, 64, 7, 0.2) \n",
      " train accuracy: [0.38387787342071533, 0.6195787787437439] and test accuracy: [0.038609977811574936, 0.1964942216873169]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "112th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57660, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.57660\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57660 to 0.49676, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49676\n",
      "\n",
      "Epoch 5: val_loss improved from 0.49676 to 0.49009, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49009\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49009\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49009\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49009\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49009\n",
      "Epoch 10: early stopping\n",
      "111-th combination = (False, True, True, 64, 28, 0.2) \n",
      " train accuracy: [0.3867499828338623, 0.6218922734260559] and test accuracy: [0.024017097428441048, 0.15497450530529022]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "113th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60172, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60172 to 0.53342, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53342\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53342 to 0.52106, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52106\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52106 to 0.48802, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.48802\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.48802\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.48802\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.48802\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.48802\n",
      "Epoch 11: early stopping\n",
      "112-th combination = (False, True, True, 64, 21, 0.2) \n",
      " train accuracy: [0.3774813711643219, 0.6143951416015625] and test accuracy: [0.025727542117238045, 0.16039808094501495]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "114th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69012, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69012 to 0.53437, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53437\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.53437\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53437 to 0.50447, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50447\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50447\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50447\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50447\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50447\n",
      "Epoch 10: early stopping\n",
      "113-th combination = (False, True, True, 64, 84, 0.2) \n",
      " train accuracy: [0.40884190797805786, 0.6394074559211731] and test accuracy: [0.020047321915626526, 0.14158856868743896]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "115th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60231, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60231 to 0.57046, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.57046\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57046\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57046\n",
      "\n",
      "Epoch 6: val_loss improved from 0.57046 to 0.55249, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.55249 to 0.53965, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.53965 to 0.53415, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53415 to 0.53120, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.53120 to 0.53021, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.53021\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.53021\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.53021\n",
      "\n",
      "Epoch 14: val_loss improved from 0.53021 to 0.52342, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.52342 to 0.51092, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.51092 to 0.49641, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.49641 to 0.49488, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49488\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49488\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49488\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49488\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.49488\n",
      "Epoch 22: early stopping\n",
      "114-th combination = (False, True, True, 64, 365, 0.2) \n",
      " train accuracy: [0.38123902678489685, 0.6174455881118774] and test accuracy: [0.03272401914000511, 0.1808978170156479]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "116th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56131, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56131 to 0.49633, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49633\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49633\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49633\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49633\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49633\n",
      "Epoch 7: early stopping\n",
      "115-th combination = (False, True, True, 128, 7, 0.2) \n",
      " train accuracy: [0.34584948420524597, 0.5880897045135498] and test accuracy: [0.021739110350608826, 0.14744189381599426]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "117th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53107, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.53107 to 0.49891, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49891\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49891\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49891\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49891\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49891\n",
      "Epoch 7: early stopping\n",
      "116-th combination = (False, True, True, 128, 28, 0.2) \n",
      " train accuracy: [0.40602514147758484, 0.6372010111808777] and test accuracy: [0.09235334396362305, 0.3038969337940216]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "118th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55980, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55980 to 0.50689, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.50689 to 0.49342, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49342\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49342\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49342\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49342\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49342\n",
      "Epoch 8: early stopping\n",
      "117-th combination = (False, True, True, 128, 21, 0.2) \n",
      " train accuracy: [0.3897719979286194, 0.6243172287940979] and test accuracy: [0.029225071892142296, 0.1709534227848053]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "119th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55899, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55899 to 0.55415, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.55415\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55415 to 0.50794, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50794\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50794\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50794 to 0.50745, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50745\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50745\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50745 to 0.50113, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50113\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.50113\n",
      "Epoch 15: early stopping\n",
      "118-th combination = (False, True, True, 128, 84, 0.2) \n",
      " train accuracy: [0.4247056245803833, 0.6516944169998169] and test accuracy: [0.08013363927602768, 0.2830788493156433]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "120th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61924, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.61924\n",
      "\n",
      "Epoch 3: val_loss improved from 0.61924 to 0.55291, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55291 to 0.51770, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51770\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51770\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51770\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51770\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51770\n",
      "Epoch 9: early stopping\n",
      "119-th combination = (False, True, True, 128, 365, 0.2) \n",
      " train accuracy: [0.40547654032707214, 0.6367704272270203] and test accuracy: [0.019572967663407326, 0.13990342617034912]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "121th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58824, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.58824 to 0.54625, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54625\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.54625\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.54625\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.54625\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.54625\n",
      "Epoch 7: early stopping\n",
      "120-th combination = (False, True, True, 256, 7, 0.2) \n",
      " train accuracy: [0.2838871479034424, 0.532810628414154] and test accuracy: [0.023296426981687546, 0.15263167023658752]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "122th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52748, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52748 to 0.51466, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51466\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51466\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51466\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51466\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51466\n",
      "Epoch 7: early stopping\n",
      "121-th combination = (False, True, True, 256, 28, 0.2) \n",
      " train accuracy: [0.4080803692340851, 0.6388117074966431] and test accuracy: [0.037117425352334976, 0.19265882670879364]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "123th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73468, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73468 to 0.52025, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52025\n",
      "Epoch 7: early stopping\n",
      "122-th combination = (False, True, True, 256, 21, 0.2) \n",
      " train accuracy: [0.4067923128604889, 0.6378027200698853] and test accuracy: [0.07140345871448517, 0.26721426844596863]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "124th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67869, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67869 to 0.62658, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62658 to 0.56820, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.56820\n",
      "\n",
      "Epoch 5: val_loss improved from 0.56820 to 0.54467, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.54467\n",
      "\n",
      "Epoch 7: val_loss improved from 0.54467 to 0.52438, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52438\n",
      "\n",
      "Epoch 9: val_loss improved from 0.52438 to 0.50983, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50983\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50983\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50983\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50983\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.50983\n",
      "Epoch 14: early stopping\n",
      "123-th combination = (False, True, True, 256, 84, 0.2) \n",
      " train accuracy: [0.3860648572444916, 0.6213411688804626] and test accuracy: [0.02437628246843815, 0.15612906217575073]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "125th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58026, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.58026\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.58026\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58026 to 0.52470, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52470\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52470\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52470\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52470\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52470\n",
      "Epoch 9: early stopping\n",
      "124-th combination = (False, True, True, 256, 365, 0.2) \n",
      " train accuracy: [0.429198294878006, 0.6551322937011719] and test accuracy: [0.13915102183818817, 0.37302953004837036]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "126th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62598, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62598 to 0.54532, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54532\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.54532\n",
      "\n",
      "Epoch 5: val_loss improved from 0.54532 to 0.54156, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.54156 to 0.52793, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52793 to 0.51948, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51948\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51948\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51948\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51948\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51948\n",
      "Epoch 12: early stopping\n",
      "125-th combination = (False, True, False, 16, 7, 0.2) \n",
      " train accuracy: [0.39981889724731445, 0.6323123574256897] and test accuracy: [0.02034253254532814, 0.14262725412845612]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "127th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.77942, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.77942 to 0.65059, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65059 to 0.57609, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57609 to 0.54941, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.54941 to 0.52318, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52318 to 0.51893, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51893 to 0.51308, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51308 to 0.50115, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50115\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50115\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50115 to 0.49912, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49912\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49912\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49912\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49912\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49912\n",
      "Epoch 16: early stopping\n",
      "126-th combination = (False, True, False, 16, 28, 0.2) \n",
      " train accuracy: [0.38649851083755493, 0.621690034866333] and test accuracy: [0.02199382334947586, 0.14830315113067627]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "128th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.90676, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.90676 to 0.76743, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.76743 to 0.69641, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.69641 to 0.65275, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.65275 to 0.63457, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.63457 to 0.62563, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.62563 to 0.61110, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.61110 to 0.59743, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.59743 to 0.59406, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.59406\n",
      "\n",
      "Epoch 11: val_loss improved from 0.59406 to 0.58693, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.58693 to 0.57834, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.57834\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.57834\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.57834\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.57834\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.57834\n",
      "Epoch 17: early stopping\n",
      "127-th combination = (False, True, False, 16, 21, 0.2) \n",
      " train accuracy: [0.40947529673576355, 0.6399025917053223] and test accuracy: [0.31696298718452454, 0.562994658946991]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "129th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.74297, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.74297 to 0.72568, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.72568\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.72568\n",
      "\n",
      "Epoch 5: val_loss improved from 0.72568 to 0.71287, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.71287 to 0.68733, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.68733 to 0.66921, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66921 to 0.66677, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66677 to 0.64283, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.64283 to 0.62633, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.62633 to 0.61912, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.61912 to 0.60657, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.60657 to 0.60236, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.60236 to 0.59185, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.59185 to 0.58347, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.58347\n",
      "\n",
      "Epoch 17: val_loss improved from 0.58347 to 0.57377, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.57377 to 0.55968, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.55968\n",
      "\n",
      "Epoch 20: val_loss improved from 0.55968 to 0.55805, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.55805 to 0.55648, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.55648 to 0.55210, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.55210 to 0.54445, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.54445\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.54445\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.54445\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.54445\n",
      "\n",
      "Epoch 28: val_loss improved from 0.54445 to 0.53717, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.53717\n",
      "\n",
      "Epoch 30: val_loss improved from 0.53717 to 0.53632, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.53632 to 0.52951, saving model to best_model.h5\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.52951\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.52951\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.52951\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.52951\n",
      "\n",
      "Epoch 36: val_loss improved from 0.52951 to 0.52640, saving model to best_model.h5\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.52640\n",
      "\n",
      "Epoch 38: val_loss improved from 0.52640 to 0.52467, saving model to best_model.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.52467 to 0.52286, saving model to best_model.h5\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.52286\n",
      "128-th combination = (False, True, False, 16, 84, 0.2) \n",
      " train accuracy: [0.3869972229003906, 0.6220909953117371] and test accuracy: [0.30701538920402527, 0.5540896654129028]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "130th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85777, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.85777 to 0.83703, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.83703 to 0.82066, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.82066 to 0.80879, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.80879 to 0.80467, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.80467\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.80467\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.80467\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.80467\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.80467\n",
      "Epoch 10: early stopping\n",
      "129-th combination = (False, True, False, 16, 365, 0.2) \n",
      " train accuracy: [0.5401083827018738, 0.7349206805229187] and test accuracy: [0.5726462602615356, 0.7567339539527893]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "131th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57970, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57970 to 0.52542, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52542\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52542 to 0.51547, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51547\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51547 to 0.49879, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49879\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49879\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49879\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49879\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49879\n",
      "Epoch 11: early stopping\n",
      "130-th combination = (False, True, False, 32, 7, 0.2) \n",
      " train accuracy: [0.37630683183670044, 0.6134385466575623] and test accuracy: [0.04882023483514786, 0.22095301747322083]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "132th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66181, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66181 to 0.57551, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.57551 to 0.55443, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55443 to 0.54360, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.54360 to 0.52918, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52918\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52918 to 0.52663, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.52663 to 0.51705, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51705\n",
      "\n",
      "Epoch 10: val_loss improved from 0.51705 to 0.51118, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51118\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51118\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51118\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51118\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51118\n",
      "Epoch 15: early stopping\n",
      "131-th combination = (False, True, False, 32, 28, 0.2) \n",
      " train accuracy: [0.3897849917411804, 0.6243276596069336] and test accuracy: [0.08071967959403992, 0.2841120958328247]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "133th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54604, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54604 to 0.54128, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54128 to 0.53768, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53768 to 0.51453, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51453\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51453\n",
      "\n",
      "Epoch 7: val_loss improved from 0.51453 to 0.50618, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50618\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50618\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50618 to 0.49746, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49746\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49746\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49746\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49746\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49746\n",
      "Epoch 15: early stopping\n",
      "132-th combination = (False, True, False, 32, 21, 0.2) \n",
      " train accuracy: [0.4050593674182892, 0.6364427208900452] and test accuracy: [0.044721122831106186, 0.21147368848323822]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "134th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63300, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.63300\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63300 to 0.57050, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57050 to 0.55457, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55457\n",
      "\n",
      "Epoch 6: val_loss improved from 0.55457 to 0.54925, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.54925 to 0.53916, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.53916 to 0.53357, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.53357\n",
      "\n",
      "Epoch 10: val_loss improved from 0.53357 to 0.52297, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.52297 to 0.51305, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51305\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51305\n",
      "\n",
      "Epoch 14: val_loss improved from 0.51305 to 0.51289, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51289\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51289\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51289\n",
      "\n",
      "Epoch 18: val_loss improved from 0.51289 to 0.50584, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.50584 to 0.50214, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50214\n",
      "\n",
      "Epoch 21: val_loss improved from 0.50214 to 0.50181, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.50181\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.50181\n",
      "\n",
      "Epoch 24: val_loss improved from 0.50181 to 0.49814, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.49814 to 0.49748, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.49748 to 0.49445, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.49445\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.49445\n",
      "\n",
      "Epoch 29: val_loss improved from 0.49445 to 0.49278, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.49278\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.49278\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.49278\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.49278\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.49278\n",
      "Epoch 34: early stopping\n",
      "133-th combination = (False, True, False, 32, 84, 0.2) \n",
      " train accuracy: [0.3744131624698639, 0.6118931174278259] and test accuracy: [0.12787464261054993, 0.35759565234184265]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "135th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.78807, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.78807 to 0.76016, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.76016\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.76016\n",
      "\n",
      "Epoch 5: val_loss improved from 0.76016 to 0.74339, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.74339 to 0.71673, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.71673 to 0.68978, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.68978 to 0.66764, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66764 to 0.65330, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65330 to 0.64858, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.64858\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.64858\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.64858\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.64858\n",
      "\n",
      "Epoch 15: val_loss improved from 0.64858 to 0.63928, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.63928 to 0.62948, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.62948 to 0.62687, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.62687\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.62687\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.62687\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.62687\n",
      "\n",
      "Epoch 22: val_loss improved from 0.62687 to 0.61717, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.61717 to 0.61146, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.61146 to 0.60558, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.60558 to 0.59885, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.59885 to 0.59197, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.59197 to 0.58661, saving model to best_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.58661 to 0.58206, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.58206 to 0.57649, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.57649 to 0.57510, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.57510\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.57510\n",
      "\n",
      "Epoch 33: val_loss improved from 0.57510 to 0.56989, saving model to best_model.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.56989 to 0.56261, saving model to best_model.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.56261 to 0.55550, saving model to best_model.h5\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.55550\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.55550\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.55550\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.55550\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.55550\n",
      "Epoch 40: early stopping\n",
      "134-th combination = (False, True, False, 32, 365, 0.2) \n",
      " train accuracy: [0.4101797640323639, 0.6404528021812439] and test accuracy: [0.2304399311542511, 0.48004159331321716]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "136th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49871, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.49871\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49871\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49871\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49871\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49871\n",
      "Epoch 6: early stopping\n",
      "135-th combination = (False, True, False, 64, 7, 0.2) \n",
      " train accuracy: [0.3949202597141266, 0.6284267902374268] and test accuracy: [0.041050124913454056, 0.20260830223560333]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "137th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54650, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.54650\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54650 to 0.51208, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51208 to 0.51182, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51182\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51182 to 0.49992, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49992\n",
      "\n",
      "Epoch 8: val_loss improved from 0.49992 to 0.49854, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49854\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49854\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49854\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49854\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49854\n",
      "Epoch 13: early stopping\n",
      "136-th combination = (False, True, False, 64, 28, 0.2) \n",
      " train accuracy: [0.3772220313549042, 0.6141840219497681] and test accuracy: [0.028227021917700768, 0.16800899803638458]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "138th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52311, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52311 to 0.49918, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49918\n",
      "\n",
      "Epoch 4: val_loss improved from 0.49918 to 0.49465, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49465\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49465\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49465\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49465\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49465\n",
      "Epoch 9: early stopping\n",
      "137-th combination = (False, True, False, 64, 21, 0.2) \n",
      " train accuracy: [0.3826282024383545, 0.6185694932937622] and test accuracy: [0.021105702966451645, 0.14527802169322968]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "139th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.77979, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.77979 to 0.65251, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65251 to 0.58915, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.58915\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.58915\n",
      "\n",
      "Epoch 6: val_loss improved from 0.58915 to 0.58562, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.58562 to 0.56448, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.56448\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.56448\n",
      "\n",
      "Epoch 10: val_loss improved from 0.56448 to 0.54146, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.54146\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.54146\n",
      "\n",
      "Epoch 13: val_loss improved from 0.54146 to 0.52882, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.52882\n",
      "\n",
      "Epoch 15: val_loss improved from 0.52882 to 0.52667, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.52667\n",
      "\n",
      "Epoch 17: val_loss improved from 0.52667 to 0.52279, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.52279 to 0.51683, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.51683\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.51683\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.51683\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.51683\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.51683\n",
      "Epoch 23: early stopping\n",
      "138-th combination = (False, True, False, 64, 84, 0.2) \n",
      " train accuracy: [0.3851715922355652, 0.620621919631958] and test accuracy: [0.12072626501321793, 0.34745684266090393]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "140th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66365, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66365 to 0.63971, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.63971\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.63971\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.63971\n",
      "\n",
      "Epoch 6: val_loss improved from 0.63971 to 0.63431, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.63431 to 0.59498, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.59498 to 0.57497, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.57497 to 0.57457, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.57457\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.57457\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.57457\n",
      "\n",
      "Epoch 13: val_loss improved from 0.57457 to 0.57085, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.57085 to 0.56412, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.56412 to 0.55456, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.55456 to 0.54097, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.54097 to 0.53452, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.53452\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.53452\n",
      "\n",
      "Epoch 20: val_loss improved from 0.53452 to 0.53311, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.53311 to 0.51966, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.51966 to 0.51675, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.51675\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.51675\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.51675\n",
      "\n",
      "Epoch 26: val_loss improved from 0.51675 to 0.51379, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.51379 to 0.51247, saving model to best_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.51247 to 0.51019, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.51019\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.51019\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.51019\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.51019\n",
      "\n",
      "Epoch 33: val_loss improved from 0.51019 to 0.50352, saving model to best_model.h5\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.50352\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.50352\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.50352\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.50352\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.50352\n",
      "Epoch 38: early stopping\n",
      "139-th combination = (False, True, False, 64, 365, 0.2) \n",
      " train accuracy: [0.3822696805000305, 0.6182796359062195] and test accuracy: [0.10234712809324265, 0.31991738080978394]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "141th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52330, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52330\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52330 to 0.51743, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51743\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51743\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51743\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51743\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51743\n",
      "Epoch 8: early stopping\n",
      "140-th combination = (False, True, False, 128, 7, 0.2) \n",
      " train accuracy: [0.343056857585907, 0.5857105851173401] and test accuracy: [0.0498284250497818, 0.22322282195091248]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "142th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54455, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.54455\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54455 to 0.54071, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.54071 to 0.52820, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52820\n",
      "\n",
      "Epoch 6: val_loss improved from 0.52820 to 0.51051, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51051\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51051\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51051\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.51051\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51051\n",
      "Epoch 11: early stopping\n",
      "141-th combination = (False, True, False, 128, 28, 0.2) \n",
      " train accuracy: [0.37674272060394287, 0.6137937307357788] and test accuracy: [0.04112105071544647, 0.2027832567691803]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "143th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51641, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51641 to 0.49163, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49163\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49163\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49163\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49163\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49163\n",
      "Epoch 7: early stopping\n",
      "142-th combination = (False, True, False, 128, 21, 0.2) \n",
      " train accuracy: [0.396515429019928, 0.6296947002410889] and test accuracy: [0.023590218275785446, 0.1535910815000534]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "144th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57554, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57554 to 0.51058, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51058\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51058 to 0.50497, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50497\n",
      "\n",
      "Epoch 6: val_loss improved from 0.50497 to 0.49224, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49224\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49224\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49224\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49224\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49224\n",
      "Epoch 11: early stopping\n",
      "143-th combination = (False, True, False, 128, 84, 0.2) \n",
      " train accuracy: [0.38622352480888367, 0.6214688420295715] and test accuracy: [0.021821122616529465, 0.14771974086761475]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "145th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63069, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63069 to 0.58699, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58699 to 0.57461, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.57461 to 0.52999, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.52999 to 0.52555, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52555\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52555\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52555\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52555\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.52555\n",
      "Epoch 10: early stopping\n",
      "144-th combination = (False, True, False, 128, 365, 0.2) \n",
      " train accuracy: [0.4039545953273773, 0.635574221611023] and test accuracy: [0.02075185440480709, 0.14405503869056702]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "146th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51896, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.51896\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51896\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51896\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51896\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51896\n",
      "Epoch 6: early stopping\n",
      "145-th combination = (False, True, False, 256, 7, 0.2) \n",
      " train accuracy: [0.4879491627216339, 0.6985335946083069] and test accuracy: [0.1692401021718979, 0.41138800978660583]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "147th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51643, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51643 to 0.51138, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51138 to 0.50119, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50119\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50119\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50119\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50119\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50119\n",
      "Epoch 8: early stopping\n",
      "146-th combination = (False, True, False, 256, 28, 0.2) \n",
      " train accuracy: [0.38805216550827026, 0.622938334941864] and test accuracy: [0.1056162416934967, 0.3249865174293518]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "148th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54476, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54476 to 0.50680, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50680\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50680\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50680\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50680\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50680\n",
      "Epoch 7: early stopping\n",
      "147-th combination = (False, True, False, 256, 21, 0.2) \n",
      " train accuracy: [0.3710775375366211, 0.6091613173484802] and test accuracy: [0.023728881031274796, 0.1540418118238449]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "149th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49631, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.49631\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49631\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49631\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49631\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49631\n",
      "Epoch 6: early stopping\n",
      "148-th combination = (False, True, False, 256, 84, 0.2) \n",
      " train accuracy: [0.4011496901512146, 0.6333637833595276] and test accuracy: [0.021198904141783714, 0.14559844136238098]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "150th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69577, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69577 to 0.62240, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62240 to 0.54230, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.54230 to 0.51432, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51432\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51432\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51432\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.51432\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.51432\n",
      "Epoch 9: early stopping\n",
      "149-th combination = (False, True, False, 256, 365, 0.2) \n",
      " train accuracy: [0.40057292580604553, 0.632908284664154] and test accuracy: [0.023474998772144318, 0.15321552753448486]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "151th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.59989, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.59989 to 0.58043, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58043 to 0.51877, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51877 to 0.49991, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.49991 to 0.49266, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49266\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49266\n",
      "\n",
      "Epoch 8: val_loss improved from 0.49266 to 0.48853, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.48853\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.48853\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.48853\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.48853\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.48853\n",
      "Epoch 13: early stopping\n",
      "150-th combination = (False, False, True, 16, 7, 0.2) \n",
      " train accuracy: [0.3689126670360565, 0.6073818206787109] and test accuracy: [0.0260621290653944, 0.16143769025802612]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "152th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.72839, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.72839 to 0.63482, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63482 to 0.55422, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55422 to 0.53137, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.53137 to 0.51021, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.51021 to 0.50782, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50782 to 0.50750, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50750 to 0.49899, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49899\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49899\n",
      "\n",
      "Epoch 11: val_loss improved from 0.49899 to 0.49530, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.49530 to 0.49377, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49377\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49377\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49377\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49377\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49377\n",
      "Epoch 17: early stopping\n",
      "151-th combination = (False, False, True, 16, 28, 0.2) \n",
      " train accuracy: [0.38485032320022583, 0.6203630566596985] and test accuracy: [0.08033556491136551, 0.28343528509140015]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "153th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61671, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61671 to 0.52084, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52084 to 0.49239, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.49239 to 0.48521, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.48521 to 0.47951, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.47951\n",
      "\n",
      "Epoch 7: val_loss improved from 0.47951 to 0.47814, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.47814 to 0.47708, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.47708\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.47708\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.47708\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.47708\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.47708\n",
      "Epoch 13: early stopping\n",
      "152-th combination = (False, False, True, 16, 21, 0.2) \n",
      " train accuracy: [0.390455961227417, 0.6248647570610046] and test accuracy: [0.060438770800828934, 0.24584297835826874]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "154th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85191, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.85191 to 0.81999, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.81999\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.81999\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.81999\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.81999\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.81999\n",
      "Epoch 7: early stopping\n",
      "153-th combination = (False, False, True, 16, 84, 0.2) \n",
      " train accuracy: [0.5346857309341431, 0.7312220931053162] and test accuracy: [0.8964783549308777, 0.946825385093689]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "155th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.82418, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.82418\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.82418\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.82418\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.82418\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.82418\n",
      "Epoch 6: early stopping\n",
      "154-th combination = (False, False, True, 16, 365, 0.2) \n",
      " train accuracy: [0.6191141605377197, 0.7868380546569824] and test accuracy: [0.7474299073219299, 0.8645402789115906]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "156th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57755, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57755 to 0.55827, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55827 to 0.53971, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53971 to 0.52211, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52211\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52211\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52211\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52211\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.52211\n",
      "Epoch 9: early stopping\n",
      "155-th combination = (False, False, True, 32, 7, 0.2) \n",
      " train accuracy: [0.37494078278541565, 0.612324059009552] and test accuracy: [0.02420041896402836, 0.15556484460830688]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "157th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61048, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.61048 to 0.53137, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53137\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53137 to 0.49925, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49925\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49925\n",
      "\n",
      "Epoch 7: val_loss improved from 0.49925 to 0.49228, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49228\n",
      "\n",
      "Epoch 9: val_loss improved from 0.49228 to 0.49072, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.49072 to 0.48994, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.48994\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.48994\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.48994\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.48994\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.48994\n",
      "Epoch 15: early stopping\n",
      "156-th combination = (False, False, True, 32, 28, 0.2) \n",
      " train accuracy: [0.3741946220397949, 0.6117144823074341] and test accuracy: [0.0224580317735672, 0.14986003935337067]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "158th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57840, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57840 to 0.53625, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53625 to 0.52716, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52716 to 0.51131, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51131 to 0.50272, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50272\n",
      "\n",
      "Epoch 7: val_loss improved from 0.50272 to 0.50270, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50270 to 0.49576, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49576\n",
      "\n",
      "Epoch 10: val_loss improved from 0.49576 to 0.49530, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49530\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49530\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49530\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49530\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49530\n",
      "Epoch 15: early stopping\n",
      "157-th combination = (False, False, True, 32, 21, 0.2) \n",
      " train accuracy: [0.3800017237663269, 0.6164427995681763] and test accuracy: [0.0246958676725626, 0.15714919567108154]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "159th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.65554, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.65554\n",
      "\n",
      "Epoch 3: val_loss improved from 0.65554 to 0.61192, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.61192 to 0.57782, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57782\n",
      "\n",
      "Epoch 6: val_loss improved from 0.57782 to 0.56726, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.56726 to 0.54019, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54019 to 0.52985, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.52985 to 0.52973, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52973 to 0.52159, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.52159 to 0.52026, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.52026 to 0.51037, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51037\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51037\n",
      "\n",
      "Epoch 15: val_loss improved from 0.51037 to 0.50387, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.50387\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.50387\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50387\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.50387\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50387\n",
      "Epoch 20: early stopping\n",
      "158-th combination = (False, False, True, 32, 84, 0.2) \n",
      " train accuracy: [0.3971233367919922, 0.6301771998405457] and test accuracy: [0.04026855155825615, 0.2006702572107315]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "160th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.74201, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.74201 to 0.69911, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.69911 to 0.68993, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.68993\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.68993\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.68993\n",
      "\n",
      "Epoch 7: val_loss improved from 0.68993 to 0.65897, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.65897 to 0.62803, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.62803 to 0.59970, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.59970 to 0.57962, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.57962 to 0.57432, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.57432 to 0.57426, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.57426\n",
      "\n",
      "Epoch 14: val_loss improved from 0.57426 to 0.57334, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.57334 to 0.56190, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.56190 to 0.54890, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.54890 to 0.54107, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.54107 to 0.53886, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.53886 to 0.53706, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.53706 to 0.53222, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.53222 to 0.52967, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.52967 to 0.52546, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.52546 to 0.52099, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.52099 to 0.51856, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.51856 to 0.51535, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.51535 to 0.50960, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.50960 to 0.50582, saving model to best_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.50582 to 0.50385, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.50385 to 0.49920, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.49920 to 0.49647, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.49647 to 0.49576, saving model to best_model.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.49576 to 0.49361, saving model to best_model.h5\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.49361\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.49361\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.49361\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.49361\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.49361\n",
      "Epoch 37: early stopping\n",
      "159-th combination = (False, False, True, 32, 365, 0.2) \n",
      " train accuracy: [0.38602912425994873, 0.6213124394416809] and test accuracy: [0.07530367374420166, 0.27441513538360596]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "161th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51267, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51267 to 0.50253, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.50253 to 0.50047, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50047\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50047\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50047\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50047\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50047\n",
      "Epoch 8: early stopping\n",
      "160-th combination = (False, False, True, 64, 7, 0.2) \n",
      " train accuracy: [0.34798669815063477, 0.5899039506912231] and test accuracy: [0.09121055901050568, 0.3020108640193939]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "162th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52181, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52181\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52181 to 0.50151, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50151\n",
      "\n",
      "Epoch 5: val_loss improved from 0.50151 to 0.49286, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49286\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49286\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49286\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49286\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49286\n",
      "Epoch 10: early stopping\n",
      "161-th combination = (False, False, True, 64, 28, 0.2) \n",
      " train accuracy: [0.38530614972114563, 0.6207303404808044] and test accuracy: [0.03105950355529785, 0.1762370616197586]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "163th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51302, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.51302\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51302 to 0.50290, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50290\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50290\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50290\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50290\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50290\n",
      "Epoch 8: early stopping\n",
      "162-th combination = (False, False, True, 64, 21, 0.2) \n",
      " train accuracy: [0.3934341073036194, 0.6272432804107666] and test accuracy: [0.027153993025422096, 0.16478468477725983]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "164th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56634, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56634 to 0.51463, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51463 to 0.49617, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49617\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49617\n",
      "\n",
      "Epoch 6: val_loss improved from 0.49617 to 0.49181, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49181\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49181\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49181\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49181\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49181\n",
      "Epoch 11: early stopping\n",
      "163-th combination = (False, False, True, 64, 84, 0.2) \n",
      " train accuracy: [0.39805030822753906, 0.6309123039245605] and test accuracy: [0.04698237031698227, 0.21675416827201843]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "165th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73410, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73410 to 0.70583, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.70583\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.70583\n",
      "\n",
      "Epoch 5: val_loss improved from 0.70583 to 0.68739, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68739 to 0.61243, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.61243 to 0.55525, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.55525 to 0.53347, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.53347\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.53347\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.53347\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.53347\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.53347\n",
      "Epoch 13: early stopping\n",
      "164-th combination = (False, False, True, 64, 365, 0.2) \n",
      " train accuracy: [0.4051802456378937, 0.6365377306938171] and test accuracy: [0.13127733767032623, 0.3623221516609192]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "166th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49142, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.49142\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49142\n",
      "Epoch 6: early stopping\n",
      "165-th combination = (False, False, True, 128, 7, 0.2) \n",
      " train accuracy: [0.38771703839302063, 0.6226692795753479] and test accuracy: [0.0470355749130249, 0.21687686443328857]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "167th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50026, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.50026 to 0.49450, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49450\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49450\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49450\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49450\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49450\n",
      "Epoch 7: early stopping\n",
      "166-th combination = (False, False, True, 128, 28, 0.2) \n",
      " train accuracy: [0.36596089601516724, 0.604947030544281] and test accuracy: [0.04167519137263298, 0.20414502918720245]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "168th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54872, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54872 to 0.52559, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52559 to 0.49487, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49487\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49487\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49487\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49487\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49487\n",
      "Epoch 8: early stopping\n",
      "167-th combination = (False, False, True, 128, 21, 0.2) \n",
      " train accuracy: [0.370254784822464, 0.6084856390953064] and test accuracy: [0.03796044737100601, 0.1948344111442566]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "169th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57475, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57475 to 0.55055, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55055 to 0.51664, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51664\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51664 to 0.50421, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50421\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50421\n",
      "Epoch 10: early stopping\n",
      "168-th combination = (False, False, True, 128, 84, 0.2) \n",
      " train accuracy: [0.4031040072441101, 0.6349047422409058] and test accuracy: [0.07079654186964035, 0.2660762071609497]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "170th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53617, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.53617\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53617\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53617 to 0.49868, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.49868 to 0.49469, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49469\n",
      "Epoch 10: early stopping\n",
      "169-th combination = (False, False, True, 128, 365, 0.2) \n",
      " train accuracy: [0.38833722472190857, 0.623167097568512] and test accuracy: [0.024845100939273834, 0.157623291015625]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "171th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54823, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.54823\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54823\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.54823\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.54823\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.54823\n",
      "Epoch 6: early stopping\n",
      "170-th combination = (False, False, True, 256, 7, 0.2) \n",
      " train accuracy: [0.3012560307979584, 0.54886794090271] and test accuracy: [0.022912267595529556, 0.15136799216270447]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "172th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.64090, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.64090 to 0.58446, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.58446 to 0.55212, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.55212\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55212\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.55212\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.55212\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.55212\n",
      "Epoch 8: early stopping\n",
      "171-th combination = (False, False, True, 256, 28, 0.2) \n",
      " train accuracy: [0.3839516341686249, 0.6196383237838745] and test accuracy: [0.02396218478679657, 0.1547972410917282]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "173th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54748, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.54748\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54748 to 0.52626, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52626\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52626\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52626\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52626\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52626\n",
      "Epoch 8: early stopping\n",
      "172-th combination = (False, False, True, 256, 21, 0.2) \n",
      " train accuracy: [0.4341020882129669, 0.6588642597198486] and test accuracy: [0.2941230833530426, 0.5423311591148376]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "174th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55296, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.55296\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55296 to 0.50428, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50428\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50428\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50428\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50428\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50428\n",
      "Epoch 8: early stopping\n",
      "173-th combination = (False, False, True, 256, 84, 0.2) \n",
      " train accuracy: [0.3940749764442444, 0.6277539134025574] and test accuracy: [0.024585694074630737, 0.15679825842380524]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "175th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62586, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62586 to 0.51538, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.51538 to 0.50700, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50700\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50700\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50700\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50700\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50700\n",
      "Epoch 8: early stopping\n",
      "174-th combination = (False, False, True, 256, 365, 0.2) \n",
      " train accuracy: [0.39469724893569946, 0.6282493472099304] and test accuracy: [0.049691904336214066, 0.22291681170463562]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "176th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55178, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55178 to 0.54267, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54267 to 0.51576, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51576\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51576 to 0.49180, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49180\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49180\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49180\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49180\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49180\n",
      "Epoch 10: early stopping\n",
      "175-th combination = (False, False, False, 16, 7, 0.2) \n",
      " train accuracy: [0.3698202669620514, 0.6081284880638123] and test accuracy: [0.13559964299201965, 0.36823856830596924]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "177th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.85912, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.85912\n",
      "\n",
      "Epoch 3: val_loss improved from 0.85912 to 0.84850, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.84850 to 0.80213, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.80213 to 0.74406, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.74406 to 0.71362, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.71362 to 0.70089, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.70089 to 0.66672, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66672 to 0.65313, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65313 to 0.65045, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65045 to 0.62841, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.62841 to 0.61976, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.61976 to 0.60904, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.60904 to 0.60648, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.60648 to 0.59569, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.59569 to 0.58577, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.58577 to 0.58158, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.58158 to 0.57186, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.57186 to 0.56934, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.56934\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.56934\n",
      "\n",
      "Epoch 22: val_loss improved from 0.56934 to 0.56344, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.56344 to 0.56269, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.56269 to 0.55667, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.55667 to 0.55408, saving model to best_model.h5\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.55408\n",
      "\n",
      "Epoch 27: val_loss improved from 0.55408 to 0.55089, saving model to best_model.h5\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.55089\n",
      "\n",
      "Epoch 29: val_loss improved from 0.55089 to 0.54918, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.54918 to 0.54400, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.54400\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.54400\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.54400\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.54400\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.54400\n",
      "Epoch 35: early stopping\n",
      "176-th combination = (False, False, False, 16, 28, 0.2) \n",
      " train accuracy: [0.36018645763397217, 0.6001553535461426] and test accuracy: [0.44553589820861816, 0.6674847602844238]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "178th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.83296, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.83296\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.83296\n",
      "\n",
      "Epoch 4: val_loss improved from 0.83296 to 0.81986, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.81986 to 0.76906, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.76906 to 0.73295, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.73295 to 0.71826, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.71826 to 0.69972, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.69972 to 0.67491, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67491 to 0.65956, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65956 to 0.65231, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65231 to 0.64138, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.64138 to 0.62644, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.62644 to 0.59577, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.59577\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.59577\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.59577\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.59577\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.59577\n",
      "Epoch 19: early stopping\n",
      "177-th combination = (False, False, False, 16, 21, 0.2) \n",
      " train accuracy: [0.4026974141597748, 0.6345844268798828] and test accuracy: [0.3141063153743744, 0.560451865196228]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "179th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.87133, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.87133 to 0.84644, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.84644\n",
      "\n",
      "Epoch 5: val_loss improved from 0.84644 to 0.81033, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.81033 to 0.77223, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.77223 to 0.74136, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.74136 to 0.72169, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.72169 to 0.71885, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.71885 to 0.69383, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.69383 to 0.68129, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.68129 to 0.67017, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.67017\n",
      "\n",
      "Epoch 14: val_loss improved from 0.67017 to 0.65462, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65462 to 0.65189, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.65189 to 0.63780, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.63780 to 0.62706, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.62706 to 0.62120, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62120 to 0.61996, saving model to best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.61996 to 0.61612, saving model to best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.61612 to 0.61191, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.61191 to 0.60959, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.60959 to 0.59510, saving model to best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.59510 to 0.58505, saving model to best_model.h5\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.58505\n",
      "\n",
      "Epoch 26: val_loss improved from 0.58505 to 0.58143, saving model to best_model.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.58143\n",
      "\n",
      "Epoch 28: val_loss improved from 0.58143 to 0.58122, saving model to best_model.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.58122 to 0.56770, saving model to best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.56770 to 0.56568, saving model to best_model.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.56568 to 0.56007, saving model to best_model.h5\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.56007\n",
      "\n",
      "Epoch 33: val_loss improved from 0.56007 to 0.55839, saving model to best_model.h5\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.55839\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.55839\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.55839\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.55839\n",
      "\n",
      "Epoch 38: val_loss improved from 0.55839 to 0.55503, saving model to best_model.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.55503 to 0.55446, saving model to best_model.h5\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.55446\n",
      "178-th combination = (False, False, False, 16, 84, 0.2) \n",
      " train accuracy: [0.39525747299194336, 0.6286950707435608] and test accuracy: [0.47697925567626953, 0.6906368732452393]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "180th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73745, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73745 to 0.73073, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.73073 to 0.72765, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.72765 to 0.72758, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.72758\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.72758\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.72758\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.72758\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.72758\n",
      "Epoch 9: early stopping\n",
      "179-th combination = (False, False, False, 16, 365, 0.2) \n",
      " train accuracy: [0.5304623246192932, 0.7283284664154053] and test accuracy: [0.39106854796409607, 0.6253547668457031]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "181th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58517, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.58517 to 0.53425, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53425 to 0.52742, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.52742 to 0.50730, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50730\n",
      "\n",
      "Epoch 6: val_loss improved from 0.50730 to 0.50103, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50103\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50103\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50103\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50103\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50103\n",
      "Epoch 11: early stopping\n",
      "180-th combination = (False, False, False, 32, 7, 0.2) \n",
      " train accuracy: [0.34114646911621094, 0.5840774774551392] and test accuracy: [0.04664767533540726, 0.21598072350025177]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "182th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68745, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68745 to 0.63106, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63106 to 0.60345, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.60345 to 0.56920, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.56920\n",
      "\n",
      "Epoch 6: val_loss improved from 0.56920 to 0.55278, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.55278 to 0.54679, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54679 to 0.53414, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.53414 to 0.52568, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.52568 to 0.52349, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52349\n",
      "\n",
      "Epoch 12: val_loss improved from 0.52349 to 0.51699, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51699\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51699\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51699\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51699\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.51699\n",
      "Epoch 17: early stopping\n",
      "181-th combination = (False, False, False, 32, 28, 0.2) \n",
      " train accuracy: [0.381033718585968, 0.6172792911529541] and test accuracy: [0.17408743500709534, 0.41723787784576416]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "183th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60947, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60947 to 0.56890, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.56890 to 0.55826, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55826 to 0.53678, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.53678\n",
      "\n",
      "Epoch 6: val_loss improved from 0.53678 to 0.52182, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52182\n",
      "\n",
      "Epoch 8: val_loss improved from 0.52182 to 0.50841, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50841\n",
      "\n",
      "Epoch 10: val_loss improved from 0.50841 to 0.50478, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50478\n",
      "\n",
      "Epoch 12: val_loss improved from 0.50478 to 0.50432, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.50432 to 0.49917, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49917\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49917\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49917\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.49917\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49917\n",
      "Epoch 18: early stopping\n",
      "182-th combination = (False, False, False, 32, 21, 0.2) \n",
      " train accuracy: [0.34787487983703613, 0.5898091793060303] and test accuracy: [0.16591045260429382, 0.4073210656642914]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "184th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.65343, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.65343 to 0.61105, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.61105\n",
      "\n",
      "Epoch 4: val_loss improved from 0.61105 to 0.56755, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.56755 to 0.54454, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.54454 to 0.52991, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52991 to 0.52423, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.52423 to 0.52108, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.52108 to 0.51674, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.51674 to 0.50874, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.50874 to 0.50643, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.50643 to 0.50273, saving model to best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.50273 to 0.49786, saving model to best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.49786 to 0.49095, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.49095 to 0.49017, saving model to best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.49017 to 0.48625, saving model to best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.48625 to 0.48530, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.48530 to 0.48422, saving model to best_model.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.48422\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.48422\n",
      "\n",
      "Epoch 21: val_loss improved from 0.48422 to 0.48262, saving model to best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.48262 to 0.48229, saving model to best_model.h5\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.48229\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.48229\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.48229\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.48229\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.48229\n",
      "Epoch 27: early stopping\n",
      "183-th combination = (False, False, False, 32, 84, 0.2) \n",
      " train accuracy: [0.374267041683197, 0.611773669719696] and test accuracy: [0.03304141014814377, 0.18177296221256256]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "185th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.70290, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.70290 to 0.62600, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.62600 to 0.58308, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.58308 to 0.57263, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57263\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57263\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.57263\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.57263\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.57263\n",
      "Epoch 9: early stopping\n",
      "184-th combination = (False, False, False, 32, 365, 0.2) \n",
      " train accuracy: [0.4516560137271881, 0.6720535755157471] and test accuracy: [0.08633522689342499, 0.2938285768032074]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "186th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52859, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52859 to 0.50895, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50895\n",
      "\n",
      "Epoch 4: val_loss improved from 0.50895 to 0.50627, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50627\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50627\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50627\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50627\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50627\n",
      "Epoch 9: early stopping\n",
      "185-th combination = (False, False, False, 64, 7, 0.2) \n",
      " train accuracy: [0.3449852466583252, 0.5873544216156006] and test accuracy: [0.036742132157087326, 0.191682368516922]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "187th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53308, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.53308\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.53308\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53308 to 0.50231, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50231\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50231\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50231\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50231 to 0.50074, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50074\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50074\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50074\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50074\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50074\n",
      "Epoch 13: early stopping\n",
      "186-th combination = (False, False, False, 64, 28, 0.2) \n",
      " train accuracy: [0.34071677923202515, 0.5837094783782959] and test accuracy: [0.03640035167336464, 0.19078876078128815]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "188th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53597, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.53597\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53597 to 0.51544, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51544 to 0.50113, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.50113 to 0.49990, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49990\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49990\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49990\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49990\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49990\n",
      "Epoch 10: early stopping\n",
      "187-th combination = (False, False, False, 64, 21, 0.2) \n",
      " train accuracy: [0.36508142948150635, 0.6042196750640869] and test accuracy: [0.03780580312013626, 0.1944371461868286]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "189th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60742, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.60742\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60742 to 0.55086, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.55086\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55086\n",
      "\n",
      "Epoch 6: val_loss improved from 0.55086 to 0.54764, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.54764 to 0.54620, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54620 to 0.54010, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.54010\n",
      "\n",
      "Epoch 10: val_loss improved from 0.54010 to 0.52368, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.52368\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.52368\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.52368\n",
      "\n",
      "Epoch 14: val_loss improved from 0.52368 to 0.51358, saving model to best_model.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51358\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.51358\n",
      "\n",
      "Epoch 17: val_loss improved from 0.51358 to 0.50991, saving model to best_model.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.50991\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.50991\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.50991\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.50991\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.50991\n",
      "Epoch 22: early stopping\n",
      "188-th combination = (False, False, False, 64, 84, 0.2) \n",
      " train accuracy: [0.367495059967041, 0.6062136888504028] and test accuracy: [0.0375959575176239, 0.19389677047729492]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "190th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67959, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67959 to 0.56393, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.56393 to 0.55479, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.55479\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.55479\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.55479\n",
      "\n",
      "Epoch 7: val_loss improved from 0.55479 to 0.54642, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54642 to 0.52491, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.52491 to 0.51390, saving model to best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.51390 to 0.51063, saving model to best_model.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.51063\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.51063\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.51063\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.51063\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.51063\n",
      "Epoch 15: early stopping\n",
      "189-th combination = (False, False, False, 64, 365, 0.2) \n",
      " train accuracy: [0.3961308002471924, 0.629389226436615] and test accuracy: [0.0743846446275711, 0.27273547649383545]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "191th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52924, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52924\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52924\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52924\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52924\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52924\n",
      "Epoch 6: early stopping\n",
      "190-th combination = (False, False, False, 128, 7, 0.2) \n",
      " train accuracy: [0.5165725350379944, 0.7187297940254211] and test accuracy: [0.045061126351356506, 0.21227605640888214]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "192th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51368, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51368 to 0.49934, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.49934\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49934\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49934\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49934\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49934\n",
      "Epoch 7: early stopping\n",
      "191-th combination = (False, False, False, 128, 28, 0.2) \n",
      " train accuracy: [0.3874259889125824, 0.6224355101585388] and test accuracy: [0.043508414179086685, 0.2085867077112198]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "193th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57384, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.57384 to 0.54285, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54285 to 0.53888, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53888 to 0.50859, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50859\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50859\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50859\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.50859\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50859\n",
      "Epoch 9: early stopping\n",
      "192-th combination = (False, False, False, 128, 21, 0.2) \n",
      " train accuracy: [0.39007386565208435, 0.6245589256286621] and test accuracy: [0.026541780680418015, 0.16291648149490356]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "194th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.59425, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.59425 to 0.52681, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52681 to 0.50479, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50479\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50479\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50479\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.50479\n",
      "\n",
      "Epoch 8: val_loss improved from 0.50479 to 0.50206, saving model to best_model.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.50206\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.50206\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.50206\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.50206\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.50206\n",
      "Epoch 13: early stopping\n",
      "193-th combination = (False, False, False, 128, 84, 0.2) \n",
      " train accuracy: [0.3795834183692932, 0.6161034107208252] and test accuracy: [0.029254045337438583, 0.17103813588619232]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "195th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55937, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.55937\n",
      "\n",
      "Epoch 4: val_loss improved from 0.55937 to 0.51739, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.51739 to 0.49134, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49134\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49134\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49134\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49134\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49134\n",
      "Epoch 10: early stopping\n",
      "194-th combination = (False, False, False, 128, 365, 0.2) \n",
      " train accuracy: [0.4017055630683899, 0.6338024735450745] and test accuracy: [0.020758669823408127, 0.14407868683338165]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "196th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57364, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.57364\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.57364\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57364\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57364\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57364\n",
      "Epoch 6: early stopping\n",
      "195-th combination = (False, False, False, 256, 7, 0.2) \n",
      " train accuracy: [0.3410775661468506, 0.5840184688568115] and test accuracy: [0.107182078063488, 0.327386736869812]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "197th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.52809, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.52809\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.52809\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52809\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52809\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52809\n",
      "Epoch 6: early stopping\n",
      "196-th combination = (False, False, False, 256, 28, 0.2) \n",
      " train accuracy: [0.44030484557151794, 0.6635547280311584] and test accuracy: [0.09980396181344986, 0.31591764092445374]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "198th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56938, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56938 to 0.51419, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.51419\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.51419\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51419\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51419\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51419\n",
      "Epoch 7: early stopping\n",
      "197-th combination = (False, False, False, 256, 21, 0.2) \n",
      " train accuracy: [0.3849567472934723, 0.6204488277435303] and test accuracy: [0.11639404296875, 0.3411657214164734]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "199th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50277, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.50277\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.50277\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.50277\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.50277\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.50277\n",
      "Epoch 6: early stopping\n",
      "198-th combination = (False, False, False, 256, 84, 0.2) \n",
      " train accuracy: [0.39342018961906433, 0.6272321939468384] and test accuracy: [0.024228082969784737, 0.15565373003482819]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "200th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56392, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56392 to 0.55758, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.55758 to 0.49448, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49448\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49448\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49448\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49448\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49448\n",
      "Epoch 8: early stopping\n",
      "199-th combination = (False, False, False, 256, 365, 0.2) \n",
      " train accuracy: [0.3976922631263733, 0.6306284666061401] and test accuracy: [0.02197268418967724, 0.1482318639755249]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    [True, False],\n",
    "    [True, False],\n",
    "    [True, False],\n",
    "    [16, 32, 64, 128, 256],\n",
    "    [7, 28, 21, 84, 365],\n",
    "    [0.2],\n",
    "]\n",
    "\n",
    "# list of lists --> [[first_additional_layer], [second_additional_layer], [third_additional_layer], [n_neurons], [n_batch_size], [dropout]]\n",
    "\n",
    "hist = LSTM_HyperParameter_Tuning(\n",
    "    config, X_train, y_train, X_test, y_test\n",
    ")  # change x_train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.34128430485725403, 0.5841954350471497]</td>\n",
       "      <td>[0.015950078144669533, 0.1262936145067215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.40547654032707214, 0.6367704272270203]</td>\n",
       "      <td>[0.019572967663407326, 0.13990342617034912]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.40884190797805786, 0.6394074559211731]</td>\n",
       "      <td>[0.020047321915626526, 0.14158856868743896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>84</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.38435444235801697, 0.6199632883071899]</td>\n",
       "      <td>[0.020282382145524025, 0.14241622388362885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.39981889724731445, 0.6323123574256897]</td>\n",
       "      <td>[0.02034253254532814, 0.14262725412845612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.68843674659729, 0.8297209143638611]</td>\n",
       "      <td>[0.5821943879127502, 0.7630166411399841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.6558093428611755, 0.8098205327987671]</td>\n",
       "      <td>[0.7348453402519226, 0.8572311997413635]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.6191141605377197, 0.7868380546569824]</td>\n",
       "      <td>[0.7474299073219299, 0.8645402789115906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.5346857309341431, 0.7312220931053162]</td>\n",
       "      <td>[0.8964783549308777, 0.946825385093689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>365</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.6881216168403625, 0.8295309543609619]</td>\n",
       "      <td>[0.9535651803016663, 0.9765066504478455]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2    3    4    5  \\\n",
       "45    True   True  False  256    7  0.2   \n",
       "119  False   True   True  128  365  0.2   \n",
       "113  False   True   True   64   84  0.2   \n",
       "68    True  False   True  128   84  0.2   \n",
       "125  False   True  False   16    7  0.2   \n",
       "..     ...    ...    ...  ...  ...  ...   \n",
       "4     True   True   True   16  365  0.2   \n",
       "79    True  False  False   16  365  0.2   \n",
       "154  False  False   True   16  365  0.2   \n",
       "153  False  False   True   16   84  0.2   \n",
       "104  False   True   True   16  365  0.2   \n",
       "\n",
       "                                             6  \\\n",
       "45   [0.34128430485725403, 0.5841954350471497]   \n",
       "119  [0.40547654032707214, 0.6367704272270203]   \n",
       "113  [0.40884190797805786, 0.6394074559211731]   \n",
       "68   [0.38435444235801697, 0.6199632883071899]   \n",
       "125  [0.39981889724731445, 0.6323123574256897]   \n",
       "..                                         ...   \n",
       "4       [0.68843674659729, 0.8297209143638611]   \n",
       "79    [0.6558093428611755, 0.8098205327987671]   \n",
       "154   [0.6191141605377197, 0.7868380546569824]   \n",
       "153   [0.5346857309341431, 0.7312220931053162]   \n",
       "104   [0.6881216168403625, 0.8295309543609619]   \n",
       "\n",
       "                                               7  \n",
       "45    [0.015950078144669533, 0.1262936145067215]  \n",
       "119  [0.019572967663407326, 0.13990342617034912]  \n",
       "113  [0.020047321915626526, 0.14158856868743896]  \n",
       "68   [0.020282382145524025, 0.14241622388362885]  \n",
       "125   [0.02034253254532814, 0.14262725412845612]  \n",
       "..                                           ...  \n",
       "4       [0.5821943879127502, 0.7630166411399841]  \n",
       "79      [0.7348453402519226, 0.8572311997413635]  \n",
       "154     [0.7474299073219299, 0.8645402789115906]  \n",
       "153      [0.8964783549308777, 0.946825385093689]  \n",
       "104     [0.9535651803016663, 0.9765066504478455]  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(hist)\n",
    "hist = hist.sort_values(by=[7], ascending=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination: \n",
      " first_additional_layer = True\n",
      " second_additional_layer = True\n",
      " third_additional_layer = False\n",
      " n_neurons = 256\n",
      " n_batch_size = 7\n",
      " dropout = 0.2\n",
      "**************************\n",
      "Results Before Tunning:\n",
      " Test Set RMSE: 0.3931\n",
      "\n",
      "Results After Tunning:\n",
      " Test Set RMSE: 0.1263\n",
      "\n",
      "68.0% Improvement\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}\"\n",
    ")\n",
    "print(\"**************************\")\n",
    "print(f\"Results Before Tunning:\\n Test Set RMSE: {np.round(results, 4)[1]}\\n\")\n",
    "print(f\"Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)[1]}\\n\")\n",
    "print(\n",
    "    f\"{np.round((results[1] - hist.iloc[0, -1][1])*100/np.round(results, 4)[1])}% Improvement\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    first_additional_layer,\n",
    "    second_additional_layer,\n",
    "    third_additional_layer,\n",
    "    n_neurons,\n",
    "    n_batch_size,\n",
    "    dropout,\n",
    ") = list(hist.iloc[0, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60355, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuell/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.60355 to 0.54122, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54122 to 0.52147, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.52147\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.52147\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.52147\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.52147\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52147\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f335055df30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(\n",
    "    LSTM(\n",
    "        units=n_neurons,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    )\n",
    ")\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "if first_additional_layer:\n",
    "    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "if second_additional_layer:\n",
    "    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "if third_additional_layer:\n",
    "    regressor.add(GRU(units=n_neurons, return_sequences=True))\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "regressor.add(Dropout(dropout))\n",
    "regressor.add(Dense(units=1, activation=\"linear\"))\n",
    "regressor.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "\n",
    "file_path = \"best_model.h5\"\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    file_path, monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True\n",
    ")\n",
    "\n",
    "regressor.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=100,\n",
    "    batch_size=n_batch_size,\n",
    "    callbacks=[es, mc],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07031791657209396"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f33cedcf430>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16, 8), dpi=100, facecolor=\"w\", edgecolor=\"k\")\n",
    "\n",
    "plt.plot(y_test, color=\"red\", label=\"Real Opening Price\")\n",
    "plt.plot(y_pred, color=\"green\", label=\"Predicted Opening Price\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

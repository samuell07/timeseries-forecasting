{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 13:56:43.944120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-30 13:56:44.102694: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 13:56:44.102772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 13:56:44.122147: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 13:56:44.165892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 13:56:45.479209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT SPEKTRAL CLASSES ###\n",
    "\n",
    "from spektral_utilities import *\n",
    "from spektral_gcn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>WHO_region</th>\n",
       "      <th>New_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AFRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AMRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>EMRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>EURO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_reported WHO_region  New_deaths\n",
       "0    2020-01-03       AFRO           0\n",
       "1    2020-01-03       AMRO           0\n",
       "2    2020-01-03       EMRO           0\n",
       "3    2020-01-03       EURO           0\n",
       "4    2020-01-03      Other           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../data/WHO-COVID-19-global-data.csv\"\n",
    "date_column = \"Date_reported\"\n",
    "target_column = \"New_deaths\"\n",
    "id_column = \"WHO_region\"\n",
    "df = pd.read_csv(file_path)[[date_column, target_column, id_column]]\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "df = df.groupby([date_column, id_column])[target_column].sum().reset_index()\n",
    "# df[id_column] = 'A'\n",
    "unique_dates = df[date_column].unique()\n",
    "um_countries_regions = len(df[id_column].unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>WHO_region</th>\n",
       "      <th>New_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AFRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AMRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>EMRO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>EURO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_reported WHO_region  New_deaths\n",
       "0    2020-01-03       AFRO           0\n",
       "1    2020-01-03       AMRO           0\n",
       "2    2020-01-03       EMRO           0\n",
       "3    2020-01-03       EURO           0\n",
       "4    2020-01-03      Other           0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = df.pivot_table(index=date_column, columns=id_column, values=target_column)\n",
    "\n",
    "# Rename 'index' back to date_columneported\n",
    "df.rename(columns={\"index\": date_column}, inplace=True)\n",
    "# df[date_column] = pd.to_datetime(df[date_column])\n",
    "# unique_dates = df[date_column].unique()\n",
    "# df.set_index(date_column, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1420)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Date_reported</th>\n",
       "      <th>2020-01-03</th>\n",
       "      <th>2020-01-04</th>\n",
       "      <th>2020-01-05</th>\n",
       "      <th>2020-01-06</th>\n",
       "      <th>2020-01-07</th>\n",
       "      <th>2020-01-08</th>\n",
       "      <th>2020-01-09</th>\n",
       "      <th>2020-01-10</th>\n",
       "      <th>2020-01-11</th>\n",
       "      <th>2020-01-12</th>\n",
       "      <th>2020-01-13</th>\n",
       "      <th>2020-01-14</th>\n",
       "      <th>2020-01-15</th>\n",
       "      <th>2020-01-16</th>\n",
       "      <th>2020-01-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFRO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMRO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMRO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EURO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Date_reported  2020-01-03  2020-01-04  2020-01-05  2020-01-06  2020-01-07  \\\n",
       "id                                                                          \n",
       "AFRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "AMRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "EMRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "EURO                  0.0         0.0         3.0         0.0         0.0   \n",
       "Other                 0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "Date_reported  2020-01-08  2020-01-09  2020-01-10  2020-01-11  2020-01-12  \\\n",
       "id                                                                          \n",
       "AFRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "AMRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "EMRO                  0.0         0.0         0.0         0.0         0.0   \n",
       "EURO                  0.0         0.0         0.0         0.0         0.0   \n",
       "Other                 0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "Date_reported  2020-01-13  2020-01-14  2020-01-15  2020-01-16  2020-01-17  \n",
       "id                                                                         \n",
       "AFRO                  0.0         0.0         0.0         0.0         0.0  \n",
       "AMRO                  0.0         0.0         0.0         0.0         0.0  \n",
       "EMRO                  0.0         0.0         0.0         0.0         0.0  \n",
       "EURO                  0.0         0.0         0.0         0.0         0.0  \n",
       "Other                 0.0         0.0         0.0         0.0         0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstaked_df = df.copy()\n",
    "unstaked_df[\"id\"] = unstaked_df[\"WHO_region\"]\n",
    "unstaked_df.set_index([\"id\", \"Date_reported\"], inplace=True)\n",
    "\n",
    "# Dropping columns not needed for the analysis\n",
    "unstaked_df.drop([\"WHO_region\"], axis=1, inplace=True)\n",
    "\n",
    "# Converting data to float and unstacking\n",
    "unstaked_df = unstaked_df.astype(float).unstack()\n",
    "unstaked_df.columns = unstaked_df.columns.get_level_values(1)\n",
    "\n",
    "# Displaying the shape and head of the updated DataFrame\n",
    "print(unstaked_df.shape)\n",
    "unstaked_df.iloc[:, :15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITY FUNCTIONS FOR FEATURE ENGINEERING ###\n",
    "\n",
    "sequence_length = 14\n",
    "\n",
    "\n",
    "\n",
    "def get_timespan(df, today, days):    \n",
    "    df = df[pd.date_range(today - timedelta(days=days), \n",
    "            periods=days, freq='D')] # day - n_days <= dates < day    \n",
    "    return df\n",
    "\n",
    "def create_features(df, today, seq_len):\n",
    "    \n",
    "    all_sequence = get_timespan(df, today, seq_len).values\n",
    "    \n",
    "    group_store = all_sequence.reshape((-1, um_countries_regions, seq_len))\n",
    "    \n",
    "    store_corr = np.stack([np.corrcoef(i) for i in group_store], axis=0)\n",
    "    \n",
    "    store_features = np.stack([\n",
    "              group_store.mean(axis=2),\n",
    "              group_store[:,:,int(sequence_length/2):].mean(axis=2),\n",
    "              group_store.std(axis=2),\n",
    "              group_store[:,:,int(sequence_length/2):].std(axis=2),\n",
    "              skew(group_store, axis=2),\n",
    "              kurtosis(group_store, axis=2),\n",
    "              np.apply_along_axis(lambda x: np.polyfit(np.arange(0, sequence_length), x, 1)[0], 2, group_store)\n",
    "            ], axis=1)\n",
    "    \n",
    "    group_store = np.transpose(group_store, (0,2,1))\n",
    "    store_features = np.transpose(store_features, (0,2,1))\n",
    "    \n",
    "    return group_store, store_corr, store_features\n",
    "\n",
    "def create_label(df, today):\n",
    "    \n",
    "    y = df[today].values\n",
    "    \n",
    "    return y.reshape((-1, um_countries_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE TRAIN, VALID, TEST DATES ###\n",
    "\n",
    "train_date = unique_dates[0]\n",
    "valid_date = unique_dates[-(len(unique_dates) // 2) + 1]\n",
    "test_date = unique_dates[-len(unique_dates) // 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/698 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuell/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/samuell/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "100%|██████████| 698/698 [00:02<00:00, 295.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 14, 7) (698, 7, 7) (698, 7, 7) (698, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_seq, X_cor, X_feat, y = [], [], [], []\n",
    "\n",
    "for d in tqdm(pd.date_range(train_date + timedelta(days=sequence_length), valid_date)):\n",
    "    seq_, corr_, feat_ = create_features(unstaked_df, d, sequence_length)\n",
    "    y_ = create_label(unstaked_df, d)\n",
    "    X_seq.append(seq_), X_cor.append(corr_), X_feat.append(feat_), y.append(y_)\n",
    "\n",
    "X_train_seq = np.concatenate(X_seq, axis=0).astype(\"float16\")\n",
    "X_train_cor = np.concatenate(X_cor, axis=0).astype(\"float16\")\n",
    "X_train_feat = np.concatenate(X_feat, axis=0).astype(\"float16\")\n",
    "y_train = np.concatenate(y, axis=0).astype(\"float16\")\n",
    "\n",
    "print(X_train_seq.shape, X_train_cor.shape, X_train_feat.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:01<00:00, 280.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 14, 7) (341, 7, 7) (341, 7, 7) (341, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### CREATE VALID FEATURES ###\n",
    "\n",
    "X_seq, X_cor, X_feat, y = [], [], [], []\n",
    "\n",
    "for d in tqdm(pd.date_range(valid_date + timedelta(days=sequence_length), test_date)):\n",
    "    seq_, corr_, feat_ = create_features(unstaked_df, d, sequence_length)\n",
    "    y_ = create_label(unstaked_df, d)\n",
    "    X_seq.append(seq_), X_cor.append(corr_), X_feat.append(feat_), y.append(y_)\n",
    "\n",
    "X_valid_seq = np.concatenate(X_seq, axis=0).astype(\"float16\")\n",
    "X_valid_cor = np.concatenate(X_cor, axis=0).astype(\"float16\")\n",
    "X_valid_feat = np.concatenate(X_feat, axis=0).astype(\"float16\")\n",
    "y_valid = np.concatenate(y, axis=0).astype(\"float16\")\n",
    "\n",
    "print(X_valid_seq.shape, X_valid_cor.shape, X_valid_feat.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:01<00:00, 296.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 14, 7) (341, 7, 7) (341, 7, 7) (341, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### CREATE TEST FEATURES ###\n",
    "\n",
    "X_seq, X_cor, X_feat, y = [], [], [], []\n",
    "\n",
    "for d in tqdm(\n",
    "    pd.date_range(test_date + timedelta(days=sequence_length), unique_dates[-1])\n",
    "):\n",
    "    seq_, corr_, feat_ = create_features(unstaked_df, d, sequence_length)\n",
    "    y_ = create_label(unstaked_df, d)\n",
    "    X_seq.append(seq_), X_cor.append(corr_), X_feat.append(feat_), y.append(y_)\n",
    "\n",
    "X_test_seq = np.concatenate(X_seq, axis=0).astype(\"float16\")\n",
    "X_test_cor = np.concatenate(X_cor, axis=0).astype(\"float16\")\n",
    "X_test_feat = np.concatenate(X_feat, axis=0).astype(\"float16\")\n",
    "y_test = np.concatenate(y, axis=0).astype(\"float16\")\n",
    "\n",
    "print(X_test_seq.shape, X_test_cor.shape, X_test_feat.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCALE SEQUENCES ###\n",
    "\n",
    "scaler_seq = StandardScaler()\n",
    "scaler_feat = StandardScaler()\n",
    "\n",
    "X_train_seq = scaler_seq.fit_transform(\n",
    "    X_train_seq.reshape(-1, um_countries_regions)\n",
    ").reshape(X_train_seq.shape)\n",
    "X_valid_seq = scaler_seq.transform(\n",
    "    X_valid_seq.reshape(-1, um_countries_regions)\n",
    ").reshape(X_valid_seq.shape)\n",
    "X_test_seq = scaler_seq.transform(X_test_seq.reshape(-1, um_countries_regions)).reshape(\n",
    "    X_test_seq.shape\n",
    ")\n",
    "\n",
    "y_train = scaler_seq.transform(y_train)\n",
    "y_valid = scaler_seq.transform(y_valid)\n",
    "y_test = scaler_seq.transform(y_test)\n",
    "\n",
    "X_train_feat = scaler_feat.fit_transform(\n",
    "    X_train_feat.reshape(-1, um_countries_regions)\n",
    ").reshape(X_train_feat.shape)\n",
    "X_valid_feat = scaler_feat.transform(\n",
    "    X_valid_feat.reshape(-1, um_countries_regions)\n",
    ").reshape(X_valid_feat.shape)\n",
    "X_test_feat = scaler_feat.transform(\n",
    "    X_test_feat.reshape(-1, um_countries_regions)\n",
    ").reshape(X_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lap = localpooling_filter(1 - np.abs(X_train_cor))\n",
    "X_valid_lap = localpooling_filter(1 - np.abs(X_valid_cor))\n",
    "X_test_lap = localpooling_filter(1 - np.abs(X_test_cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    set_seed(33)\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "\n",
    "    inp_seq = Input((sequence_length, um_countries_regions))\n",
    "    inp_lap = Input((um_countries_regions, um_countries_regions))\n",
    "    inp_feat = Input((um_countries_regions, X_train_feat.shape[-1]))\n",
    "\n",
    "    x = GraphConv(256, activation=\"relu\")([inp_feat, inp_lap])\n",
    "    x = GraphConv(128, activation=\"relu\")([x, inp_lap])\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    xx = LSTM(256, activation=\"relu\", return_sequences=True)(inp_seq)\n",
    "    xx = LSTM(128, activation=\"relu\")(xx)\n",
    "\n",
    "    x = Concatenate()([x, xx])\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(1)(x)\n",
    "\n",
    "    model = Model([inp_seq, inp_lap, inp_feat], out)\n",
    "    model.compile(\n",
    "        optimizer=opt, loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_99 (InputLayer)       [(None, 7, 7)]               0         []                            \n",
      "                                                                                                  \n",
      " input_98 (InputLayer)       [(None, 7, 7)]               0         []                            \n",
      "                                                                                                  \n",
      " graph_conv_64 (GraphConv)   (None, 7, 256)               2048      ['input_99[0][0]',            \n",
      "                                                                     'input_98[0][0]']            \n",
      "                                                                                                  \n",
      " input_97 (InputLayer)       [(None, 14, 7)]              0         []                            \n",
      "                                                                                                  \n",
      " graph_conv_65 (GraphConv)   (None, 7, 128)               32896     ['graph_conv_64[0][0]',       \n",
      "                                                                     'input_98[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_64 (LSTM)              (None, 14, 256)              270336    ['input_97[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_32 (Flatten)        (None, 896)                  0         ['graph_conv_65[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_65 (LSTM)              (None, 128)                  197120    ['lstm_64[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenat  (None, 1024)                 0         ['flatten_32[0][0]',          \n",
      " e)                                                                  'lstm_65[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)        (None, 1024)                 0         ['concatenate_32[0][0]']      \n",
      "                                                                                                  \n",
      " dense_96 (Dense)            (None, 256)                  262400    ['dropout_64[0][0]']          \n",
      "                                                                                                  \n",
      " dense_97 (Dense)            (None, 128)                  32896     ['dense_96[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)        (None, 128)                  0         ['dense_97[0][0]']            \n",
      "                                                                                                  \n",
      " dense_98 (Dense)            (None, 1)                    129       ['dropout_65[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 797825 (3.04 MB)\n",
      "Trainable params: 797825 (3.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 0 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 0.9943 - root_mean_squared_error: 0.9972 - val_loss: 1.0154 - val_root_mean_squared_error: 1.0077 - 4s/epoch - 154ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 0.9945 - root_mean_squared_error: 0.9972 - val_loss: 1.0068 - val_root_mean_squared_error: 1.0034 - 708ms/epoch - 29ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 0.9949 - root_mean_squared_error: 0.9974 - val_loss: 1.0242 - val_root_mean_squared_error: 1.0120 - 670ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 0.9943 - root_mean_squared_error: 0.9972 - val_loss: 1.0165 - val_root_mean_squared_error: 1.0082 - 670ms/epoch - 28ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 0.9945 - root_mean_squared_error: 0.9972 - val_loss: 1.0083 - val_root_mean_squared_error: 1.0041 - 664ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "24/24 - 1s - loss: 0.9945 - root_mean_squared_error: 0.9972 - val_loss: 1.0219 - val_root_mean_squared_error: 1.0109 - 679ms/epoch - 28ms/step\n",
      "Epoch 7/1000\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "24/24 - 1s - loss: 0.9943 - root_mean_squared_error: 0.9971 - val_loss: 1.0230 - val_root_mean_squared_error: 1.0114 - 682ms/epoch - 28ms/step\n",
      "Epoch 7: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 1 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 0.9752 - root_mean_squared_error: 0.9875 - val_loss: 3.0833 - val_root_mean_squared_error: 1.7559 - 4s/epoch - 156ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 0.9751 - root_mean_squared_error: 0.9875 - val_loss: 3.0506 - val_root_mean_squared_error: 1.7466 - 671ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 0.9748 - root_mean_squared_error: 0.9873 - val_loss: 3.0667 - val_root_mean_squared_error: 1.7512 - 680ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9874 - val_loss: 3.0536 - val_root_mean_squared_error: 1.7475 - 688ms/epoch - 29ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9874 - val_loss: 3.0424 - val_root_mean_squared_error: 1.7442 - 671ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "24/24 - 1s - loss: 0.9748 - root_mean_squared_error: 0.9873 - val_loss: 3.0459 - val_root_mean_squared_error: 1.7452 - 676ms/epoch - 28ms/step\n",
      "Epoch 7/1000\n",
      "24/24 - 1s - loss: 0.9751 - root_mean_squared_error: 0.9875 - val_loss: 3.0558 - val_root_mean_squared_error: 1.7481 - 690ms/epoch - 29ms/step\n",
      "Epoch 8/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9873 - val_loss: 3.0483 - val_root_mean_squared_error: 1.7460 - 662ms/epoch - 28ms/step\n",
      "Epoch 9/1000\n",
      "24/24 - 1s - loss: 0.9750 - root_mean_squared_error: 0.9874 - val_loss: 3.0376 - val_root_mean_squared_error: 1.7429 - 662ms/epoch - 28ms/step\n",
      "Epoch 10/1000\n",
      "24/24 - 1s - loss: 0.9748 - root_mean_squared_error: 0.9873 - val_loss: 3.0445 - val_root_mean_squared_error: 1.7448 - 660ms/epoch - 28ms/step\n",
      "Epoch 11/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9874 - val_loss: 3.0401 - val_root_mean_squared_error: 1.7436 - 653ms/epoch - 27ms/step\n",
      "Epoch 12/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9874 - val_loss: 3.0413 - val_root_mean_squared_error: 1.7439 - 661ms/epoch - 28ms/step\n",
      "Epoch 13/1000\n",
      "24/24 - 1s - loss: 0.9749 - root_mean_squared_error: 0.9874 - val_loss: 3.0535 - val_root_mean_squared_error: 1.7474 - 666ms/epoch - 28ms/step\n",
      "Epoch 14/1000\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "24/24 - 1s - loss: 0.9747 - root_mean_squared_error: 0.9873 - val_loss: 3.0535 - val_root_mean_squared_error: 1.7474 - 708ms/epoch - 30ms/step\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n",
      "------- store 2 -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 0.9779 - root_mean_squared_error: 0.9889 - val_loss: 2.7056 - val_root_mean_squared_error: 1.6449 - 4s/epoch - 157ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 0.9777 - root_mean_squared_error: 0.9888 - val_loss: 2.7149 - val_root_mean_squared_error: 1.6477 - 671ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 0.9776 - root_mean_squared_error: 0.9887 - val_loss: 2.7225 - val_root_mean_squared_error: 1.6500 - 665ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 0.9775 - root_mean_squared_error: 0.9887 - val_loss: 2.7206 - val_root_mean_squared_error: 1.6494 - 675ms/epoch - 28ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 0.9777 - root_mean_squared_error: 0.9888 - val_loss: 2.7095 - val_root_mean_squared_error: 1.6461 - 663ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "24/24 - 1s - loss: 0.9777 - root_mean_squared_error: 0.9888 - val_loss: 2.7284 - val_root_mean_squared_error: 1.6518 - 674ms/epoch - 28ms/step\n",
      "Epoch 6: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 3 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 1.0103 - root_mean_squared_error: 1.0051 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6796 - 4s/epoch - 159ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 1.0095 - root_mean_squared_error: 1.0047 - val_loss: 0.4812 - val_root_mean_squared_error: 0.6937 - 683ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 1.0092 - root_mean_squared_error: 1.0046 - val_loss: 0.4781 - val_root_mean_squared_error: 0.6914 - 669ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 1.0091 - root_mean_squared_error: 1.0045 - val_loss: 0.4843 - val_root_mean_squared_error: 0.6959 - 655ms/epoch - 27ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 1.0091 - root_mean_squared_error: 1.0045 - val_loss: 0.4840 - val_root_mean_squared_error: 0.6957 - 652ms/epoch - 27ms/step\n",
      "Epoch 6/1000\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "24/24 - 1s - loss: 1.0091 - root_mean_squared_error: 1.0045 - val_loss: 0.4872 - val_root_mean_squared_error: 0.6980 - 671ms/epoch - 28ms/step\n",
      "Epoch 6: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 4 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 1.0007 - root_mean_squared_error: 1.0004 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156 - 4s/epoch - 157ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 1.0007 - root_mean_squared_error: 1.0003 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144 - 670ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 1.0008 - root_mean_squared_error: 1.0004 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221 - 678ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 1.0007 - root_mean_squared_error: 1.0003 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199 - 679ms/epoch - 28ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 1.0006 - root_mean_squared_error: 1.0003 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213 - 679ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "24/24 - 1s - loss: 1.0006 - root_mean_squared_error: 1.0003 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184 - 679ms/epoch - 28ms/step\n",
      "Epoch 6: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 5 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 5s - loss: 0.9966 - root_mean_squared_error: 0.9983 - val_loss: 0.7808 - val_root_mean_squared_error: 0.8836 - 5s/epoch - 195ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 0.9965 - root_mean_squared_error: 0.9983 - val_loss: 0.7789 - val_root_mean_squared_error: 0.8826 - 675ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 0.9965 - root_mean_squared_error: 0.9983 - val_loss: 0.7802 - val_root_mean_squared_error: 0.8833 - 669ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 0.9966 - root_mean_squared_error: 0.9983 - val_loss: 0.7790 - val_root_mean_squared_error: 0.8826 - 663ms/epoch - 28ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 0.9965 - root_mean_squared_error: 0.9982 - val_loss: 0.7826 - val_root_mean_squared_error: 0.8847 - 674ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "24/24 - 1s - loss: 0.9968 - root_mean_squared_error: 0.9984 - val_loss: 0.7934 - val_root_mean_squared_error: 0.8907 - 667ms/epoch - 28ms/step\n",
      "Epoch 7/1000\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "24/24 - 1s - loss: 0.9966 - root_mean_squared_error: 0.9983 - val_loss: 0.7828 - val_root_mean_squared_error: 0.8848 - 676ms/epoch - 28ms/step\n",
      "Epoch 7: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- store 6 -------\n",
      "Epoch 1/1000\n",
      "24/24 - 4s - loss: 1.0043 - root_mean_squared_error: 1.0022 - val_loss: 156.2550 - val_root_mean_squared_error: 12.5002 - 4s/epoch - 155ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 1s - loss: 1.0042 - root_mean_squared_error: 1.0021 - val_loss: 156.2502 - val_root_mean_squared_error: 12.5000 - 683ms/epoch - 28ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 1s - loss: 1.0042 - root_mean_squared_error: 1.0021 - val_loss: 156.2461 - val_root_mean_squared_error: 12.4998 - 676ms/epoch - 28ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 1s - loss: 1.0040 - root_mean_squared_error: 1.0020 - val_loss: 156.2462 - val_root_mean_squared_error: 12.4998 - 687ms/epoch - 29ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 1s - loss: 1.0043 - root_mean_squared_error: 1.0021 - val_loss: 156.2467 - val_root_mean_squared_error: 12.4999 - 676ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "24/24 - 1s - loss: 1.0044 - root_mean_squared_error: 1.0022 - val_loss: 156.2368 - val_root_mean_squared_error: 12.4995 - 663ms/epoch - 28ms/step\n",
      "Epoch 7/1000\n",
      "24/24 - 1s - loss: 1.0039 - root_mean_squared_error: 1.0020 - val_loss: 156.2368 - val_root_mean_squared_error: 12.4995 - 659ms/epoch - 27ms/step\n",
      "Epoch 8/1000\n",
      "24/24 - 1s - loss: 1.0040 - root_mean_squared_error: 1.0020 - val_loss: 156.2350 - val_root_mean_squared_error: 12.4994 - 670ms/epoch - 28ms/step\n",
      "Epoch 9/1000\n",
      "24/24 - 1s - loss: 1.0040 - root_mean_squared_error: 1.0020 - val_loss: 156.2328 - val_root_mean_squared_error: 12.4993 - 666ms/epoch - 28ms/step\n",
      "Epoch 10/1000\n",
      "24/24 - 1s - loss: 1.0038 - root_mean_squared_error: 1.0019 - val_loss: 156.2355 - val_root_mean_squared_error: 12.4994 - 671ms/epoch - 28ms/step\n",
      "Epoch 11/1000\n",
      "24/24 - 1s - loss: 1.0039 - root_mean_squared_error: 1.0020 - val_loss: 156.2377 - val_root_mean_squared_error: 12.4995 - 679ms/epoch - 28ms/step\n",
      "Epoch 12/1000\n",
      "24/24 - 1s - loss: 1.0039 - root_mean_squared_error: 1.0020 - val_loss: 156.2383 - val_root_mean_squared_error: 12.4995 - 663ms/epoch - 28ms/step\n",
      "Epoch 13/1000\n",
      "24/24 - 1s - loss: 1.0039 - root_mean_squared_error: 1.0019 - val_loss: 156.2383 - val_root_mean_squared_error: 12.4995 - 666ms/epoch - 28ms/step\n",
      "Epoch 14/1000\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "24/24 - 1s - loss: 1.0039 - root_mean_squared_error: 1.0020 - val_loss: 156.2383 - val_root_mean_squared_error: 12.4995 - 684ms/epoch - 29ms/step\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 11ms/step\n",
      "11/11 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "### TRAIN A MODEL FOR EACH STORES USING ALL THE DATA AVAILALBE FROM OTHER STORES ###\n",
    "\n",
    "pred_valid_all = np.zeros(y_valid.shape)\n",
    "pred_test_all = np.zeros(y_test.shape)\n",
    "\n",
    "for store in range(um_countries_regions):\n",
    "    print(\"-------\", \"store\", store, \"-------\")\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_delta=0.001,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    model = get_model()\n",
    "    model.fit(\n",
    "        [X_train_seq, X_train_lap, X_train_feat],\n",
    "        y_train[:, store],\n",
    "        epochs=1000,\n",
    "        batch_size=30,\n",
    "        validation_data=([X_valid_seq, X_valid_lap, X_valid_feat], y_test[:, store]),\n",
    "        callbacks=[es],\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    pred_valid_all[:, store] = model.predict(\n",
    "        [X_valid_seq, X_valid_lap, X_valid_feat]\n",
    "    ).ravel()\n",
    "    pred_test_all[:, store] = model.predict(\n",
    "        [X_test_seq, X_test_lap, X_test_feat]\n",
    "    ).ravel()\n",
    "\n",
    "\n",
    "pred_valid_all = scaler_seq.inverse_transform(pred_valid_all)\n",
    "reverse_valid = scaler_seq.inverse_transform(y_valid)\n",
    "pred_test_all = scaler_seq.inverse_transform(pred_test_all)\n",
    "reverse_test = scaler_seq.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02],\n",
       "       [2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02],\n",
       "       [2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02],\n",
       "       ...,\n",
       "       [2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02],\n",
       "       [2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02],\n",
       "       [2.e+02, 3.e+03, 4.e+02, ..., 2.e-02, 1.e+03, 2.e+02]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RMSE ON TEST DATA ###\n",
    "\n",
    "\n",
    "\n",
    "error = np.sqrt(mean_squared_error(reverse_test, pred_test_all))\n",
    "pred_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### PLOT RMSE ###\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(1 ,error)\n",
    "# plt.xticks(range(7), [str(s) for s in range(7)])\n",
    "plt.ylabel(\"error\")\n",
    "np.set_printoptions(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred, store, item):\n",
    "    y_true = y_true.reshape(1, -1, 7)\n",
    "    y_pred = y_pred.reshape(1, -1, 7)\n",
    "    t = y_true[item, :, store]\n",
    "    for i in range(7):\n",
    "\n",
    "    plt.plot(y_true[item, :, store], label=\"true\")\n",
    "    plt.plot(y_pred[item, :, store], label=\"prediction\")\n",
    "    plt.title(f\"store: {store} item: {item}\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"sales\")\n",
    "    plt.xlabel(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m11\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_predictions(reverse_test, pred_test_all, \u001b[39m6\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(y_true[item, :, store], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(y_pred[item, :, store], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/samuell/Desktop/timeseries-forecasting/covid_deaths/models/covid-deaths-gnn.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstore: \u001b[39m\u001b[39m{\u001b[39;00mstore\u001b[39m}\u001b[39;00m\u001b[39m item: \u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1100x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "plot_predictions(reverse_test, pred_test_all, 6, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
